{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from nltk.corpus import words\n",
    "import random\n",
    "import string\n",
    "from torchvision import transforms\n",
    "from typing import List, Tuple\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using GPU: MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Generating dataset...\n",
      "Calculating random baseline...\n",
      "Random Baseline MAE: 2.3707\n",
      "\n",
      "Training model...\n",
      "Epoch 1/20:\n",
      "Training Loss: 0.6624\n",
      "Validation Loss: 0.0031\n",
      "Validation MAE: 0.0472\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 238\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 195\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Baseline MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_mae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 195\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating generalization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m mae_by_length \u001b[38;5;241m=\u001b[39m evaluate_generalization(model, device)\n",
      "Cell \u001b[0;32mIn[9], line 89\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     86\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(sequences, lengths)\n\u001b[1;32m     87\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 89\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     92\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Desktop/college/smai/env/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/college/smai/env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/college/smai/env/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class BitSequenceDataset(Dataset):\n",
    "    def __init__(self, sequences: List[str], labels: List[int]):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor([int(b) for b in self.sequences[idx]], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return seq, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n",
    "    labels = torch.stack(labels)    \n",
    "    return sequences_padded, labels, lengths\n",
    "\n",
    "\n",
    "def generate_dataset(num_samples, min_len, max_len) :\n",
    "    sequences = []\n",
    "    labels = []    \n",
    "    for _ in range(num_samples):\n",
    "        length = random.randint(min_len, max_len)\n",
    "        sequence = ''.join(random.choice('01') for _ in range(length))\n",
    "        count = sum(int(b) for b in sequence)        \n",
    "        sequences.append(sequence)\n",
    "        labels.append(count)    \n",
    "    return sequences, labels\n",
    "\n",
    "\n",
    "class BitCounterRNN(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_layers: int, dropout: float = 0.1):\n",
    "        super(BitCounterRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "   \n",
    "        x = x.unsqueeze(-1)  \n",
    "        packed_x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )        \n",
    "\n",
    "        packed_output, _ = self.rnn(packed_x)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "   \n",
    "        batch_size = output.size(0)\n",
    "        last_outputs = torch.zeros(batch_size, self.hidden_size, device=output.device)\n",
    "        for i in range(batch_size):\n",
    "            last_outputs[i] = output[i, lengths[i]-1]\n",
    "        count = self.fc(last_outputs)\n",
    "        return count.squeeze(-1)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, labels, lengths in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "     \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sequences, labels, lengths in val_loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                outputs = model(sequences, lengths)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                val_mae += torch.mean(torch.abs(outputs - labels)).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation MAE: {val_mae:.4f}\\n')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_generalization(model, device, max_length=32):\n",
    "    model.eval()\n",
    "    mae_by_length = {}\n",
    "    \n",
    "    for length in range(1, max_length + 1):\n",
    "     \n",
    "        sequences, labels = generate_dataset(1000, length, length)\n",
    "        dataset = BitSequenceDataset(sequences, labels)\n",
    "        loader = DataLoader(dataset, batch_size=64, collate_fn=collate_fn)\n",
    "        \n",
    "        total_mae = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels, lengths in loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                outputs = model(sequences, lengths)\n",
    "                total_mae += torch.mean(torch.abs(outputs - labels)).item() * len(sequences)\n",
    "        \n",
    "        mae_by_length[length] = total_mae / 1000\n",
    "    \n",
    "    return mae_by_length\n",
    "\n",
    "\n",
    "def random_baseline(test_loader, device):\n",
    "    total_mae = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for sequences, labels, lengths in test_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        batch_size = labels.size(0)\n",
    "       \n",
    "        max_counts = lengths.float()  \n",
    "        random_predictions = torch.rand(batch_size, device=device) * max_counts\n",
    "        \n",
    "        mae = torch.mean(torch.abs(random_predictions - labels)).item()\n",
    "        total_mae += mae * batch_size\n",
    "        total_samples += batch_size\n",
    "    \n",
    "    return total_mae / total_samples\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Generating dataset...\")\n",
    "sequences, labels = generate_dataset(100000, 1, 16)\n",
    "dataset = BitSequenceDataset(sequences, labels)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "    \n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "\n",
    "model = BitCounterRNN(hidden_size=64, num_layers=2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Calculating random baseline...\")\n",
    "random_mae = random_baseline(test_loader, device)\n",
    "print(f\"Random Baseline MAE: {random_mae:.4f}\")\n",
    "    \n",
    "print(\"\\nTraining model...\")\n",
    "train_losses, val_losses = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device=device\n",
    ")\n",
    "    \n",
    "print(\"\\nEvaluating generalization...\")\n",
    "mae_by_length = evaluate_generalization(model, device)\n",
    "    \n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "lengths = list(mae_by_length.keys())\n",
    "maes = list(mae_by_length.values())\n",
    "    \n",
    "plt.plot(lengths, maes, marker='o', label='Model MAE')\n",
    "plt.axhline(y=random_mae, color='r', linestyle='--', label='Random Baseline')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Model Generalization across Different Sequence Lengths')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('generalization_plot.png')\n",
    "plt.close()\n",
    "    \n",
    "    # Print example predictions\n",
    "print(\"\\nExample predictions:\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for sequences, labels, lengths in test_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        predictions = model(sequences, lengths)\n",
    "        \n",
    "        # Print first 5 examples\n",
    "        for i in range(min(5, len(sequences))):\n",
    "            seq = sequences[i][:lengths[i]].cpu().numpy()\n",
    "            seq_str = ''.join(map(str, map(int, seq)))\n",
    "            print(f\"Sequence: {seq_str}\")\n",
    "            print(f\"True count: {labels[i].item():.0f}\")\n",
    "            print(f\"Predicted count: {predictions[i].item():.1f}\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, word_list: List[str], image_size: Tuple[int, int] = (256, 64), max_word_length=20):\n",
    "        self.words = [word for word in word_list if len(word) <= max_word_length]\n",
    "        self.image_size = image_size\n",
    "        self.max_word_length = max_word_length\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "        \n",
    "       \n",
    "        self.font = ImageFont.truetype(\"arial.ttf\", size=32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "    \n",
    "    def render_word(self, word: str) -> Image:\n",
    "       \n",
    "        img = Image.new('L', self.image_size, color=255)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        \n",
    "        bbox = draw.textbbox((0, 0), word, font=self.font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        \n",
    "      \n",
    "        x = (self.image_size[0] - text_width) // 2\n",
    "        y = (self.image_size[1] - text_height) // 2\n",
    "        \n",
    "       \n",
    "        draw.text((x, y), word, fill=0, font=self.font)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words[idx]\n",
    "        image = self.render_word(word)\n",
    "        image_tensor = self.transform(image)\n",
    "        \n",
    "        char_indices = [string.ascii_lowercase.find(c.lower()) + 1 for c in word if c.lower() in string.ascii_lowercase]\n",
    "        return image_tensor, torch.tensor(char_indices, dtype=torch.long), len(char_indices)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    images, labels, lengths = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    \n",
    "    max_len = max(lengths)\n",
    "    padded_labels = torch.zeros(len(labels), max_len).long()\n",
    "    for i, label in enumerate(labels):\n",
    "        padded_labels[i, :len(label)] = label\n",
    "    lengths = torch.tensor(lengths)\n",
    "    \n",
    "    return images, padded_labels, lengths\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        batch_size = x.size(0)\n",
    "        return x.view(batch_size, -1, 512)\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "class OCRModel(nn.Module):\n",
    "    def __init__(self, num_classes=27):  \n",
    "        super(OCRModel, self).__init__()\n",
    "        self.encoder = CNNEncoder()\n",
    "        self.decoder = RNNDecoder(\n",
    "            input_size=512,\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, device='mps'):\n",
    "    \n",
    "    criterion = nn.CTCLoss(blank=0, reduction='mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (images, targets, target_lengths) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "     \n",
    "            input_lengths = torch.full((outputs.size(0),), outputs.size(1), dtype=torch.long)\n",
    "            loss = criterion(outputs.transpose(0, 1), targets, input_lengths, target_lengths)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "   \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_chars = 0\n",
    "        total_chars = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets, target_lengths in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                \n",
    "               \n",
    "                input_lengths = torch.full((outputs.size(0),), outputs.size(1), dtype=torch.long)\n",
    "                loss = criterion(outputs.transpose(0, 1), targets, input_lengths, target_lengths)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "               \n",
    "                pred_indices = outputs.argmax(dim=-1)\n",
    "                for pred, target, length in zip(pred_indices, targets, target_lengths):\n",
    "                    pred = pred[:length]\n",
    "                    target = target[:length]\n",
    "                    correct_chars += (pred == target).sum().item()\n",
    "                    total_chars += length\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        char_accuracy = correct_chars / total_chars\n",
    "        \n",
    "        print(f'Epoch {epoch}:')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Character Accuracy: {char_accuracy:.4f}')\n",
    "        \n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "       \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_ocr_model.pth')\n",
    "\n",
    "def decode_prediction(pred_indices, blank_label=0):\n",
    "    \n",
    "    print(\"Raw indices:\", pred_indices)\n",
    "    \n",
    "    previous = blank_label\n",
    "    decoded = []\n",
    "    for idx in pred_indices:\n",
    "        if idx != previous and idx != blank_label:\n",
    "            decoded.append(idx)\n",
    "        previous = idx\n",
    "        \n",
    "    print(\"Decoded indices:\", decoded)\n",
    "    \n",
    "    result = ''.join([string.ascii_lowercase[idx-1] if idx > 0 else '' for idx in decoded])\n",
    "    return result\n",
    "\n",
    "def visualize_predictions(model, test_loader, device, num_examples=5):\n",
    "    model.eval()\n",
    "   \n",
    "    images, targets, lengths = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        pred_indices = outputs.argmax(dim=-1)\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(num_examples, 1, figsize=(15, 3*num_examples))\n",
    "    if num_examples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "       \n",
    "        img = images[i].cpu().squeeze().numpy()\n",
    "        img = (img * 0.5 + 0.5)  \n",
    "      \n",
    "        true_text = ''.join([string.ascii_lowercase[idx-1] for idx in targets[i][:lengths[i]]])\n",
    "        pred_text = decode_prediction(pred_indices[i].cpu().numpy())\n",
    "       \n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'True: {true_text}\\nPredicted: {pred_text}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_accuracy(pred_indices, target_indices, target_length):\n",
    "    \n",
    "    decoded_pred = []\n",
    "    previous = 0  # blank\n",
    "    for idx in pred_indices:\n",
    "        if idx != previous and idx != 0:\n",
    "            decoded_pred.append(idx)\n",
    "        previous = idx\n",
    "  \n",
    "    target = target_indices[:target_length].tolist()\n",
    "  \n",
    "    pred_text = ''.join([string.ascii_lowercase[idx-1] if idx > 0 else '' for idx in decoded_pred])\n",
    "    true_text = ''.join([string.ascii_lowercase[idx-1] if idx > 0 else '' for idx in target])\n",
    "    \n",
    "    correct_chars = sum(1 for p, t in zip(pred_text, true_text) if p == t)\n",
    "    total_chars = len(true_text)\n",
    "    \n",
    "    return correct_chars, total_chars, pred_text, true_text\n",
    "\n",
    "def load_and_test_model():\n",
    "    test_words = random.sample([word for word in words.words() if word.isalpha()], 1000)\n",
    "    test_dataset = WordImageDataset(test_words)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    model = OCRModel()\n",
    "    model.load_state_dict(torch.load('best_ocr_model.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    word_correct = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    print(\"\\nSample predictions:\")\n",
    "    with torch.no_grad():\n",
    "        for images, targets, target_lengths in test_loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_indices = outputs.argmax(dim=-1)\n",
    "            \n",
    "            for i in range(len(targets)):\n",
    "                curr_correct, curr_total, pred_text, true_text = calculate_accuracy(\n",
    "                    pred_indices[i].cpu().numpy(),\n",
    "                    targets[i],\n",
    "                    target_lengths[i]\n",
    "                )\n",
    "                \n",
    "                correct_chars += curr_correct\n",
    "                total_chars += curr_total\n",
    "                \n",
    "                if pred_text == true_text:\n",
    "                    word_correct += 1\n",
    "                total_words += 1\n",
    "                \n",
    "                if i < 5:\n",
    "                    print(f\"\\nTrue: {true_text}\")\n",
    "                    print(f\"Pred: {pred_text}\")\n",
    "                    print(f\"Character accuracy: {curr_correct}/{curr_total}\")\n",
    "    \n",
    "    char_accuracy = correct_chars / total_chars\n",
    "    word_accuracy = word_correct / total_words\n",
    "    \n",
    "    print(f'\\nOverall Character Accuracy: {char_accuracy:.4f}')\n",
    "    print(f'Overall Word Accuracy: {word_accuracy:.4f}')\n",
    "    print(f'Total correct words: {word_correct}/{total_words}')\n",
    "    \n",
    "    # Visualize some examples\n",
    "    visualize_predictions(model, test_loader, device)\n",
    "\n",
    "\n",
    "def random_baseline_accuracy(test_loader):\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    word_correct = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    print(\"\\nRandom Baseline Predictions:\")\n",
    "    \n",
    "    for _, targets, target_lengths in test_loader:\n",
    "        for i in range(len(targets)):\n",
    "            true_text = ''.join([string.ascii_lowercase[idx-1] for idx in targets[i][:target_lengths[i]]])\n",
    "            # Generate random prediction of same length\n",
    "            random_pred = ''.join(random.choice(string.ascii_lowercase) for _ in range(len(true_text)))\n",
    "            \n",
    "            # Calculate character accuracy\n",
    "            correct_chars += sum(1 for p, t in zip(random_pred, true_text) if p == t)\n",
    "            total_chars += len(true_text)\n",
    "            \n",
    "            # Calculate word accuracy\n",
    "            if random_pred == true_text:\n",
    "                word_correct += 1\n",
    "            total_words += 1\n",
    "            \n",
    "            # Print some sample predictions (first 5 of each batch)\n",
    "            if i < 5:\n",
    "                print(f\"\\nTrue: {true_text}\")\n",
    "                print(f\"Random: {random_pred}\")\n",
    "                print(f\"Character matches: {sum(1 for p, t in zip(random_pred, true_text) if p == t)}/{len(true_text)}\")\n",
    "    \n",
    "    char_accuracy = correct_chars / total_chars\n",
    "    word_accuracy = word_correct / total_words\n",
    "    \n",
    "    print(f'\\nRandom Baseline Results:')\n",
    "    print(f'Character Accuracy: {char_accuracy:.4f}')\n",
    "    print(f'Word Accuracy: {word_accuracy:.4f}')\n",
    "    print(f'Total correct words: {word_correct}/{total_words}')\n",
    "    \n",
    "    return char_accuracy, word_accuracy\n",
    "\n",
    "def compare_with_baseline():\n",
    "    # Create test dataset\n",
    "    test_words = random.sample([word for word in words.words() if word.isalpha()], 1000)\n",
    "    test_dataset = WordImageDataset(test_words)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Get model predictions\n",
    "    model = OCRModel()\n",
    "    model.load_state_dict(torch.load('best_ocr_model.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    model_correct_chars = 0\n",
    "    model_total_chars = 0\n",
    "    model_word_correct = 0\n",
    "    model_total_words = 0\n",
    "    \n",
    "    print(\"Model Predictions:\")\n",
    "    with torch.no_grad():\n",
    "        for images, targets, target_lengths in test_loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_indices = outputs.argmax(dim=-1)\n",
    "            \n",
    "            for i in range(len(targets)):\n",
    "                curr_correct, curr_total, pred_text, true_text = calculate_accuracy(\n",
    "                    pred_indices[i].cpu().numpy(),\n",
    "                    targets[i],\n",
    "                    target_lengths[i]\n",
    "                )\n",
    "                \n",
    "                model_correct_chars += curr_correct\n",
    "                model_total_chars += curr_total\n",
    "                \n",
    "                if pred_text == true_text:\n",
    "                    model_word_correct += 1\n",
    "                model_total_words += 1\n",
    "                \n",
    "                if i < 5:\n",
    "                    print(f\"\\nTrue: {true_text}\")\n",
    "                    print(f\"Pred: {pred_text}\")\n",
    "                    print(f\"Character matches: {curr_correct}/{curr_total}\")\n",
    "    \n",
    "    model_char_accuracy = model_correct_chars / model_total_chars\n",
    "    model_word_accuracy = model_word_correct / model_total_words\n",
    "    \n",
    "    print(f'\\nModel Results:')\n",
    "    print(f'Character Accuracy: {model_char_accuracy:.4f}')\n",
    "    print(f'Word Accuracy: {model_word_accuracy:.4f}')\n",
    "    print(f'Total correct words: {model_word_correct}/{model_total_words}')\n",
    "    \n",
    "    # Get random baseline predictions\n",
    "    print('\\n' + '='*50)\n",
    "    baseline_char_accuracy, baseline_word_accuracy = random_baseline_accuracy(test_loader)\n",
    "    \n",
    "    # Compare results\n",
    "    print('\\n' + '='*50)\n",
    "    print('Comparison Summary:')\n",
    "    print(f'Character Accuracy - Model: {model_char_accuracy:.4f}, Random: {baseline_char_accuracy:.4f}')\n",
    "    print(f'Character Accuracy Improvement: {(model_char_accuracy - baseline_char_accuracy):.4f}')\n",
    "    print(f'Word Accuracy - Model: {model_word_accuracy:.4f}, Random: {baseline_word_accuracy:.4f}')\n",
    "    print(f'Word Accuracy Improvement: {(model_word_accuracy - baseline_word_accuracy):.4f}')\n",
    "\n",
    "\n",
    "\n",
    "compare_with_baseline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
