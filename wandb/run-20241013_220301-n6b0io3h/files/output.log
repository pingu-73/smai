Epoch 0, Training loss: 1.0481, Validation loss: 0.8292
Epoch 1, Training loss: 0.6117, Validation loss: 0.5123
Epoch 2, Training loss: 0.5432, Validation loss: 0.4820
Epoch 3, Training loss: 0.5274, Validation loss: 0.4731
Epoch 4, Training loss: 0.5232, Validation loss: 0.4649
Epoch 5, Training loss: 0.5145, Validation loss: 0.4745
Epoch 6, Training loss: 0.5115, Validation loss: 0.4744
Epoch 7, Training loss: 0.5076, Validation loss: 0.4645
Epoch 8, Training loss: 0.5061, Validation loss: 0.4615
Epoch 9, Training loss: 0.5039, Validation loss: 0.4633
Epoch 10, Training loss: 0.5032, Validation loss: 0.4610
Epoch 11, Training loss: 0.5019, Validation loss: 0.4614
Epoch 12, Training loss: 0.5023, Validation loss: 0.4721
Epoch 13, Training loss: 0.5000, Validation loss: 0.4640
Epoch 14, Training loss: 0.4995, Validation loss: 0.4617
Epoch 15, Training loss: 0.4993, Validation loss: 0.4595
Epoch 16, Training loss: 0.4984, Validation loss: 0.4650
Epoch 17, Training loss: 0.4977, Validation loss: 0.4624
Epoch 18, Training loss: 0.4974, Validation loss: 0.4609
Epoch 19, Training loss: 0.4970, Validation loss: 0.4627
Epoch 20, Training loss: 0.4969, Validation loss: 0.4603
Epoch 21, Training loss: 0.4980, Validation loss: 0.4656
Epoch 22, Training loss: 0.4964, Validation loss: 0.4600
Epoch 23, Training loss: 0.4987, Validation loss: 0.4546
Epoch 24, Training loss: 0.4958, Validation loss: 0.4584
Epoch 25, Training loss: 0.4982, Validation loss: 0.4547
Epoch 26, Training loss: 0.4956, Validation loss: 0.4572
Epoch 27, Training loss: 0.4952, Validation loss: 0.4700
Epoch 28, Training loss: 0.4939, Validation loss: 0.4608
Epoch 29, Training loss: 0.4936, Validation loss: 0.4628
Epoch 30, Training loss: 0.4937, Validation loss: 0.4598
Epoch 31, Training loss: 0.4934, Validation loss: 0.4610
Epoch 32, Training loss: 0.4931, Validation loss: 0.4659
Epoch 33, Training loss: 0.4931, Validation loss: 0.4587
Early stopping.
Epoch 0, Training loss: 0.7413, Validation loss: 0.6311
Epoch 1, Training loss: 0.6182, Validation loss: 0.5246
Epoch 2, Training loss: 0.5765, Validation loss: 0.4901
Epoch 3, Training loss: 0.5555, Validation loss: 0.4733
Epoch 4, Training loss: 0.5413, Validation loss: 0.4643
Epoch 5, Training loss: 0.5316, Validation loss: 0.4578
Epoch 6, Training loss: 0.5231, Validation loss: 0.4583
Epoch 7, Training loss: 0.5164, Validation loss: 0.4522
Epoch 8, Training loss: 0.5112, Validation loss: 0.4508
Epoch 9, Training loss: 0.5095, Validation loss: 0.4571
Epoch 10, Training loss: 0.5038, Validation loss: 0.4501
Epoch 11, Training loss: 0.5007, Validation loss: 0.4465
Epoch 12, Training loss: 0.4981, Validation loss: 0.4456
Epoch 13, Training loss: 0.5041, Validation loss: 0.4587
Epoch 14, Training loss: 0.4945, Validation loss: 0.4446
Epoch 15, Training loss: 0.4918, Validation loss: 0.4409
Epoch 16, Training loss: 0.4935, Validation loss: 0.4371
Epoch 17, Training loss: 0.4885, Validation loss: 0.4417
Epoch 18, Training loss: 0.4867, Validation loss: 0.4390
Epoch 19, Training loss: 0.4855, Validation loss: 0.4392
Epoch 20, Training loss: 0.4846, Validation loss: 0.4381
Epoch 21, Training loss: 0.4839, Validation loss: 0.4385
Epoch 22, Training loss: 0.4828, Validation loss: 0.4374
Epoch 23, Training loss: 0.4821, Validation loss: 0.4420
Epoch 24, Training loss: 0.4806, Validation loss: 0.4366
Epoch 25, Training loss: 0.4796, Validation loss: 0.4371
Epoch 26, Training loss: 0.4811, Validation loss: 0.4338
Epoch 27, Training loss: 0.4796, Validation loss: 0.4342
Epoch 28, Training loss: 0.4808, Validation loss: 0.4321
Epoch 29, Training loss: 0.4797, Validation loss: 0.4316
Epoch 30, Training loss: 0.4771, Validation loss: 0.4329
Epoch 31, Training loss: 0.4764, Validation loss: 0.4337
Epoch 32, Training loss: 0.4762, Validation loss: 0.4334
Epoch 33, Training loss: 0.4753, Validation loss: 0.4347
Epoch 34, Training loss: 0.4749, Validation loss: 0.4370
Epoch 35, Training loss: 0.4753, Validation loss: 0.4386
Epoch 36, Training loss: 0.4742, Validation loss: 0.4350
Epoch 37, Training loss: 0.4748, Validation loss: 0.4400
Epoch 38, Training loss: 0.4735, Validation loss: 0.4351
Epoch 39, Training loss: 0.4731, Validation loss: 0.4346
Early stopping.
Epoch 0, Training loss: 1.0855, Validation loss: 0.8421
Epoch 1, Training loss: 1.0836, Validation loss: 0.8398
Epoch 2, Training loss: 1.0820, Validation loss: 0.8379
Epoch 3, Training loss: 1.0806, Validation loss: 0.8361
Epoch 4, Training loss: 1.0799, Validation loss: 0.8350
Epoch 5, Training loss: 1.0793, Validation loss: 0.8341
Epoch 6, Training loss: 1.0788, Validation loss: 0.8334
Epoch 7, Training loss: 1.0783, Validation loss: 0.8329
Epoch 8, Training loss: 1.0779, Validation loss: 0.8324
Epoch 9, Training loss: 1.0775, Validation loss: 0.8321
Epoch 10, Training loss: 1.0772, Validation loss: 0.8318
Epoch 11, Training loss: 1.0769, Validation loss: 0.8316
Epoch 12, Training loss: 1.0766, Validation loss: 0.8313
Epoch 13, Training loss: 1.0763, Validation loss: 0.8311
Epoch 14, Training loss: 1.0762, Validation loss: 0.8301
Epoch 15, Training loss: 1.0760, Validation loss: 0.8302
Epoch 16, Training loss: 1.0758, Validation loss: 0.8303
Epoch 17, Training loss: 1.0756, Validation loss: 0.8303
Epoch 18, Training loss: 1.0754, Validation loss: 0.8304
Epoch 19, Training loss: 1.0752, Validation loss: 0.8305
Epoch 20, Training loss: 1.0750, Validation loss: 0.8305
Epoch 21, Training loss: 1.0748, Validation loss: 0.8306
Epoch 22, Training loss: 1.0747, Validation loss: 0.8305
Epoch 23, Training loss: 1.0745, Validation loss: 0.8306
Epoch 24, Training loss: 1.0743, Validation loss: 0.8306
Early stopping.
Epoch 0, Training loss: 0.4566, Validation loss: 0.3588
Epoch 1, Training loss: 0.4255, Validation loss: 0.3508
Epoch 2, Training loss: 0.4130, Validation loss: 0.3580
Epoch 3, Training loss: 0.4071, Validation loss: 0.3480
Epoch 4, Training loss: 0.4043, Validation loss: 0.3438
Epoch 5, Training loss: 0.4033, Validation loss: 0.3537
Epoch 6, Training loss: 0.4014, Validation loss: 0.3441
Epoch 7, Training loss: 0.4033, Validation loss: 0.3302
Epoch 8, Training loss: 0.4047, Validation loss: 0.3591
Epoch 9, Training loss: 0.4001, Validation loss: 0.3463
Epoch 10, Training loss: 0.3990, Validation loss: 0.3378
Epoch 11, Training loss: 0.3981, Validation loss: 0.3349
Epoch 12, Training loss: 0.4032, Validation loss: 0.3325
Epoch 13, Training loss: 0.4037, Validation loss: 0.3326
Epoch 14, Training loss: 0.3987, Validation loss: 0.3427
Epoch 15, Training loss: 0.3995, Validation loss: 0.3373
Epoch 16, Training loss: 0.3978, Validation loss: 0.3379
Epoch 17, Training loss: 0.4018, Validation loss: 0.3605
Early stopping.
Epoch 0, Training loss: 0.4760, Validation loss: 0.4445
Epoch 1, Training loss: 0.4516, Validation loss: 0.4472
Epoch 2, Training loss: 0.4306, Validation loss: 0.4104
Epoch 3, Training loss: 0.4178, Validation loss: 0.3768
Epoch 4, Training loss: 0.4084, Validation loss: 0.3468
Epoch 5, Training loss: 0.4051, Validation loss: 0.3570
Epoch 6, Training loss: 0.4024, Validation loss: 0.3462
Epoch 7, Training loss: 0.4040, Validation loss: 0.3329
Epoch 8, Training loss: 0.4018, Validation loss: 0.3307
Epoch 9, Training loss: 0.4098, Validation loss: 0.3716
Epoch 10, Training loss: 0.3999, Validation loss: 0.3382
Epoch 11, Training loss: 0.4064, Validation loss: 0.3367
Epoch 12, Training loss: 0.4004, Validation loss: 0.3456
Epoch 13, Training loss: 0.4196, Validation loss: 0.3193
Epoch 14, Training loss: 0.3977, Validation loss: 0.3350
Epoch 15, Training loss: 0.3976, Validation loss: 0.3268
Epoch 16, Training loss: 0.3963, Validation loss: 0.3351
Epoch 17, Training loss: 0.3985, Validation loss: 0.3407
Epoch 18, Training loss: 0.3988, Validation loss: 0.3351
Epoch 19, Training loss: 0.3999, Validation loss: 0.3355
Epoch 20, Training loss: 0.3994, Validation loss: 0.3378
Epoch 21, Training loss: 0.4014, Validation loss: 0.3309
Epoch 22, Training loss: 0.3993, Validation loss: 0.3379
Epoch 23, Training loss: 0.4014, Validation loss: 0.3316
Early stopping.
Epoch 0, Training loss: 0.4989, Validation loss: 0.4108
Epoch 1, Training loss: 0.4517, Validation loss: 0.3576
Epoch 2, Training loss: 0.4310, Validation loss: 0.3597
Epoch 3, Training loss: 0.4236, Validation loss: 0.3659
Epoch 4, Training loss: 0.4174, Validation loss: 0.3516
Epoch 5, Training loss: 0.4139, Validation loss: 0.3458
Epoch 6, Training loss: 0.4133, Validation loss: 0.3504
Epoch 7, Training loss: 0.4099, Validation loss: 0.3761
Epoch 8, Training loss: 0.4131, Validation loss: 0.3499
Epoch 9, Training loss: 0.4043, Validation loss: 0.3621
Epoch 10, Training loss: 0.4035, Validation loss: 0.3475
Epoch 11, Training loss: 0.4018, Validation loss: 0.3515
Epoch 12, Training loss: 0.3992, Validation loss: 0.3516
Epoch 13, Training loss: 0.3988, Validation loss: 0.3489
Epoch 14, Training loss: 0.4067, Validation loss: 0.3837
Epoch 15, Training loss: 0.3986, Validation loss: 0.3470
Early stopping.
Epoch 0, Training loss: 1.1303, Validation loss: 0.8430
Epoch 1, Training loss: 1.0019, Validation loss: 0.7335
Epoch 2, Training loss: 0.9120, Validation loss: 0.6726
Epoch 3, Training loss: 0.8403, Validation loss: 0.6299
Epoch 4, Training loss: 0.7910, Validation loss: 0.6002
Epoch 5, Training loss: 0.7532, Validation loss: 0.5774
Epoch 6, Training loss: 0.7242, Validation loss: 0.5612
Epoch 7, Training loss: 0.7003, Validation loss: 0.5487
Epoch 8, Training loss: 0.6798, Validation loss: 0.5385
Epoch 9, Training loss: 0.6636, Validation loss: 0.5299
Epoch 10, Training loss: 0.6503, Validation loss: 0.5225
Epoch 11, Training loss: 0.6392, Validation loss: 0.5163
Epoch 12, Training loss: 0.6295, Validation loss: 0.5109
Epoch 13, Training loss: 0.6208, Validation loss: 0.5063
Epoch 14, Training loss: 0.6130, Validation loss: 0.5022
Epoch 15, Training loss: 0.6062, Validation loss: 0.4985
Epoch 16, Training loss: 0.6001, Validation loss: 0.4952
Epoch 17, Training loss: 0.5945, Validation loss: 0.4921
Epoch 18, Training loss: 0.5895, Validation loss: 0.4899
Epoch 19, Training loss: 0.5847, Validation loss: 0.4873
Epoch 20, Training loss: 0.5789, Validation loss: 0.4841
Epoch 21, Training loss: 0.5749, Validation loss: 0.4825
Epoch 22, Training loss: 0.5706, Validation loss: 0.4802
Epoch 23, Training loss: 0.5676, Validation loss: 0.4785
Epoch 24, Training loss: 0.5648, Validation loss: 0.4768
Epoch 25, Training loss: 0.5621, Validation loss: 0.4754
Epoch 26, Training loss: 0.5597, Validation loss: 0.4739
Epoch 27, Training loss: 0.5568, Validation loss: 0.4727
Epoch 28, Training loss: 0.5546, Validation loss: 0.4711
Epoch 29, Training loss: 0.5526, Validation loss: 0.4700
Epoch 30, Training loss: 0.5506, Validation loss: 0.4687
Epoch 31, Training loss: 0.5488, Validation loss: 0.4677
Epoch 32, Training loss: 0.5469, Validation loss: 0.4666
Epoch 33, Training loss: 0.5450, Validation loss: 0.4650
Epoch 34, Training loss: 0.5436, Validation loss: 0.4642
Epoch 35, Training loss: 0.5423, Validation loss: 0.4634
Epoch 36, Training loss: 0.5410, Validation loss: 0.4627
Epoch 37, Training loss: 0.5395, Validation loss: 0.4621
Epoch 38, Training loss: 0.5381, Validation loss: 0.4610
Epoch 39, Training loss: 0.5367, Validation loss: 0.4611
Epoch 40, Training loss: 0.5356, Validation loss: 0.4604
Epoch 41, Training loss: 0.5346, Validation loss: 0.4598
Epoch 42, Training loss: 0.5337, Validation loss: 0.4589
Epoch 43, Training loss: 0.5327, Validation loss: 0.4577
Epoch 44, Training loss: 0.5317, Validation loss: 0.4572
Epoch 45, Training loss: 0.5307, Validation loss: 0.4569
Epoch 46, Training loss: 0.5298, Validation loss: 0.4563
Epoch 47, Training loss: 0.5290, Validation loss: 0.4557
Epoch 48, Training loss: 0.5281, Validation loss: 0.4552
Epoch 49, Training loss: 0.5272, Validation loss: 0.4548
Epoch 50, Training loss: 0.5264, Validation loss: 0.4542
Epoch 51, Training loss: 0.5257, Validation loss: 0.4539
Epoch 52, Training loss: 0.5249, Validation loss: 0.4536
Epoch 53, Training loss: 0.5242, Validation loss: 0.4535
Epoch 54, Training loss: 0.5234, Validation loss: 0.4527
Epoch 55, Training loss: 0.5228, Validation loss: 0.4523
Epoch 56, Training loss: 0.5221, Validation loss: 0.4518
Epoch 57, Training loss: 0.5215, Validation loss: 0.4511
Epoch 58, Training loss: 0.5208, Validation loss: 0.4507
Epoch 59, Training loss: 0.5201, Validation loss: 0.4507
Epoch 60, Training loss: 0.5195, Validation loss: 0.4500
Epoch 61, Training loss: 0.5189, Validation loss: 0.4491
Epoch 62, Training loss: 0.5183, Validation loss: 0.4488
Epoch 63, Training loss: 0.5177, Validation loss: 0.4485
Epoch 64, Training loss: 0.5171, Validation loss: 0.4483
Epoch 65, Training loss: 0.5166, Validation loss: 0.4481
Epoch 66, Training loss: 0.5160, Validation loss: 0.4477
Epoch 67, Training loss: 0.5155, Validation loss: 0.4475
Epoch 68, Training loss: 0.5149, Validation loss: 0.4472
Epoch 69, Training loss: 0.5144, Validation loss: 0.4469
Epoch 70, Training loss: 0.5138, Validation loss: 0.4470
Epoch 71, Training loss: 0.5133, Validation loss: 0.4466
Epoch 72, Training loss: 0.5132, Validation loss: 0.4466
Epoch 73, Training loss: 0.5127, Validation loss: 0.4465
Epoch 74, Training loss: 0.5125, Validation loss: 0.4468
Epoch 75, Training loss: 0.5120, Validation loss: 0.4464
Epoch 76, Training loss: 0.5115, Validation loss: 0.4462
Epoch 77, Training loss: 0.5110, Validation loss: 0.4460
Epoch 78, Training loss: 0.5106, Validation loss: 0.4458
Epoch 79, Training loss: 0.5100, Validation loss: 0.4457
Epoch 80, Training loss: 0.5095, Validation loss: 0.4456
Epoch 81, Training loss: 0.5089, Validation loss: 0.4447
Epoch 82, Training loss: 0.5085, Validation loss: 0.4446
Epoch 83, Training loss: 0.5081, Validation loss: 0.4445
Epoch 84, Training loss: 0.5077, Validation loss: 0.4444
Epoch 85, Training loss: 0.5073, Validation loss: 0.4441
Epoch 86, Training loss: 0.5069, Validation loss: 0.4438
Epoch 87, Training loss: 0.5064, Validation loss: 0.4437
Epoch 88, Training loss: 0.5060, Validation loss: 0.4434
Epoch 89, Training loss: 0.5057, Validation loss: 0.4431
Epoch 90, Training loss: 0.5052, Validation loss: 0.4430
Epoch 91, Training loss: 0.5048, Validation loss: 0.4428
Epoch 92, Training loss: 0.5045, Validation loss: 0.4425
Epoch 93, Training loss: 0.5042, Validation loss: 0.4424
Epoch 94, Training loss: 0.5038, Validation loss: 0.4421
Epoch 95, Training loss: 0.5035, Validation loss: 0.4420
Epoch 96, Training loss: 0.5032, Validation loss: 0.4419
Epoch 97, Training loss: 0.5028, Validation loss: 0.4418
Epoch 98, Training loss: 0.5025, Validation loss: 0.4417
Epoch 99, Training loss: 0.5022, Validation loss: 0.4415
Epoch 100, Training loss: 0.5019, Validation loss: 0.4413
Epoch 101, Training loss: 0.5019, Validation loss: 0.4414
Epoch 102, Training loss: 0.5017, Validation loss: 0.4412
Epoch 103, Training loss: 0.5014, Validation loss: 0.4411
Epoch 104, Training loss: 0.5011, Validation loss: 0.4409
Epoch 105, Training loss: 0.5008, Validation loss: 0.4409
Epoch 106, Training loss: 0.5005, Validation loss: 0.4407
Epoch 107, Training loss: 0.5002, Validation loss: 0.4407
Epoch 108, Training loss: 0.4999, Validation loss: 0.4406
Epoch 109, Training loss: 0.4996, Validation loss: 0.4406
Epoch 110, Training loss: 0.4994, Validation loss: 0.4405
Epoch 111, Training loss: 0.4990, Validation loss: 0.4407
Epoch 112, Training loss: 0.4987, Validation loss: 0.4406
Epoch 113, Training loss: 0.4984, Validation loss: 0.4407
Epoch 114, Training loss: 0.4981, Validation loss: 0.4406
Epoch 115, Training loss: 0.4979, Validation loss: 0.4407
Epoch 116, Training loss: 0.4976, Validation loss: 0.4405
Epoch 117, Training loss: 0.4974, Validation loss: 0.4405
Epoch 118, Training loss: 0.4972, Validation loss: 0.4402
Epoch 119, Training loss: 0.4970, Validation loss: 0.4401
Epoch 120, Training loss: 0.4967, Validation loss: 0.4402
Epoch 121, Training loss: 0.4965, Validation loss: 0.4399
Epoch 122, Training loss: 0.4961, Validation loss: 0.4400
Epoch 123, Training loss: 0.4959, Validation loss: 0.4400
Epoch 124, Training loss: 0.4957, Validation loss: 0.4398
Epoch 125, Training loss: 0.4954, Validation loss: 0.4398
Epoch 126, Training loss: 0.4951, Validation loss: 0.4399
Epoch 127, Training loss: 0.4949, Validation loss: 0.4397
Epoch 128, Training loss: 0.4947, Validation loss: 0.4396
Epoch 129, Training loss: 0.4946, Validation loss: 0.4392
Epoch 130, Training loss: 0.4944, Validation loss: 0.4390
Epoch 131, Training loss: 0.4941, Validation loss: 0.4392
Epoch 132, Training loss: 0.4939, Validation loss: 0.4393
Epoch 133, Training loss: 0.4938, Validation loss: 0.4391
Epoch 134, Training loss: 0.4936, Validation loss: 0.4386
Epoch 135, Training loss: 0.4934, Validation loss: 0.4384
Epoch 136, Training loss: 0.4932, Validation loss: 0.4385
Epoch 137, Training loss: 0.4929, Validation loss: 0.4384
Epoch 138, Training loss: 0.4927, Validation loss: 0.4384
Epoch 139, Training loss: 0.4926, Validation loss: 0.4381
Epoch 140, Training loss: 0.4925, Validation loss: 0.4378
Epoch 141, Training loss: 0.4922, Validation loss: 0.4379
Epoch 142, Training loss: 0.4920, Validation loss: 0.4374
Epoch 143, Training loss: 0.4917, Validation loss: 0.4375
Epoch 144, Training loss: 0.4915, Validation loss: 0.4374
Epoch 145, Training loss: 0.4914, Validation loss: 0.4372
Epoch 146, Training loss: 0.4912, Validation loss: 0.4371
Epoch 147, Training loss: 0.4910, Validation loss: 0.4373
Epoch 148, Training loss: 0.4909, Validation loss: 0.4371
Epoch 149, Training loss: 0.4907, Validation loss: 0.4370
Epoch 150, Training loss: 0.4906, Validation loss: 0.4369
Epoch 151, Training loss: 0.4905, Validation loss: 0.4367
Epoch 152, Training loss: 0.4904, Validation loss: 0.4365
Epoch 153, Training loss: 0.4902, Validation loss: 0.4367
Epoch 154, Training loss: 0.4900, Validation loss: 0.4368
Epoch 155, Training loss: 0.4899, Validation loss: 0.4368
Epoch 156, Training loss: 0.4898, Validation loss: 0.4366
Epoch 157, Training loss: 0.4896, Validation loss: 0.4366
Epoch 158, Training loss: 0.4895, Validation loss: 0.4364
Epoch 159, Training loss: 0.4894, Validation loss: 0.4361
Epoch 160, Training loss: 0.4893, Validation loss: 0.4359
Epoch 161, Training loss: 0.4892, Validation loss: 0.4359
Epoch 162, Training loss: 0.4891, Validation loss: 0.4358
Epoch 163, Training loss: 0.4888, Validation loss: 0.4359
Epoch 164, Training loss: 0.4887, Validation loss: 0.4358
Epoch 165, Training loss: 0.4886, Validation loss: 0.4357
Epoch 166, Training loss: 0.4885, Validation loss: 0.4355
Epoch 167, Training loss: 0.4884, Validation loss: 0.4355
Epoch 168, Training loss: 0.4883, Validation loss: 0.4354
Epoch 169, Training loss: 0.4882, Validation loss: 0.4353
Epoch 170, Training loss: 0.4880, Validation loss: 0.4355
Epoch 171, Training loss: 0.4879, Validation loss: 0.4355
Epoch 172, Training loss: 0.4878, Validation loss: 0.4354
Epoch 173, Training loss: 0.4877, Validation loss: 0.4354
Epoch 174, Training loss: 0.4876, Validation loss: 0.4354
Epoch 175, Training loss: 0.4875, Validation loss: 0.4353
Epoch 176, Training loss: 0.4875, Validation loss: 0.4353
Epoch 177, Training loss: 0.4872, Validation loss: 0.4354
Epoch 178, Training loss: 0.4870, Validation loss: 0.4349
Epoch 179, Training loss: 0.4869, Validation loss: 0.4349
Epoch 180, Training loss: 0.4868, Validation loss: 0.4348
Epoch 181, Training loss: 0.4867, Validation loss: 0.4347
Epoch 182, Training loss: 0.4867, Validation loss: 0.4344
Epoch 183, Training loss: 0.4866, Validation loss: 0.4345
Epoch 184, Training loss: 0.4865, Validation loss: 0.4345
Epoch 185, Training loss: 0.4864, Validation loss: 0.4342
Epoch 186, Training loss: 0.4863, Validation loss: 0.4342
Epoch 187, Training loss: 0.4862, Validation loss: 0.4343
Epoch 188, Training loss: 0.4862, Validation loss: 0.4342
Epoch 189, Training loss: 0.4860, Validation loss: 0.4343
Epoch 190, Training loss: 0.4859, Validation loss: 0.4341
Epoch 191, Training loss: 0.4858, Validation loss: 0.4341
Epoch 192, Training loss: 0.4858, Validation loss: 0.4340
Epoch 193, Training loss: 0.4857, Validation loss: 0.4339
Epoch 194, Training loss: 0.4856, Validation loss: 0.4338
Epoch 195, Training loss: 0.4855, Validation loss: 0.4338
Epoch 196, Training loss: 0.4854, Validation loss: 0.4339
Epoch 197, Training loss: 0.4851, Validation loss: 0.4342
Epoch 198, Training loss: 0.4850, Validation loss: 0.4343
Epoch 199, Training loss: 0.4848, Validation loss: 0.4345
Epoch 200, Training loss: 0.4848, Validation loss: 0.4343
Epoch 201, Training loss: 0.4847, Validation loss: 0.4342
Epoch 202, Training loss: 0.4847, Validation loss: 0.4343
Epoch 203, Training loss: 0.4846, Validation loss: 0.4341
Epoch 204, Training loss: 0.4845, Validation loss: 0.4340
Epoch 205, Training loss: 0.4845, Validation loss: 0.4340
Early stopping.
Epoch 0, Training loss: 1.1326, Validation loss: 0.8330
Epoch 1, Training loss: 1.1209, Validation loss: 0.8265
Epoch 2, Training loss: 1.1082, Validation loss: 0.8205
Epoch 3, Training loss: 1.1005, Validation loss: 0.8179
Epoch 4, Training loss: 1.0945, Validation loss: 0.8161
Epoch 5, Training loss: 1.0899, Validation loss: 0.8146
Epoch 6, Training loss: 1.0857, Validation loss: 0.8131
Epoch 7, Training loss: 1.0834, Validation loss: 0.8123
Epoch 8, Training loss: 1.0815, Validation loss: 0.8118
Epoch 9, Training loss: 1.0797, Validation loss: 0.8115
Epoch 10, Training loss: 1.0782, Validation loss: 0.8113
Epoch 11, Training loss: 1.0769, Validation loss: 0.8111
Epoch 12, Training loss: 1.0758, Validation loss: 0.8111
Epoch 13, Training loss: 1.0748, Validation loss: 0.8110
Epoch 14, Training loss: 1.0737, Validation loss: 0.8111
Epoch 15, Training loss: 1.0732, Validation loss: 0.8111
Epoch 16, Training loss: 1.0729, Validation loss: 0.8110
Epoch 17, Training loss: 1.0726, Validation loss: 0.8109
Epoch 18, Training loss: 1.0724, Validation loss: 0.8108
Epoch 19, Training loss: 1.0722, Validation loss: 0.8107
Epoch 20, Training loss: 1.0721, Validation loss: 0.8107
Epoch 21, Training loss: 1.0720, Validation loss: 0.8106
Epoch 22, Training loss: 1.0719, Validation loss: 0.8105
Epoch 23, Training loss: 1.0717, Validation loss: 0.8104
Epoch 24, Training loss: 1.0716, Validation loss: 0.8103
Epoch 25, Training loss: 1.0715, Validation loss: 0.8102
Epoch 26, Training loss: 1.0714, Validation loss: 0.8101
Epoch 27, Training loss: 1.0712, Validation loss: 0.8100
Epoch 28, Training loss: 1.0711, Validation loss: 0.8099
Epoch 29, Training loss: 1.0710, Validation loss: 0.8098
Epoch 30, Training loss: 1.0709, Validation loss: 0.8097
Epoch 31, Training loss: 1.0707, Validation loss: 0.8098
Epoch 32, Training loss: 1.0706, Validation loss: 0.8097
Epoch 33, Training loss: 1.0705, Validation loss: 0.8096
Epoch 34, Training loss: 1.0704, Validation loss: 0.8095
Epoch 35, Training loss: 1.0703, Validation loss: 0.8094
Epoch 36, Training loss: 1.0702, Validation loss: 0.8093
Epoch 37, Training loss: 1.0701, Validation loss: 0.8094
Epoch 38, Training loss: 1.0699, Validation loss: 0.8093
Epoch 39, Training loss: 1.0698, Validation loss: 0.8092
Epoch 40, Training loss: 1.0697, Validation loss: 0.8091
Epoch 41, Training loss: 1.0696, Validation loss: 0.8090
Epoch 42, Training loss: 1.0695, Validation loss: 0.8089
Epoch 43, Training loss: 1.0694, Validation loss: 0.8088
Epoch 44, Training loss: 1.0692, Validation loss: 0.8087
Epoch 45, Training loss: 1.0691, Validation loss: 0.8086
Epoch 46, Training loss: 1.0690, Validation loss: 0.8084
Epoch 47, Training loss: 1.0688, Validation loss: 0.8083
Epoch 48, Training loss: 1.0687, Validation loss: 0.8082
Epoch 49, Training loss: 1.0686, Validation loss: 0.8081
Epoch 50, Training loss: 1.0685, Validation loss: 0.8080
Epoch 51, Training loss: 1.0683, Validation loss: 0.8079
Epoch 52, Training loss: 1.0682, Validation loss: 0.8078
Epoch 53, Training loss: 1.0681, Validation loss: 0.8077
Epoch 54, Training loss: 1.0680, Validation loss: 0.8081
Epoch 55, Training loss: 1.0679, Validation loss: 0.8080
Epoch 56, Training loss: 1.0678, Validation loss: 0.8079
Epoch 57, Training loss: 1.0677, Validation loss: 0.8078
Epoch 58, Training loss: 1.0676, Validation loss: 0.8076
Epoch 59, Training loss: 1.0675, Validation loss: 0.8075
Epoch 60, Training loss: 1.0674, Validation loss: 0.8074
Epoch 61, Training loss: 1.0673, Validation loss: 0.8073
Epoch 62, Training loss: 1.0671, Validation loss: 0.8072
Epoch 63, Training loss: 1.0670, Validation loss: 0.8071
Epoch 64, Training loss: 1.0669, Validation loss: 0.8069
Epoch 65, Training loss: 1.0669, Validation loss: 0.8072
Epoch 66, Training loss: 1.0668, Validation loss: 0.8070
Epoch 67, Training loss: 1.0667, Validation loss: 0.8068
Epoch 68, Training loss: 1.0666, Validation loss: 0.8066
Epoch 69, Training loss: 1.0665, Validation loss: 0.8063
Epoch 70, Training loss: 1.0664, Validation loss: 0.8061
Epoch 71, Training loss: 1.0663, Validation loss: 0.8059
Epoch 72, Training loss: 1.0662, Validation loss: 0.8057
Epoch 73, Training loss: 1.0661, Validation loss: 0.8055
Epoch 74, Training loss: 1.0660, Validation loss: 0.8053
Epoch 75, Training loss: 1.0659, Validation loss: 0.8051
Epoch 76, Training loss: 1.0658, Validation loss: 0.8049
Epoch 77, Training loss: 1.0656, Validation loss: 0.8047
Epoch 78, Training loss: 1.0656, Validation loss: 0.8045
Epoch 79, Training loss: 1.0655, Validation loss: 0.8043
Epoch 80, Training loss: 1.0654, Validation loss: 0.8041
Epoch 81, Training loss: 1.0653, Validation loss: 0.8039
Epoch 82, Training loss: 1.0652, Validation loss: 0.8037
Epoch 83, Training loss: 1.0652, Validation loss: 0.8038
Epoch 84, Training loss: 1.0651, Validation loss: 0.8036
Epoch 85, Training loss: 1.0650, Validation loss: 0.8034
Epoch 86, Training loss: 1.0649, Validation loss: 0.8032
Epoch 87, Training loss: 1.0648, Validation loss: 0.8031
Epoch 88, Training loss: 1.0648, Validation loss: 0.8034
Epoch 89, Training loss: 1.0647, Validation loss: 0.8032
Epoch 90, Training loss: 1.0647, Validation loss: 0.8030
Epoch 91, Training loss: 1.0646, Validation loss: 0.8031
Epoch 92, Training loss: 1.0646, Validation loss: 0.8032
Epoch 93, Training loss: 1.0645, Validation loss: 0.8030
Epoch 94, Training loss: 1.0644, Validation loss: 0.8028
Epoch 95, Training loss: 1.0643, Validation loss: 0.8026
Epoch 96, Training loss: 1.0642, Validation loss: 0.8024
Epoch 97, Training loss: 1.0641, Validation loss: 0.8022
Epoch 98, Training loss: 1.0641, Validation loss: 0.8020
Epoch 99, Training loss: 1.0640, Validation loss: 0.8021
Epoch 100, Training loss: 1.0639, Validation loss: 0.8019
Epoch 101, Training loss: 1.0639, Validation loss: 0.8017
Epoch 102, Training loss: 1.0638, Validation loss: 0.8015
Epoch 103, Training loss: 1.0637, Validation loss: 0.8013
Epoch 104, Training loss: 1.0634, Validation loss: 0.8009
Epoch 105, Training loss: 1.0631, Validation loss: 0.8005
Epoch 106, Training loss: 1.0629, Validation loss: 0.8001
Epoch 107, Training loss: 1.0629, Validation loss: 0.8006
Epoch 108, Training loss: 1.0626, Validation loss: 0.8001
Epoch 109, Training loss: 1.0624, Validation loss: 0.7997
Epoch 110, Training loss: 1.0621, Validation loss: 0.7993
Epoch 111, Training loss: 1.0619, Validation loss: 0.7988
Epoch 112, Training loss: 1.0616, Validation loss: 0.7983
Epoch 113, Training loss: 1.0610, Validation loss: 0.7976
Epoch 114, Training loss: 1.0603, Validation loss: 0.7976
Epoch 115, Training loss: 1.0590, Validation loss: 0.7966
Epoch 116, Training loss: 1.0575, Validation loss: 0.7953
Epoch 117, Training loss: 1.0563, Validation loss: 0.7944
Epoch 118, Training loss: 1.0551, Validation loss: 0.7935
Epoch 119, Training loss: 1.0539, Validation loss: 0.7925
Epoch 120, Training loss: 1.0527, Validation loss: 0.7916
Epoch 121, Training loss: 1.0515, Validation loss: 0.7906
Epoch 122, Training loss: 1.0494, Validation loss: 0.7892
Epoch 123, Training loss: 1.0457, Validation loss: 0.7875
Epoch 124, Training loss: 1.0337, Validation loss: 0.7838
Epoch 125, Training loss: 1.0258, Validation loss: 0.7808
Epoch 126, Training loss: 1.0176, Validation loss: 0.7779
Epoch 127, Training loss: 1.0085, Validation loss: 0.7749
Epoch 128, Training loss: 0.9970, Validation loss: 0.7702
Epoch 129, Training loss: 0.9834, Validation loss: 0.7646
Epoch 130, Training loss: 0.9668, Validation loss: 0.7576
Epoch 131, Training loss: 0.9471, Validation loss: 0.7458
Epoch 132, Training loss: 0.9241, Validation loss: 0.7345
Epoch 133, Training loss: 0.8920, Validation loss: 0.7191
Epoch 134, Training loss: 0.8661, Validation loss: 0.7065
Epoch 135, Training loss: 0.8339, Validation loss: 0.6875
Epoch 136, Training loss: 0.8144, Validation loss: 0.6758
Epoch 137, Training loss: 0.7938, Validation loss: 0.6632
Epoch 138, Training loss: 0.7774, Validation loss: 0.6537
Epoch 139, Training loss: 0.7590, Validation loss: 0.6407
Epoch 140, Training loss: 0.7416, Validation loss: 0.6281
Epoch 141, Training loss: 0.7269, Validation loss: 0.6173
Epoch 142, Training loss: 0.7142, Validation loss: 0.6079
Epoch 143, Training loss: 0.6991, Validation loss: 0.5974
Epoch 144, Training loss: 0.6893, Validation loss: 0.5902
Epoch 145, Training loss: 0.6803, Validation loss: 0.5836
Epoch 146, Training loss: 0.6678, Validation loss: 0.5753
Epoch 147, Training loss: 0.6600, Validation loss: 0.5697
Epoch 148, Training loss: 0.6533, Validation loss: 0.5649
Epoch 149, Training loss: 0.6459, Validation loss: 0.5608
Epoch 150, Training loss: 0.6396, Validation loss: 0.5562
Epoch 151, Training loss: 0.6338, Validation loss: 0.5519
Epoch 152, Training loss: 0.6283, Validation loss: 0.5479
Epoch 153, Training loss: 0.6233, Validation loss: 0.5439
Epoch 154, Training loss: 0.6147, Validation loss: 0.5377
Epoch 155, Training loss: 0.6085, Validation loss: 0.5333
Epoch 156, Training loss: 0.6049, Validation loss: 0.5307
Epoch 157, Training loss: 0.6013, Validation loss: 0.5280
Epoch 158, Training loss: 0.5974, Validation loss: 0.5252
Epoch 159, Training loss: 0.5942, Validation loss: 0.5227
Epoch 160, Training loss: 0.5912, Validation loss: 0.5204
Epoch 161, Training loss: 0.5880, Validation loss: 0.5181
Epoch 162, Training loss: 0.5852, Validation loss: 0.5159
Epoch 163, Training loss: 0.5826, Validation loss: 0.5134
Epoch 164, Training loss: 0.5800, Validation loss: 0.5115
Epoch 165, Training loss: 0.5777, Validation loss: 0.5093
Epoch 166, Training loss: 0.5752, Validation loss: 0.5076
Epoch 167, Training loss: 0.5730, Validation loss: 0.5058
Epoch 168, Training loss: 0.5675, Validation loss: 0.5020
Epoch 169, Training loss: 0.5646, Validation loss: 0.5004
Epoch 170, Training loss: 0.5624, Validation loss: 0.4986
Epoch 171, Training loss: 0.5606, Validation loss: 0.4974
Epoch 172, Training loss: 0.5576, Validation loss: 0.4954
Epoch 173, Training loss: 0.5553, Validation loss: 0.4934
Epoch 174, Training loss: 0.5537, Validation loss: 0.4920
Epoch 175, Training loss: 0.5521, Validation loss: 0.4896
Epoch 176, Training loss: 0.5498, Validation loss: 0.4877
Epoch 177, Training loss: 0.5483, Validation loss: 0.4867
Epoch 178, Training loss: 0.5470, Validation loss: 0.4857
Epoch 179, Training loss: 0.5457, Validation loss: 0.4847
Epoch 180, Training loss: 0.5443, Validation loss: 0.4842
Epoch 181, Training loss: 0.5429, Validation loss: 0.4829
Epoch 182, Training loss: 0.5418, Validation loss: 0.4821
Epoch 183, Training loss: 0.5405, Validation loss: 0.4813
Epoch 184, Training loss: 0.5393, Validation loss: 0.4802
Epoch 185, Training loss: 0.5382, Validation loss: 0.4794
Epoch 186, Training loss: 0.5372, Validation loss: 0.4787
Epoch 187, Training loss: 0.5361, Validation loss: 0.4782
Epoch 188, Training loss: 0.5351, Validation loss: 0.4772
Epoch 189, Training loss: 0.5341, Validation loss: 0.4766
Epoch 190, Training loss: 0.5330, Validation loss: 0.4759
Epoch 191, Training loss: 0.5320, Validation loss: 0.4754
Epoch 192, Training loss: 0.5311, Validation loss: 0.4746
Epoch 193, Training loss: 0.5304, Validation loss: 0.4737
Epoch 194, Training loss: 0.5295, Validation loss: 0.4716
Epoch 195, Training loss: 0.5285, Validation loss: 0.4709
Epoch 196, Training loss: 0.5277, Validation loss: 0.4705
Epoch 197, Training loss: 0.5270, Validation loss: 0.4701
Epoch 198, Training loss: 0.5262, Validation loss: 0.4696
Epoch 199, Training loss: 0.5256, Validation loss: 0.4692
Epoch 200, Training loss: 0.5248, Validation loss: 0.4691
Epoch 201, Training loss: 0.5241, Validation loss: 0.4686
Epoch 202, Training loss: 0.5234, Validation loss: 0.4682
Epoch 203, Training loss: 0.5228, Validation loss: 0.4676
Epoch 204, Training loss: 0.5221, Validation loss: 0.4674
Epoch 205, Training loss: 0.5216, Validation loss: 0.4672
Epoch 206, Training loss: 0.5209, Validation loss: 0.4676
Epoch 207, Training loss: 0.5198, Validation loss: 0.4678
Epoch 208, Training loss: 0.5189, Validation loss: 0.4678
Epoch 209, Training loss: 0.5184, Validation loss: 0.4675
Epoch 210, Training loss: 0.5176, Validation loss: 0.4668
Epoch 211, Training loss: 0.5171, Validation loss: 0.4664
Epoch 212, Training loss: 0.5166, Validation loss: 0.4663
Epoch 213, Training loss: 0.5161, Validation loss: 0.4660
Epoch 214, Training loss: 0.5157, Validation loss: 0.4653
Epoch 215, Training loss: 0.5152, Validation loss: 0.4651
Epoch 216, Training loss: 0.5148, Validation loss: 0.4652
Epoch 217, Training loss: 0.5143, Validation loss: 0.4649
Epoch 218, Training loss: 0.5137, Validation loss: 0.4652
Epoch 219, Training loss: 0.5134, Validation loss: 0.4648
Epoch 220, Training loss: 0.5131, Validation loss: 0.4643
Epoch 221, Training loss: 0.5127, Validation loss: 0.4643
Epoch 222, Training loss: 0.5128, Validation loss: 0.4665
Epoch 223, Training loss: 0.5121, Validation loss: 0.4663
Epoch 224, Training loss: 0.5115, Validation loss: 0.4661
Epoch 225, Training loss: 0.5112, Validation loss: 0.4657
Epoch 226, Training loss: 0.5108, Validation loss: 0.4656
Epoch 227, Training loss: 0.5105, Validation loss: 0.4651
Epoch 228, Training loss: 0.5101, Validation loss: 0.4654
Epoch 229, Training loss: 0.5097, Validation loss: 0.4655
Epoch 230, Training loss: 0.5094, Validation loss: 0.4653
Epoch 231, Training loss: 0.5091, Validation loss: 0.4652
Early stopping.
Epoch 0, Training loss: 1.1511, Validation loss: 0.8832
Epoch 1, Training loss: 1.1469, Validation loss: 0.8795
Epoch 2, Training loss: 1.1430, Validation loss: 0.8760
Epoch 3, Training loss: 1.1345, Validation loss: 0.8687
Epoch 4, Training loss: 1.1315, Validation loss: 0.8658
Epoch 5, Training loss: 1.1286, Validation loss: 0.8631
Epoch 6, Training loss: 1.1258, Validation loss: 0.8605
Epoch 7, Training loss: 1.1231, Validation loss: 0.8581
Epoch 8, Training loss: 1.1204, Validation loss: 0.8558
Epoch 9, Training loss: 1.1178, Validation loss: 0.8536
Epoch 10, Training loss: 1.1154, Validation loss: 0.8516
Epoch 11, Training loss: 1.1131, Validation loss: 0.8497
Epoch 12, Training loss: 1.1111, Validation loss: 0.8480
Epoch 13, Training loss: 1.1093, Validation loss: 0.8463
Epoch 14, Training loss: 1.1076, Validation loss: 0.8447
Epoch 15, Training loss: 1.1058, Validation loss: 0.8432
Epoch 16, Training loss: 1.1042, Validation loss: 0.8416
Epoch 17, Training loss: 1.1008, Validation loss: 0.8385
Epoch 18, Training loss: 1.0993, Validation loss: 0.8370
Epoch 19, Training loss: 1.0978, Validation loss: 0.8356
Epoch 20, Training loss: 1.0961, Validation loss: 0.8344
Epoch 21, Training loss: 1.0949, Validation loss: 0.8336
Epoch 22, Training loss: 1.0937, Validation loss: 0.8329
Epoch 23, Training loss: 1.0925, Validation loss: 0.8322
Epoch 24, Training loss: 1.0914, Validation loss: 0.8315
Epoch 25, Training loss: 1.0903, Validation loss: 0.8308
Epoch 26, Training loss: 1.0893, Validation loss: 0.8303
Epoch 27, Training loss: 1.0883, Validation loss: 0.8302
Epoch 28, Training loss: 1.0875, Validation loss: 0.8300
Epoch 29, Training loss: 1.0867, Validation loss: 0.8299
Epoch 30, Training loss: 1.0858, Validation loss: 0.8296
Epoch 31, Training loss: 1.0854, Validation loss: 0.8295
Epoch 32, Training loss: 1.0847, Validation loss: 0.8293
Epoch 33, Training loss: 1.0844, Validation loss: 0.8293
Epoch 34, Training loss: 1.0841, Validation loss: 0.8293
Epoch 35, Training loss: 1.0839, Validation loss: 0.8292
Epoch 36, Training loss: 1.0838, Validation loss: 0.8292
Epoch 37, Training loss: 1.0836, Validation loss: 0.8292
Epoch 38, Training loss: 1.0834, Validation loss: 0.8292
Epoch 39, Training loss: 1.0833, Validation loss: 0.8291
Epoch 40, Training loss: 1.0831, Validation loss: 0.8291
Epoch 41, Training loss: 1.0822, Validation loss: 0.8290
Epoch 42, Training loss: 1.0822, Validation loss: 0.8290
Epoch 43, Training loss: 1.0821, Validation loss: 0.8290
Epoch 44, Training loss: 1.0820, Validation loss: 0.8290
Epoch 45, Training loss: 1.0819, Validation loss: 0.8290
Epoch 46, Training loss: 1.0818, Validation loss: 0.8290
Epoch 47, Training loss: 1.0818, Validation loss: 0.8289
Epoch 48, Training loss: 1.0817, Validation loss: 0.8289
Epoch 49, Training loss: 1.0816, Validation loss: 0.8289
Epoch 50, Training loss: 1.0815, Validation loss: 0.8289
Epoch 51, Training loss: 1.0814, Validation loss: 0.8289
Epoch 52, Training loss: 1.0813, Validation loss: 0.8289
Epoch 53, Training loss: 1.0813, Validation loss: 0.8288
Epoch 54, Training loss: 1.0812, Validation loss: 0.8288
Epoch 55, Training loss: 1.0811, Validation loss: 0.8288
Epoch 56, Training loss: 1.0811, Validation loss: 0.8288
Epoch 57, Training loss: 1.0810, Validation loss: 0.8288
Epoch 58, Training loss: 1.0809, Validation loss: 0.8288
Epoch 59, Training loss: 1.0808, Validation loss: 0.8288
Epoch 60, Training loss: 1.0808, Validation loss: 0.8287
Epoch 61, Training loss: 1.0807, Validation loss: 0.8287
Epoch 62, Training loss: 1.0806, Validation loss: 0.8287
Epoch 63, Training loss: 1.0806, Validation loss: 0.8287
Epoch 64, Training loss: 1.0805, Validation loss: 0.8287
Epoch 65, Training loss: 1.0804, Validation loss: 0.8287
Epoch 66, Training loss: 1.0804, Validation loss: 0.8287
Epoch 67, Training loss: 1.0803, Validation loss: 0.8287
Epoch 68, Training loss: 1.0802, Validation loss: 0.8286
Epoch 69, Training loss: 1.0802, Validation loss: 0.8286
Epoch 70, Training loss: 1.0801, Validation loss: 0.8286
Epoch 71, Training loss: 1.0801, Validation loss: 0.8286
Epoch 72, Training loss: 1.0800, Validation loss: 0.8286
Epoch 73, Training loss: 1.0800, Validation loss: 0.8286
Epoch 74, Training loss: 1.0800, Validation loss: 0.8285
Epoch 75, Training loss: 1.0799, Validation loss: 0.8285
Epoch 76, Training loss: 1.0799, Validation loss: 0.8285
Epoch 77, Training loss: 1.0799, Validation loss: 0.8285
Epoch 78, Training loss: 1.0799, Validation loss: 0.8285
Epoch 79, Training loss: 1.0798, Validation loss: 0.8285
Epoch 80, Training loss: 1.0798, Validation loss: 0.8285
Epoch 81, Training loss: 1.0798, Validation loss: 0.8285
Epoch 82, Training loss: 1.0798, Validation loss: 0.8285
Epoch 83, Training loss: 1.0797, Validation loss: 0.8284
Epoch 84, Training loss: 1.0797, Validation loss: 0.8284
Epoch 85, Training loss: 1.0797, Validation loss: 0.8284
Epoch 86, Training loss: 1.0795, Validation loss: 0.8284
Epoch 87, Training loss: 1.0795, Validation loss: 0.8284
Epoch 88, Training loss: 1.0795, Validation loss: 0.8284
Epoch 89, Training loss: 1.0795, Validation loss: 0.8284
Epoch 90, Training loss: 1.0795, Validation loss: 0.8284
Epoch 91, Training loss: 1.0795, Validation loss: 0.8284
Epoch 92, Training loss: 1.0795, Validation loss: 0.8283
Epoch 93, Training loss: 1.0795, Validation loss: 0.8283
Epoch 94, Training loss: 1.0795, Validation loss: 0.8283
Epoch 95, Training loss: 1.0795, Validation loss: 0.8283
Epoch 96, Training loss: 1.0795, Validation loss: 0.8283
Epoch 97, Training loss: 1.0795, Validation loss: 0.8283
Epoch 98, Training loss: 1.0795, Validation loss: 0.8283
Epoch 99, Training loss: 1.0795, Validation loss: 0.8283
Epoch 100, Training loss: 1.0795, Validation loss: 0.8283
Epoch 101, Training loss: 1.0795, Validation loss: 0.8283
Epoch 102, Training loss: 1.0795, Validation loss: 0.8283
Epoch 103, Training loss: 1.0794, Validation loss: 0.8283
Epoch 104, Training loss: 1.0794, Validation loss: 0.8283
Epoch 105, Training loss: 1.0794, Validation loss: 0.8282
Epoch 106, Training loss: 1.0794, Validation loss: 0.8282
Epoch 107, Training loss: 1.0794, Validation loss: 0.8282
Epoch 108, Training loss: 1.0794, Validation loss: 0.8282
Epoch 109, Training loss: 1.0794, Validation loss: 0.8282
Epoch 110, Training loss: 1.0794, Validation loss: 0.8282
Epoch 111, Training loss: 1.0794, Validation loss: 0.8282
Epoch 112, Training loss: 1.0794, Validation loss: 0.8282
Epoch 113, Training loss: 1.0794, Validation loss: 0.8282
Epoch 114, Training loss: 1.0794, Validation loss: 0.8282
Epoch 115, Training loss: 1.0794, Validation loss: 0.8282
Epoch 116, Training loss: 1.0794, Validation loss: 0.8282
Epoch 117, Training loss: 1.0794, Validation loss: 0.8282
Epoch 118, Training loss: 1.0794, Validation loss: 0.8282
Epoch 119, Training loss: 1.0794, Validation loss: 0.8281
Epoch 120, Training loss: 1.0794, Validation loss: 0.8281
Epoch 121, Training loss: 1.0794, Validation loss: 0.8281
Epoch 122, Training loss: 1.0794, Validation loss: 0.8281
Epoch 123, Training loss: 1.0794, Validation loss: 0.8281
Epoch 124, Training loss: 1.0794, Validation loss: 0.8281
Epoch 125, Training loss: 1.0794, Validation loss: 0.8281
Epoch 126, Training loss: 1.0794, Validation loss: 0.8281
Epoch 127, Training loss: 1.0794, Validation loss: 0.8281
Epoch 128, Training loss: 1.0794, Validation loss: 0.8281
Epoch 129, Training loss: 1.0794, Validation loss: 0.8281
Epoch 130, Training loss: 1.0794, Validation loss: 0.8281
Epoch 131, Training loss: 1.0794, Validation loss: 0.8281
Epoch 132, Training loss: 1.0794, Validation loss: 0.8281
Epoch 133, Training loss: 1.0794, Validation loss: 0.8281
Epoch 134, Training loss: 1.0794, Validation loss: 0.8281
Epoch 135, Training loss: 1.0794, Validation loss: 0.8280
Epoch 136, Training loss: 1.0794, Validation loss: 0.8280
Epoch 137, Training loss: 1.0793, Validation loss: 0.8280
Epoch 138, Training loss: 1.0793, Validation loss: 0.8280
Epoch 139, Training loss: 1.0793, Validation loss: 0.8280
Epoch 140, Training loss: 1.0793, Validation loss: 0.8280
Epoch 141, Training loss: 1.0793, Validation loss: 0.8280
Epoch 142, Training loss: 1.0793, Validation loss: 0.8280
Epoch 143, Training loss: 1.0793, Validation loss: 0.8280
Epoch 144, Training loss: 1.0793, Validation loss: 0.8280
Epoch 145, Training loss: 1.0793, Validation loss: 0.8280
Epoch 146, Training loss: 1.0793, Validation loss: 0.8280
Epoch 147, Training loss: 1.0793, Validation loss: 0.8280
Epoch 148, Training loss: 1.0793, Validation loss: 0.8280
Epoch 149, Training loss: 1.0793, Validation loss: 0.8279
Epoch 150, Training loss: 1.0793, Validation loss: 0.8279
Epoch 151, Training loss: 1.0793, Validation loss: 0.8279
Epoch 152, Training loss: 1.0793, Validation loss: 0.8279
Epoch 153, Training loss: 1.0793, Validation loss: 0.8279
Epoch 154, Training loss: 1.0793, Validation loss: 0.8279
Epoch 155, Training loss: 1.0793, Validation loss: 0.8279
Epoch 156, Training loss: 1.0793, Validation loss: 0.8279
Epoch 157, Training loss: 1.0793, Validation loss: 0.8279
Epoch 158, Training loss: 1.0793, Validation loss: 0.8279
Epoch 159, Training loss: 1.0793, Validation loss: 0.8279
Epoch 160, Training loss: 1.0793, Validation loss: 0.8279
Epoch 161, Training loss: 1.0793, Validation loss: 0.8279
Epoch 162, Training loss: 1.0793, Validation loss: 0.8279
Epoch 163, Training loss: 1.0793, Validation loss: 0.8279
Epoch 164, Training loss: 1.0793, Validation loss: 0.8279
Epoch 165, Training loss: 1.0793, Validation loss: 0.8279
Epoch 166, Training loss: 1.0793, Validation loss: 0.8279
Epoch 167, Training loss: 1.0793, Validation loss: 0.8279
Epoch 168, Training loss: 1.0793, Validation loss: 0.8278
Epoch 169, Training loss: 1.0793, Validation loss: 0.8278
Epoch 170, Training loss: 1.0793, Validation loss: 0.8278
Epoch 171, Training loss: 1.0793, Validation loss: 0.8278
Epoch 172, Training loss: 1.0793, Validation loss: 0.8278
Epoch 173, Training loss: 1.0793, Validation loss: 0.8278
Epoch 174, Training loss: 1.0793, Validation loss: 0.8278
Epoch 175, Training loss: 1.0793, Validation loss: 0.8278
Epoch 176, Training loss: 1.0793, Validation loss: 0.8278
Epoch 177, Training loss: 1.0793, Validation loss: 0.8278
Epoch 178, Training loss: 1.0793, Validation loss: 0.8278
Epoch 179, Training loss: 1.0793, Validation loss: 0.8278
Epoch 180, Training loss: 1.0793, Validation loss: 0.8278
Epoch 181, Training loss: 1.0793, Validation loss: 0.8278
Epoch 182, Training loss: 1.0793, Validation loss: 0.8278
Epoch 183, Training loss: 1.0793, Validation loss: 0.8278
Epoch 184, Training loss: 1.0793, Validation loss: 0.8278
Epoch 185, Training loss: 1.0793, Validation loss: 0.8278
Epoch 186, Training loss: 1.0793, Validation loss: 0.8278
Epoch 187, Training loss: 1.0793, Validation loss: 0.8277
Epoch 188, Training loss: 1.0793, Validation loss: 0.8277
Epoch 189, Training loss: 1.0793, Validation loss: 0.8277
Epoch 190, Training loss: 1.0793, Validation loss: 0.8277
Epoch 191, Training loss: 1.0793, Validation loss: 0.8277
Epoch 192, Training loss: 1.0793, Validation loss: 0.8277
Epoch 193, Training loss: 1.0793, Validation loss: 0.8277
Epoch 194, Training loss: 1.0793, Validation loss: 0.8277
Epoch 195, Training loss: 1.0793, Validation loss: 0.8277
Epoch 196, Training loss: 1.0793, Validation loss: 0.8277
Epoch 197, Training loss: 1.0793, Validation loss: 0.8277
Epoch 198, Training loss: 1.0793, Validation loss: 0.8277
Epoch 199, Training loss: 1.0793, Validation loss: 0.8277
Epoch 200, Training loss: 1.0793, Validation loss: 0.8277
Epoch 201, Training loss: 1.0793, Validation loss: 0.8277
Epoch 202, Training loss: 1.0793, Validation loss: 0.8277
Epoch 203, Training loss: 1.0793, Validation loss: 0.8277
Epoch 204, Training loss: 1.0793, Validation loss: 0.8277
Epoch 205, Training loss: 1.0793, Validation loss: 0.8277
Epoch 206, Training loss: 1.0793, Validation loss: 0.8276
Epoch 207, Training loss: 1.0793, Validation loss: 0.8276
Epoch 208, Training loss: 1.0793, Validation loss: 0.8276
Epoch 209, Training loss: 1.0793, Validation loss: 0.8276
Epoch 210, Training loss: 1.0793, Validation loss: 0.8276
Epoch 211, Training loss: 1.0793, Validation loss: 0.8276
Epoch 212, Training loss: 1.0793, Validation loss: 0.8276
Epoch 213, Training loss: 1.0793, Validation loss: 0.8276
Epoch 214, Training loss: 1.0793, Validation loss: 0.8276
Epoch 215, Training loss: 1.0793, Validation loss: 0.8276
Epoch 216, Training loss: 1.0793, Validation loss: 0.8276
Epoch 217, Training loss: 1.0793, Validation loss: 0.8276
Epoch 218, Training loss: 1.0793, Validation loss: 0.8276
Epoch 219, Training loss: 1.0793, Validation loss: 0.8276
Epoch 220, Training loss: 1.0793, Validation loss: 0.8276
Epoch 221, Training loss: 1.0793, Validation loss: 0.8276
Epoch 222, Training loss: 1.0792, Validation loss: 0.8276
Epoch 223, Training loss: 1.0792, Validation loss: 0.8276
Epoch 224, Training loss: 1.0792, Validation loss: 0.8276
Epoch 225, Training loss: 1.0792, Validation loss: 0.8275
Epoch 226, Training loss: 1.0792, Validation loss: 0.8275
Epoch 227, Training loss: 1.0792, Validation loss: 0.8275
Epoch 228, Training loss: 1.0792, Validation loss: 0.8275
Epoch 229, Training loss: 1.0792, Validation loss: 0.8275
Epoch 230, Training loss: 1.0792, Validation loss: 0.8275
Epoch 231, Training loss: 1.0792, Validation loss: 0.8275
Epoch 232, Training loss: 1.0792, Validation loss: 0.8275
Epoch 233, Training loss: 1.0792, Validation loss: 0.8275
Epoch 234, Training loss: 1.0792, Validation loss: 0.8275
Epoch 235, Training loss: 1.0792, Validation loss: 0.8275
Epoch 236, Training loss: 1.0792, Validation loss: 0.8275
Epoch 237, Training loss: 1.0792, Validation loss: 0.8275
Epoch 238, Training loss: 1.0792, Validation loss: 0.8275
Epoch 239, Training loss: 1.0792, Validation loss: 0.8275
Epoch 240, Training loss: 1.0792, Validation loss: 0.8275
Epoch 241, Training loss: 1.0792, Validation loss: 0.8275
Epoch 242, Training loss: 1.0792, Validation loss: 0.8275
Epoch 243, Training loss: 1.0792, Validation loss: 0.8275
Epoch 244, Training loss: 1.0792, Validation loss: 0.8275
Epoch 245, Training loss: 1.0792, Validation loss: 0.8275
Epoch 246, Training loss: 1.0792, Validation loss: 0.8275
Epoch 247, Training loss: 1.0792, Validation loss: 0.8275
Epoch 248, Training loss: 1.0792, Validation loss: 0.8274
Epoch 249, Training loss: 1.0792, Validation loss: 0.8274
Epoch 250, Training loss: 1.0792, Validation loss: 0.8274
Epoch 251, Training loss: 1.0792, Validation loss: 0.8274
Epoch 252, Training loss: 1.0792, Validation loss: 0.8274
Epoch 253, Training loss: 1.0792, Validation loss: 0.8274
Epoch 254, Training loss: 1.0792, Validation loss: 0.8274
Epoch 255, Training loss: 1.0792, Validation loss: 0.8274
Epoch 256, Training loss: 1.0792, Validation loss: 0.8274
Epoch 257, Training loss: 1.0792, Validation loss: 0.8274
Epoch 258, Training loss: 1.0792, Validation loss: 0.8274
Epoch 259, Training loss: 1.0792, Validation loss: 0.8274
Epoch 260, Training loss: 1.0792, Validation loss: 0.8274
Epoch 261, Training loss: 1.0792, Validation loss: 0.8274
Epoch 262, Training loss: 1.0792, Validation loss: 0.8274
Epoch 263, Training loss: 1.0792, Validation loss: 0.8274
Epoch 264, Training loss: 1.0792, Validation loss: 0.8274
Epoch 265, Training loss: 1.0792, Validation loss: 0.8274
Epoch 266, Training loss: 1.0792, Validation loss: 0.8274
Epoch 267, Training loss: 1.0792, Validation loss: 0.8274
Epoch 268, Training loss: 1.0792, Validation loss: 0.8274
Epoch 269, Training loss: 1.0792, Validation loss: 0.8274
Epoch 270, Training loss: 1.0792, Validation loss: 0.8273
Epoch 271, Training loss: 1.0792, Validation loss: 0.8273
Epoch 272, Training loss: 1.0792, Validation loss: 0.8273
Epoch 273, Training loss: 1.0792, Validation loss: 0.8273
Epoch 274, Training loss: 1.0792, Validation loss: 0.8273
Epoch 275, Training loss: 1.0792, Validation loss: 0.8273
Epoch 276, Training loss: 1.0792, Validation loss: 0.8273
Epoch 277, Training loss: 1.0792, Validation loss: 0.8273
Epoch 278, Training loss: 1.0792, Validation loss: 0.8273
Epoch 279, Training loss: 1.0792, Validation loss: 0.8273
Epoch 280, Training loss: 1.0792, Validation loss: 0.8273
Epoch 281, Training loss: 1.0792, Validation loss: 0.8273
Epoch 282, Training loss: 1.0792, Validation loss: 0.8273
Epoch 283, Training loss: 1.0792, Validation loss: 0.8273
Epoch 284, Training loss: 1.0792, Validation loss: 0.8273
Epoch 285, Training loss: 1.0792, Validation loss: 0.8273
Epoch 286, Training loss: 1.0792, Validation loss: 0.8273
Epoch 287, Training loss: 1.0792, Validation loss: 0.8273
Epoch 288, Training loss: 1.0792, Validation loss: 0.8273
Epoch 289, Training loss: 1.0792, Validation loss: 0.8273
Epoch 290, Training loss: 1.0792, Validation loss: 0.8273
Epoch 291, Training loss: 1.0792, Validation loss: 0.8272
Epoch 292, Training loss: 1.0792, Validation loss: 0.8272
Epoch 293, Training loss: 1.0792, Validation loss: 0.8272
Epoch 294, Training loss: 1.0792, Validation loss: 0.8272
Epoch 295, Training loss: 1.0792, Validation loss: 0.8272
Epoch 296, Training loss: 1.0792, Validation loss: 0.8272
Epoch 297, Training loss: 1.0792, Validation loss: 0.8272
Epoch 298, Training loss: 1.0792, Validation loss: 0.8272
Epoch 299, Training loss: 1.0792, Validation loss: 0.8272
Epoch 300, Training loss: 1.0792, Validation loss: 0.8272
Epoch 301, Training loss: 1.0792, Validation loss: 0.8272
Epoch 302, Training loss: 1.0792, Validation loss: 0.8272
Epoch 303, Training loss: 1.0792, Validation loss: 0.8272
Epoch 304, Training loss: 1.0792, Validation loss: 0.8272
Epoch 305, Training loss: 1.0792, Validation loss: 0.8272
Epoch 306, Training loss: 1.0792, Validation loss: 0.8272
Epoch 307, Training loss: 1.0792, Validation loss: 0.8272
Epoch 308, Training loss: 1.0792, Validation loss: 0.8272
Epoch 309, Training loss: 1.0792, Validation loss: 0.8272
Epoch 310, Training loss: 1.0792, Validation loss: 0.8272
Epoch 311, Training loss: 1.0792, Validation loss: 0.8272
Epoch 312, Training loss: 1.0792, Validation loss: 0.8271
Epoch 313, Training loss: 1.0792, Validation loss: 0.8271
Epoch 314, Training loss: 1.0792, Validation loss: 0.8271
Epoch 315, Training loss: 1.0792, Validation loss: 0.8271
Epoch 316, Training loss: 1.0792, Validation loss: 0.8271
Epoch 317, Training loss: 1.0792, Validation loss: 0.8271
Epoch 318, Training loss: 1.0792, Validation loss: 0.8271
Epoch 319, Training loss: 1.0792, Validation loss: 0.8271
Epoch 320, Training loss: 1.0792, Validation loss: 0.8271
Epoch 321, Training loss: 1.0791, Validation loss: 0.8271
Epoch 322, Training loss: 1.0791, Validation loss: 0.8271
Epoch 323, Training loss: 1.0791, Validation loss: 0.8271
Epoch 324, Training loss: 1.0791, Validation loss: 0.8271
Epoch 325, Training loss: 1.0791, Validation loss: 0.8271
Epoch 326, Training loss: 1.0791, Validation loss: 0.8271
Epoch 327, Training loss: 1.0791, Validation loss: 0.8271
Epoch 328, Training loss: 1.0791, Validation loss: 0.8271
Epoch 329, Training loss: 1.0791, Validation loss: 0.8271
Epoch 330, Training loss: 1.0791, Validation loss: 0.8271
Epoch 331, Training loss: 1.0791, Validation loss: 0.8271
Epoch 332, Training loss: 1.0791, Validation loss: 0.8271
Epoch 333, Training loss: 1.0791, Validation loss: 0.8271
Epoch 334, Training loss: 1.0791, Validation loss: 0.8271
Epoch 335, Training loss: 1.0791, Validation loss: 0.8271
Epoch 336, Training loss: 1.0791, Validation loss: 0.8270
Epoch 337, Training loss: 1.0791, Validation loss: 0.8270
Epoch 338, Training loss: 1.0791, Validation loss: 0.8270
Epoch 339, Training loss: 1.0791, Validation loss: 0.8270
Epoch 340, Training loss: 1.0791, Validation loss: 0.8270
Epoch 341, Training loss: 1.0791, Validation loss: 0.8270
Epoch 342, Training loss: 1.0791, Validation loss: 0.8270
Epoch 343, Training loss: 1.0791, Validation loss: 0.8270
Epoch 344, Training loss: 1.0791, Validation loss: 0.8270
Epoch 345, Training loss: 1.0791, Validation loss: 0.8270
Epoch 346, Training loss: 1.0791, Validation loss: 0.8270
Epoch 347, Training loss: 1.0791, Validation loss: 0.8270
Epoch 348, Training loss: 1.0791, Validation loss: 0.8270
Epoch 349, Training loss: 1.0791, Validation loss: 0.8270
Epoch 350, Training loss: 1.0791, Validation loss: 0.8270
Epoch 351, Training loss: 1.0791, Validation loss: 0.8270
Epoch 352, Training loss: 1.0791, Validation loss: 0.8270
Epoch 353, Training loss: 1.0791, Validation loss: 0.8270
Epoch 354, Training loss: 1.0791, Validation loss: 0.8270
Epoch 355, Training loss: 1.0791, Validation loss: 0.8270
Epoch 356, Training loss: 1.0791, Validation loss: 0.8270
Epoch 357, Training loss: 1.0791, Validation loss: 0.8270
Epoch 358, Training loss: 1.0791, Validation loss: 0.8270
Epoch 359, Training loss: 1.0791, Validation loss: 0.8270
Epoch 360, Training loss: 1.0791, Validation loss: 0.8270
Epoch 361, Training loss: 1.0791, Validation loss: 0.8270
Epoch 362, Training loss: 1.0791, Validation loss: 0.8270
Epoch 363, Training loss: 1.0791, Validation loss: 0.8270
Epoch 364, Training loss: 1.0791, Validation loss: 0.8270
Epoch 365, Training loss: 1.0791, Validation loss: 0.8269
Epoch 366, Training loss: 1.0791, Validation loss: 0.8269
Epoch 367, Training loss: 1.0791, Validation loss: 0.8269
Epoch 368, Training loss: 1.0791, Validation loss: 0.8269
Epoch 369, Training loss: 1.0791, Validation loss: 0.8269
Epoch 370, Training loss: 1.0791, Validation loss: 0.8269
Epoch 371, Training loss: 1.0791, Validation loss: 0.8269
Epoch 372, Training loss: 1.0791, Validation loss: 0.8269
Epoch 373, Training loss: 1.0791, Validation loss: 0.8269
Epoch 374, Training loss: 1.0791, Validation loss: 0.8269
Epoch 375, Training loss: 1.0791, Validation loss: 0.8269
Epoch 376, Training loss: 1.0791, Validation loss: 0.8269
Epoch 377, Training loss: 1.0791, Validation loss: 0.8269
Epoch 378, Training loss: 1.0791, Validation loss: 0.8269
Epoch 379, Training loss: 1.0791, Validation loss: 0.8269
Epoch 380, Training loss: 1.0791, Validation loss: 0.8269
Epoch 381, Training loss: 1.0791, Validation loss: 0.8269
Epoch 382, Training loss: 1.0791, Validation loss: 0.8269
Epoch 383, Training loss: 1.0791, Validation loss: 0.8269
Epoch 384, Training loss: 1.0791, Validation loss: 0.8269
Epoch 385, Training loss: 1.0791, Validation loss: 0.8269
Epoch 386, Training loss: 1.0791, Validation loss: 0.8269
Epoch 387, Training loss: 1.0791, Validation loss: 0.8269
Epoch 388, Training loss: 1.0791, Validation loss: 0.8269
Epoch 389, Training loss: 1.0791, Validation loss: 0.8269
Epoch 390, Training loss: 1.0791, Validation loss: 0.8269
Epoch 391, Training loss: 1.0791, Validation loss: 0.8269
Epoch 392, Training loss: 1.0791, Validation loss: 0.8269
Epoch 393, Training loss: 1.0791, Validation loss: 0.8269
Epoch 394, Training loss: 1.0791, Validation loss: 0.8269
Epoch 395, Training loss: 1.0791, Validation loss: 0.8269
Epoch 396, Training loss: 1.0791, Validation loss: 0.8269
Epoch 397, Training loss: 1.0791, Validation loss: 0.8268
Epoch 398, Training loss: 1.0791, Validation loss: 0.8268
Epoch 399, Training loss: 1.0791, Validation loss: 0.8268
Epoch 400, Training loss: 1.0791, Validation loss: 0.8268
Epoch 401, Training loss: 1.0791, Validation loss: 0.8268
Epoch 402, Training loss: 1.0791, Validation loss: 0.8268
Epoch 403, Training loss: 1.0791, Validation loss: 0.8268
Epoch 404, Training loss: 1.0791, Validation loss: 0.8268
Epoch 405, Training loss: 1.0791, Validation loss: 0.8268
Epoch 406, Training loss: 1.0791, Validation loss: 0.8268
Epoch 407, Training loss: 1.0791, Validation loss: 0.8268
Epoch 408, Training loss: 1.0791, Validation loss: 0.8268
Epoch 409, Training loss: 1.0791, Validation loss: 0.8268
Epoch 410, Training loss: 1.0791, Validation loss: 0.8268
Epoch 411, Training loss: 1.0791, Validation loss: 0.8268
Epoch 412, Training loss: 1.0791, Validation loss: 0.8268
Epoch 413, Training loss: 1.0791, Validation loss: 0.8268
Epoch 414, Training loss: 1.0791, Validation loss: 0.8268
Epoch 415, Training loss: 1.0791, Validation loss: 0.8268
Epoch 416, Training loss: 1.0791, Validation loss: 0.8268
Epoch 417, Training loss: 1.0791, Validation loss: 0.8268
Epoch 418, Training loss: 1.0791, Validation loss: 0.8268
Epoch 419, Training loss: 1.0791, Validation loss: 0.8268
Epoch 420, Training loss: 1.0791, Validation loss: 0.8268
Epoch 421, Training loss: 1.0791, Validation loss: 0.8268
Epoch 422, Training loss: 1.0791, Validation loss: 0.8268
Epoch 423, Training loss: 1.0791, Validation loss: 0.8268
Epoch 424, Training loss: 1.0791, Validation loss: 0.8268
Epoch 425, Training loss: 1.0791, Validation loss: 0.8268
Epoch 426, Training loss: 1.0791, Validation loss: 0.8268
Epoch 427, Training loss: 1.0791, Validation loss: 0.8267
Epoch 428, Training loss: 1.0791, Validation loss: 0.8267
Epoch 429, Training loss: 1.0791, Validation loss: 0.8267
Epoch 430, Training loss: 1.0791, Validation loss: 0.8267
Epoch 431, Training loss: 1.0791, Validation loss: 0.8267
Epoch 432, Training loss: 1.0791, Validation loss: 0.8267
Epoch 433, Training loss: 1.0791, Validation loss: 0.8267
Epoch 434, Training loss: 1.0791, Validation loss: 0.8267
Epoch 435, Training loss: 1.0791, Validation loss: 0.8267
Epoch 436, Training loss: 1.0791, Validation loss: 0.8267
Epoch 437, Training loss: 1.0791, Validation loss: 0.8267
Epoch 438, Training loss: 1.0791, Validation loss: 0.8267
Epoch 439, Training loss: 1.0791, Validation loss: 0.8267
Epoch 440, Training loss: 1.0791, Validation loss: 0.8267
Epoch 441, Training loss: 1.0791, Validation loss: 0.8267
Epoch 442, Training loss: 1.0791, Validation loss: 0.8267
Epoch 443, Training loss: 1.0791, Validation loss: 0.8267
Epoch 444, Training loss: 1.0791, Validation loss: 0.8267
Epoch 445, Training loss: 1.0791, Validation loss: 0.8267
Epoch 446, Training loss: 1.0791, Validation loss: 0.8267
Epoch 447, Training loss: 1.0791, Validation loss: 0.8267
Epoch 448, Training loss: 1.0791, Validation loss: 0.8267
Epoch 449, Training loss: 1.0790, Validation loss: 0.8267
Epoch 450, Training loss: 1.0790, Validation loss: 0.8267
Epoch 451, Training loss: 1.0790, Validation loss: 0.8267
Epoch 452, Training loss: 1.0790, Validation loss: 0.8267
Epoch 453, Training loss: 1.0790, Validation loss: 0.8267
Epoch 454, Training loss: 1.0790, Validation loss: 0.8267
Epoch 455, Training loss: 1.0790, Validation loss: 0.8267
Epoch 456, Training loss: 1.0790, Validation loss: 0.8266
Epoch 457, Training loss: 1.0790, Validation loss: 0.8266
Epoch 458, Training loss: 1.0790, Validation loss: 0.8266
Epoch 459, Training loss: 1.0790, Validation loss: 0.8266
Epoch 460, Training loss: 1.0790, Validation loss: 0.8266
Epoch 461, Training loss: 1.0790, Validation loss: 0.8266
Epoch 462, Training loss: 1.0790, Validation loss: 0.8266
Epoch 463, Training loss: 1.0790, Validation loss: 0.8266
Epoch 464, Training loss: 1.0790, Validation loss: 0.8266
Epoch 465, Training loss: 1.0790, Validation loss: 0.8266
Epoch 466, Training loss: 1.0790, Validation loss: 0.8266
Epoch 467, Training loss: 1.0790, Validation loss: 0.8266
Epoch 468, Training loss: 1.0790, Validation loss: 0.8266
Epoch 469, Training loss: 1.0790, Validation loss: 0.8266
Epoch 470, Training loss: 1.0790, Validation loss: 0.8266
Epoch 471, Training loss: 1.0790, Validation loss: 0.8266
Epoch 472, Training loss: 1.0790, Validation loss: 0.8266
Epoch 473, Training loss: 1.0790, Validation loss: 0.8266
Epoch 474, Training loss: 1.0790, Validation loss: 0.8266
Epoch 475, Training loss: 1.0790, Validation loss: 0.8266
Epoch 476, Training loss: 1.0790, Validation loss: 0.8266
Epoch 477, Training loss: 1.0790, Validation loss: 0.8266
Epoch 478, Training loss: 1.0790, Validation loss: 0.8266
Epoch 479, Training loss: 1.0790, Validation loss: 0.8266
Epoch 480, Training loss: 1.0790, Validation loss: 0.8266
Epoch 481, Training loss: 1.0790, Validation loss: 0.8266
Epoch 482, Training loss: 1.0790, Validation loss: 0.8266
Epoch 483, Training loss: 1.0790, Validation loss: 0.8266
Epoch 484, Training loss: 1.0790, Validation loss: 0.8266
Epoch 485, Training loss: 1.0790, Validation loss: 0.8266
Epoch 486, Training loss: 1.0790, Validation loss: 0.8266
Epoch 487, Training loss: 1.0790, Validation loss: 0.8266
Epoch 488, Training loss: 1.0790, Validation loss: 0.8266
Epoch 489, Training loss: 1.0790, Validation loss: 0.8266
Epoch 490, Training loss: 1.0790, Validation loss: 0.8266
Epoch 491, Training loss: 1.0790, Validation loss: 0.8266
Epoch 492, Training loss: 1.0790, Validation loss: 0.8266
Epoch 493, Training loss: 1.0790, Validation loss: 0.8266
Epoch 494, Training loss: 1.0790, Validation loss: 0.8266
Epoch 495, Training loss: 1.0790, Validation loss: 0.8266
Epoch 496, Training loss: 1.0790, Validation loss: 0.8266
Epoch 497, Training loss: 1.0790, Validation loss: 0.8265
Epoch 498, Training loss: 1.0790, Validation loss: 0.8265
Epoch 499, Training loss: 1.0790, Validation loss: 0.8265
Epoch 0, Training loss: 0.4119, Validation loss: 0.3544
Epoch 1, Training loss: 0.4046, Validation loss: 0.3638
Epoch 2, Training loss: 0.4374, Validation loss: 0.3434
Epoch 3, Training loss: 0.3949, Validation loss: 0.3442
Epoch 4, Training loss: 0.3933, Validation loss: 0.3339
Epoch 5, Training loss: 0.3932, Validation loss: 0.3317
Epoch 6, Training loss: 0.3923, Validation loss: 0.3283
Epoch 7, Training loss: 0.3922, Validation loss: 0.3269
Epoch 8, Training loss: 0.3950, Validation loss: 0.3537
Epoch 9, Training loss: 0.3922, Validation loss: 0.3320
Epoch 10, Training loss: 0.3932, Validation loss: 0.3488
Epoch 11, Training loss: 0.3945, Validation loss: 0.3223
Epoch 12, Training loss: 0.3906, Validation loss: 0.3335
Epoch 13, Training loss: 0.3946, Validation loss: 0.3292
Epoch 14, Training loss: 0.3921, Validation loss: 0.3481
Epoch 15, Training loss: 0.3908, Validation loss: 0.3434
Epoch 16, Training loss: 0.3923, Validation loss: 0.3217
Epoch 17, Training loss: 0.3907, Validation loss: 0.3322
Epoch 18, Training loss: 0.3920, Validation loss: 0.3473
Epoch 19, Training loss: 0.3919, Validation loss: 0.3431
Epoch 20, Training loss: 0.3922, Validation loss: 0.3346
Epoch 21, Training loss: 0.3919, Validation loss: 0.3375
Epoch 22, Training loss: 0.3968, Validation loss: 0.3276
Epoch 23, Training loss: 0.3918, Validation loss: 0.3366
Epoch 24, Training loss: 0.3915, Validation loss: 0.3409
Epoch 25, Training loss: 0.3926, Validation loss: 0.3340
Epoch 26, Training loss: 0.3931, Validation loss: 0.3427
Early stopping.
Epoch 0, Training loss: 0.4264, Validation loss: 0.3676
Epoch 1, Training loss: 0.4158, Validation loss: 0.3533
Epoch 2, Training loss: 0.4090, Validation loss: 0.3523
Epoch 3, Training loss: 0.4070, Validation loss: 0.3584
Epoch 4, Training loss: 0.4017, Validation loss: 0.3476
Epoch 5, Training loss: 0.4180, Validation loss: 0.3894
Epoch 6, Training loss: 0.4002, Validation loss: 0.3228
Epoch 7, Training loss: 0.3950, Validation loss: 0.3358
Epoch 8, Training loss: 0.3939, Validation loss: 0.3289
Epoch 9, Training loss: 0.3921, Validation loss: 0.3386
Epoch 10, Training loss: 0.3909, Validation loss: 0.3342
Epoch 11, Training loss: 0.3948, Validation loss: 0.3146
Epoch 12, Training loss: 0.3924, Validation loss: 0.3231
Epoch 13, Training loss: 0.3984, Validation loss: 0.3649
Epoch 14, Training loss: 0.4034, Validation loss: 0.3238
Epoch 15, Training loss: 0.3893, Validation loss: 0.3279
Epoch 16, Training loss: 0.3884, Validation loss: 0.3312
Epoch 17, Training loss: 0.3894, Validation loss: 0.3259
Epoch 18, Training loss: 0.5699, Validation loss: 0.4151
Epoch 19, Training loss: 0.4063, Validation loss: 0.3709
Epoch 20, Training loss: 0.3946, Validation loss: 0.3488
Epoch 21, Training loss: 0.3892, Validation loss: 0.3380
Early stopping.
Epoch 0, Training loss: 0.6614, Validation loss: 0.6095
Epoch 1, Training loss: 0.5299, Validation loss: 0.4836
Epoch 2, Training loss: 0.5430, Validation loss: 0.4596
Epoch 3, Training loss: 0.4677, Validation loss: 0.3982
Epoch 4, Training loss: 0.4370, Validation loss: 0.3730
Epoch 5, Training loss: 0.4266, Validation loss: 0.3594
Epoch 6, Training loss: 0.4302, Validation loss: 0.3516
Epoch 7, Training loss: 0.4182, Validation loss: 0.3583
Epoch 8, Training loss: 0.4152, Validation loss: 0.3624
Epoch 9, Training loss: 0.4171, Validation loss: 0.3447
Epoch 10, Training loss: 0.4228, Validation loss: 0.3889
Epoch 11, Training loss: 0.4041, Validation loss: 0.3501
Epoch 12, Training loss: 0.4047, Validation loss: 0.3554
Epoch 13, Training loss: 0.4030, Validation loss: 0.3510
Epoch 14, Training loss: 0.4003, Validation loss: 0.3433
Epoch 15, Training loss: 0.4027, Validation loss: 0.3321
Epoch 16, Training loss: 0.4224, Validation loss: 0.3907
Epoch 17, Training loss: 0.4059, Validation loss: 0.3294
Epoch 18, Training loss: 0.4011, Validation loss: 0.3541
Epoch 19, Training loss: 0.4084, Validation loss: 0.3694
Epoch 20, Training loss: 0.4031, Validation loss: 0.3568
Epoch 21, Training loss: 0.3988, Validation loss: 0.3330
Epoch 22, Training loss: 0.4165, Validation loss: 0.3408
Epoch 23, Training loss: 0.3981, Validation loss: 0.3350
Epoch 24, Training loss: 0.4016, Validation loss: 0.3650
Epoch 25, Training loss: 0.3960, Validation loss: 0.3206
Epoch 26, Training loss: 0.3959, Validation loss: 0.3176
Epoch 27, Training loss: 0.3942, Validation loss: 0.3286
Epoch 28, Training loss: 0.3976, Validation loss: 0.3405
Epoch 29, Training loss: 0.3951, Validation loss: 0.3375
Epoch 30, Training loss: 0.3939, Validation loss: 0.3349
Epoch 31, Training loss: 0.3930, Validation loss: 0.3276
Epoch 32, Training loss: 0.3938, Validation loss: 0.3256
Epoch 33, Training loss: 0.3968, Validation loss: 0.3458
Epoch 34, Training loss: 0.3947, Validation loss: 0.3419
Epoch 35, Training loss: 0.3939, Validation loss: 0.3288
Epoch 36, Training loss: 0.3946, Validation loss: 0.3281
Early stopping.
Epoch 0, Training loss: 0.5146, Validation loss: 0.4768
Epoch 1, Training loss: 0.5012, Validation loss: 0.4760
Epoch 2, Training loss: 0.5010, Validation loss: 0.4836
Epoch 3, Training loss: 0.5023, Validation loss: 0.4630
Epoch 4, Training loss: 0.5028, Validation loss: 0.4631
Epoch 5, Training loss: 0.4933, Validation loss: 0.4532
Epoch 6, Training loss: 0.4937, Validation loss: 0.4590
Epoch 7, Training loss: 0.4900, Validation loss: 0.4584
Epoch 8, Training loss: 0.4909, Validation loss: 0.4595
Epoch 9, Training loss: 0.4949, Validation loss: 0.4567
Epoch 10, Training loss: 0.4910, Validation loss: 0.4594
Epoch 11, Training loss: 0.4956, Validation loss: 0.4564
Epoch 12, Training loss: 0.4892, Validation loss: 0.4620
Epoch 13, Training loss: 0.4917, Validation loss: 0.4688
Epoch 14, Training loss: 0.4967, Validation loss: 0.4541
Epoch 15, Training loss: 0.4915, Validation loss: 0.4585
Early stopping.
Epoch 0, Training loss: 1.0121, Validation loss: 0.8019
Epoch 1, Training loss: 0.7853, Validation loss: 0.6496
Epoch 2, Training loss: 0.6464, Validation loss: 0.5603
Epoch 3, Training loss: 0.5849, Validation loss: 0.5163
Epoch 4, Training loss: 0.5458, Validation loss: 0.4882
Epoch 5, Training loss: 0.5303, Validation loss: 0.4785
Epoch 6, Training loss: 0.5295, Validation loss: 0.5127
Epoch 7, Training loss: 0.5039, Validation loss: 0.4747
Epoch 8, Training loss: 0.4976, Validation loss: 0.4709
Epoch 9, Training loss: 0.4961, Validation loss: 0.4743
Epoch 10, Training loss: 0.4922, Validation loss: 0.4618
Epoch 11, Training loss: 0.4905, Validation loss: 0.4588
Epoch 12, Training loss: 0.4910, Validation loss: 0.4566
Epoch 13, Training loss: 0.5159, Validation loss: 0.4744
Epoch 14, Training loss: 0.4877, Validation loss: 0.4429
Epoch 15, Training loss: 0.4860, Validation loss: 0.4439
Epoch 16, Training loss: 0.4847, Validation loss: 0.4576
Epoch 17, Training loss: 0.4832, Validation loss: 0.4485
Epoch 18, Training loss: 0.4814, Validation loss: 0.4520
Epoch 19, Training loss: 0.4801, Validation loss: 0.4548
Epoch 20, Training loss: 0.4825, Validation loss: 0.4488
Epoch 21, Training loss: 0.4785, Validation loss: 0.4528
Epoch 22, Training loss: 0.4834, Validation loss: 0.4462
Epoch 23, Training loss: 0.4836, Validation loss: 0.4474
Epoch 24, Training loss: 0.4842, Validation loss: 0.4480
Early stopping.
Epoch 0, Training loss: 0.8940, Validation loss: 0.6794
Epoch 1, Training loss: 0.7627, Validation loss: 0.6071
Epoch 2, Training loss: 0.6174, Validation loss: 0.5078
Epoch 3, Training loss: 0.5601, Validation loss: 0.4809
Epoch 4, Training loss: 0.5412, Validation loss: 0.4911
Epoch 5, Training loss: 0.5256, Validation loss: 0.4709
Epoch 6, Training loss: 0.5267, Validation loss: 0.4647
Epoch 7, Training loss: 0.5182, Validation loss: 0.4625
Epoch 8, Training loss: 0.5135, Validation loss: 0.4608
Epoch 9, Training loss: 0.5194, Validation loss: 0.4877
Epoch 10, Training loss: 0.5051, Validation loss: 0.4599
Epoch 11, Training loss: 0.5040, Validation loss: 0.4571
Epoch 12, Training loss: 0.5035, Validation loss: 0.4542
Epoch 13, Training loss: 0.5152, Validation loss: 0.4666
Epoch 14, Training loss: 0.4971, Validation loss: 0.4482
Epoch 15, Training loss: 0.4958, Validation loss: 0.4485
Epoch 16, Training loss: 0.4949, Validation loss: 0.4484
Epoch 17, Training loss: 0.4934, Validation loss: 0.4486
Epoch 18, Training loss: 0.4935, Validation loss: 0.4470
Epoch 19, Training loss: 0.4927, Validation loss: 0.4483
Epoch 20, Training loss: 0.4893, Validation loss: 0.4520
Epoch 21, Training loss: 0.4908, Validation loss: 0.4512
Epoch 22, Training loss: 0.4898, Validation loss: 0.4565
Epoch 23, Training loss: 0.4905, Validation loss: 0.4504
Epoch 24, Training loss: 0.4921, Validation loss: 0.4486
Epoch 25, Training loss: 0.4922, Validation loss: 0.4482
Epoch 26, Training loss: 0.4925, Validation loss: 0.4483
Epoch 27, Training loss: 0.4907, Validation loss: 0.4518
Epoch 28, Training loss: 0.4908, Validation loss: 0.4524
Early stopping.
Epoch 0, Training loss: 0.4343, Validation loss: 0.3359
Epoch 1, Training loss: 0.4676, Validation loss: 0.3598
Epoch 2, Training loss: 0.4221, Validation loss: 0.3476
Epoch 3, Training loss: 0.4057, Validation loss: 0.3408
Epoch 4, Training loss: 0.4100, Validation loss: 0.3279
Epoch 5, Training loss: 0.3947, Validation loss: 0.3450
Epoch 6, Training loss: 0.4220, Validation loss: 0.3592
Epoch 7, Training loss: 0.3887, Validation loss: 0.3383
Epoch 8, Training loss: 0.3850, Validation loss: 0.3271
Epoch 9, Training loss: 0.3909, Validation loss: 0.3192
Epoch 10, Training loss: 0.3928, Validation loss: 0.3610
Epoch 11, Training loss: 0.3951, Validation loss: 0.3724
Epoch 12, Training loss: 0.3824, Validation loss: 0.3456
Epoch 13, Training loss: 0.3803, Validation loss: 0.3105
Epoch 14, Training loss: 0.3999, Validation loss: 0.3769
Epoch 15, Training loss: 0.3807, Validation loss: 0.3479
Epoch 16, Training loss: 0.4487, Validation loss: 0.3464
Epoch 17, Training loss: 0.3796, Validation loss: 0.3156
Epoch 18, Training loss: 0.3805, Validation loss: 0.3482
Epoch 19, Training loss: 0.3812, Validation loss: 0.3498
Epoch 20, Training loss: 0.3741, Validation loss: 0.3299
Epoch 21, Training loss: 0.3889, Validation loss: 0.3599
Epoch 22, Training loss: 0.4405, Validation loss: 0.4420
Epoch 23, Training loss: 0.3848, Validation loss: 0.3035
Epoch 24, Training loss: 0.3724, Validation loss: 0.3135
Epoch 25, Training loss: 0.4078, Validation loss: 0.3152
Epoch 26, Training loss: 0.3901, Validation loss: 0.3108
Epoch 27, Training loss: 0.3718, Validation loss: 0.3239
Epoch 28, Training loss: 0.3711, Validation loss: 0.3144
Epoch 29, Training loss: 0.3708, Validation loss: 0.3215
Epoch 30, Training loss: 0.3723, Validation loss: 0.3151
Epoch 31, Training loss: 0.3840, Validation loss: 0.3066
Epoch 32, Training loss: 0.3792, Validation loss: 0.3057
Epoch 33, Training loss: 0.3740, Validation loss: 0.3123
Early stopping.
Epoch 0, Training loss: 0.4264, Validation loss: 0.3734
Epoch 1, Training loss: 0.4061, Validation loss: 0.3517
Epoch 2, Training loss: 0.4105, Validation loss: 0.3381
Epoch 3, Training loss: 0.3980, Validation loss: 0.3335
Epoch 4, Training loss: 0.3901, Validation loss: 0.3494
Epoch 5, Training loss: 0.4143, Validation loss: 0.4045
Epoch 6, Training loss: 0.3973, Validation loss: 0.3788
Epoch 7, Training loss: 0.3832, Validation loss: 0.3343
Epoch 8, Training loss: 0.3802, Validation loss: 0.3207
Epoch 9, Training loss: 0.3800, Validation loss: 0.3153
Epoch 10, Training loss: 0.3783, Validation loss: 0.3108
Epoch 11, Training loss: 0.3865, Validation loss: 0.3163
Epoch 12, Training loss: 0.3960, Validation loss: 0.3805
Epoch 13, Training loss: 0.3892, Validation loss: 0.3617
Epoch 14, Training loss: 0.3751, Validation loss: 0.3324
Epoch 15, Training loss: 0.4141, Validation loss: 0.4204
Epoch 16, Training loss: 0.4057, Validation loss: 0.3149
Epoch 17, Training loss: 0.3698, Validation loss: 0.3191
Epoch 18, Training loss: 0.3693, Validation loss: 0.3142
Epoch 19, Training loss: 0.3713, Validation loss: 0.3218
Epoch 20, Training loss: 0.3884, Validation loss: 0.3098
Epoch 21, Training loss: 0.3785, Validation loss: 0.3101
Epoch 22, Training loss: 0.3926, Validation loss: 0.3862
Epoch 23, Training loss: 0.3674, Validation loss: 0.3249
Epoch 24, Training loss: 0.3656, Validation loss: 0.3105
Epoch 25, Training loss: 0.4374, Validation loss: 0.4597
Epoch 26, Training loss: 0.3678, Validation loss: 0.3197
Epoch 27, Training loss: 0.3848, Validation loss: 0.3114
Epoch 28, Training loss: 0.9291, Validation loss: 0.6580
Epoch 29, Training loss: 0.3939, Validation loss: 0.3187
Epoch 30, Training loss: 0.3818, Validation loss: 0.3025
Epoch 31, Training loss: 0.3756, Validation loss: 0.3487
Epoch 32, Training loss: 0.3648, Validation loss: 0.3089
Epoch 33, Training loss: 0.3653, Validation loss: 0.3070
Epoch 34, Training loss: 0.3651, Validation loss: 0.3208
Epoch 35, Training loss: 0.3676, Validation loss: 0.3043
Epoch 36, Training loss: 0.3643, Validation loss: 0.3145
Epoch 37, Training loss: 0.3932, Validation loss: 0.3188
Epoch 38, Training loss: 0.3648, Validation loss: 0.3274
Epoch 39, Training loss: 0.3788, Validation loss: 0.3071
Epoch 40, Training loss: 0.3631, Validation loss: 0.3185
Early stopping.
Epoch 0, Training loss: 0.5066, Validation loss: 0.4333
Epoch 1, Training loss: 0.4655, Validation loss: 0.4162
Epoch 2, Training loss: 0.4401, Validation loss: 0.3642
Epoch 3, Training loss: 0.4668, Validation loss: 0.3610
Epoch 4, Training loss: 0.4203, Validation loss: 0.3419
Epoch 5, Training loss: 0.4217, Validation loss: 0.3283
Epoch 6, Training loss: 0.4161, Validation loss: 0.3163
Epoch 7, Training loss: 0.4082, Validation loss: 0.3141
Epoch 8, Training loss: 0.4067, Validation loss: 0.3279
Epoch 9, Training loss: 0.4053, Validation loss: 0.3309
Epoch 10, Training loss: 0.4250, Validation loss: 0.3187
Epoch 11, Training loss: 0.4188, Validation loss: 0.3807
Epoch 12, Training loss: 0.4029, Validation loss: 0.3275
Epoch 13, Training loss: 0.4234, Validation loss: 0.3929
Epoch 14, Training loss: 0.3907, Validation loss: 0.3328
Epoch 15, Training loss: 0.4034, Validation loss: 0.3727
Epoch 16, Training loss: 0.4104, Validation loss: 0.3218
Epoch 17, Training loss: 0.3961, Validation loss: 0.3213
Early stopping.
Epoch 0, Training loss: 0.5277, Validation loss: 0.4928
Epoch 1, Training loss: 0.5326, Validation loss: 0.4747
Epoch 2, Training loss: 0.5243, Validation loss: 0.4680
Epoch 3, Training loss: 0.5032, Validation loss: 0.4604
Epoch 4, Training loss: 0.5084, Validation loss: 0.4611
Epoch 5, Training loss: 0.5003, Validation loss: 0.4647
Epoch 6, Training loss: 0.5051, Validation loss: 0.4638
Epoch 7, Training loss: 0.5107, Validation loss: 0.4639
Epoch 8, Training loss: 0.5027, Validation loss: 0.4693
Epoch 9, Training loss: 0.5070, Validation loss: 0.4564
Epoch 10, Training loss: 0.5065, Validation loss: 0.4593
Epoch 11, Training loss: 0.5106, Validation loss: 0.4586
Epoch 12, Training loss: 0.5176, Validation loss: 0.4581
Epoch 13, Training loss: 0.5268, Validation loss: 0.4624
Epoch 14, Training loss: 0.5087, Validation loss: 0.4860
Epoch 15, Training loss: 0.5070, Validation loss: 0.4628
Epoch 16, Training loss: 0.5191, Validation loss: 0.4610
Epoch 17, Training loss: 0.5188, Validation loss: 0.4622
Epoch 18, Training loss: 0.5165, Validation loss: 0.4562
Epoch 19, Training loss: 0.5163, Validation loss: 0.4614
Epoch 20, Training loss: 0.5176, Validation loss: 0.4624
Epoch 21, Training loss: 0.5128, Validation loss: 0.4612
Epoch 22, Training loss: 0.5108, Validation loss: 0.4621
Epoch 23, Training loss: 0.5125, Validation loss: 0.4602
Epoch 24, Training loss: 0.5145, Validation loss: 0.4597
Epoch 25, Training loss: 0.5153, Validation loss: 0.4897
Epoch 26, Training loss: 0.5102, Validation loss: 0.4603
Epoch 27, Training loss: 0.5222, Validation loss: 0.4592
Epoch 28, Training loss: 0.5087, Validation loss: 0.4636
Early stopping.
Epoch 0, Training loss: 0.6980, Validation loss: 0.5638
Epoch 1, Training loss: 0.6397, Validation loss: 0.6425
Epoch 2, Training loss: 0.5265, Validation loss: 0.4948
Epoch 3, Training loss: 0.5200, Validation loss: 0.4613
Epoch 4, Training loss: 0.5305, Validation loss: 0.4545
Epoch 5, Training loss: 0.5097, Validation loss: 0.4782
Epoch 6, Training loss: 0.4926, Validation loss: 0.4428
Epoch 7, Training loss: 0.5105, Validation loss: 0.4446
Epoch 8, Training loss: 0.5014, Validation loss: 0.4450
Epoch 9, Training loss: 0.4996, Validation loss: 0.4463
Epoch 10, Training loss: 0.4987, Validation loss: 0.4663
Epoch 11, Training loss: 0.4978, Validation loss: 0.4495
Epoch 12, Training loss: 0.5061, Validation loss: 0.4485
Epoch 13, Training loss: 0.5115, Validation loss: 0.4480
Epoch 14, Training loss: 0.5045, Validation loss: 0.4644
Epoch 15, Training loss: 0.5083, Validation loss: 0.4508
Epoch 16, Training loss: 0.5079, Validation loss: 0.4511
Early stopping.
Epoch 0, Training loss: 1.0618, Validation loss: 0.8163
Epoch 1, Training loss: 1.0585, Validation loss: 0.8112
Epoch 2, Training loss: 1.0564, Validation loss: 0.8071
Epoch 3, Training loss: 1.0551, Validation loss: 0.8045
Epoch 4, Training loss: 1.0545, Validation loss: 0.8037
Epoch 5, Training loss: 1.0527, Validation loss: 0.8033
Epoch 6, Training loss: 0.8154, Validation loss: 0.6454
Epoch 7, Training loss: 0.5948, Validation loss: 0.4934
Epoch 8, Training loss: 0.5840, Validation loss: 0.5099
Epoch 9, Training loss: 0.5271, Validation loss: 0.4483
Epoch 10, Training loss: 0.5233, Validation loss: 0.4598
Epoch 11, Training loss: 0.5200, Validation loss: 0.4453
Epoch 12, Training loss: 0.5080, Validation loss: 0.4471
Epoch 13, Training loss: 0.5393, Validation loss: 0.4549
Epoch 14, Training loss: 0.5161, Validation loss: 0.4477
Epoch 15, Training loss: 0.5111, Validation loss: 0.4727
Epoch 16, Training loss: 0.5034, Validation loss: 0.4497
Epoch 17, Training loss: 0.5072, Validation loss: 0.4557
Epoch 18, Training loss: 0.5076, Validation loss: 0.4540
Epoch 19, Training loss: 0.5059, Validation loss: 0.4670
Epoch 20, Training loss: 0.5027, Validation loss: 0.4614
Epoch 21, Training loss: 0.5059, Validation loss: 0.4512
Early stopping.
Epoch 0, Training loss: 0.4545, Validation loss: 0.3664
Epoch 1, Training loss: 0.4316, Validation loss: 0.3644
Epoch 2, Training loss: 0.4268, Validation loss: 0.3572
Epoch 3, Training loss: 0.4181, Validation loss: 0.3631
Epoch 4, Training loss: 0.4153, Validation loss: 0.3601
Epoch 5, Training loss: 0.4130, Validation loss: 0.3570
Epoch 6, Training loss: 0.4110, Validation loss: 0.3561
Epoch 7, Training loss: 0.4094, Validation loss: 0.3555
Epoch 8, Training loss: 0.4081, Validation loss: 0.3565
Epoch 9, Training loss: 0.4067, Validation loss: 0.3532
Epoch 10, Training loss: 0.4062, Validation loss: 0.3464
Epoch 11, Training loss: 0.4049, Validation loss: 0.3497
Epoch 12, Training loss: 0.4039, Validation loss: 0.3508
Epoch 13, Training loss: 0.4032, Validation loss: 0.3486
Epoch 14, Training loss: 0.4026, Validation loss: 0.3461
Epoch 15, Training loss: 0.4017, Validation loss: 0.3467
Epoch 16, Training loss: 0.4013, Validation loss: 0.3467
Epoch 17, Training loss: 0.4009, Validation loss: 0.3447
Epoch 18, Training loss: 0.4006, Validation loss: 0.3429
Epoch 19, Training loss: 0.4000, Validation loss: 0.3448
Epoch 20, Training loss: 0.3995, Validation loss: 0.3473
Epoch 21, Training loss: 0.3991, Validation loss: 0.3459
Epoch 22, Training loss: 0.3987, Validation loss: 0.3448
Epoch 23, Training loss: 0.3985, Validation loss: 0.3432
Epoch 24, Training loss: 0.3982, Validation loss: 0.3428
Epoch 25, Training loss: 0.3977, Validation loss: 0.3434
Epoch 26, Training loss: 0.3973, Validation loss: 0.3450
Epoch 27, Training loss: 0.3971, Validation loss: 0.3445
Epoch 28, Training loss: 0.3969, Validation loss: 0.3455
Epoch 29, Training loss: 0.3966, Validation loss: 0.3402
Epoch 30, Training loss: 0.3963, Validation loss: 0.3400
Epoch 31, Training loss: 0.3960, Validation loss: 0.3401
Epoch 32, Training loss: 0.3960, Validation loss: 0.3397
Epoch 33, Training loss: 0.3961, Validation loss: 0.3381
Epoch 34, Training loss: 0.3958, Validation loss: 0.3400
Epoch 35, Training loss: 0.3955, Validation loss: 0.3414
Epoch 36, Training loss: 0.3955, Validation loss: 0.3431
Epoch 37, Training loss: 0.3953, Validation loss: 0.3412
Epoch 38, Training loss: 0.3953, Validation loss: 0.3396
Epoch 39, Training loss: 0.3953, Validation loss: 0.3390
Epoch 40, Training loss: 0.3953, Validation loss: 0.3380
Epoch 41, Training loss: 0.3950, Validation loss: 0.3385
Epoch 42, Training loss: 0.3948, Validation loss: 0.3393
Epoch 43, Training loss: 0.3946, Validation loss: 0.3395
Epoch 44, Training loss: 0.3946, Validation loss: 0.3414
Epoch 45, Training loss: 0.3945, Validation loss: 0.3408
Epoch 46, Training loss: 0.3947, Validation loss: 0.3390
Epoch 47, Training loss: 0.3946, Validation loss: 0.3408
Epoch 48, Training loss: 0.3946, Validation loss: 0.3402
Epoch 49, Training loss: 0.3947, Validation loss: 0.3380
Epoch 50, Training loss: 0.3945, Validation loss: 0.3382
Early stopping.
Epoch 0, Training loss: 0.5645, Validation loss: 0.4566
Epoch 1, Training loss: 0.5229, Validation loss: 0.4234
Epoch 2, Training loss: 0.4994, Validation loss: 0.3990
Epoch 3, Training loss: 0.4836, Validation loss: 0.3876
Epoch 4, Training loss: 0.4737, Validation loss: 0.3818
Epoch 5, Training loss: 0.4666, Validation loss: 0.3781
Epoch 6, Training loss: 0.4594, Validation loss: 0.3801
Epoch 7, Training loss: 0.4538, Validation loss: 0.3748
Epoch 8, Training loss: 0.4498, Validation loss: 0.3753
Epoch 9, Training loss: 0.4462, Validation loss: 0.3757
Epoch 10, Training loss: 0.4438, Validation loss: 0.3781
Epoch 11, Training loss: 0.4395, Validation loss: 0.3685
Epoch 12, Training loss: 0.4368, Validation loss: 0.3693
Epoch 13, Training loss: 0.4344, Validation loss: 0.3685
Epoch 14, Training loss: 0.4314, Validation loss: 0.3641
Epoch 15, Training loss: 0.4293, Validation loss: 0.3600
Epoch 16, Training loss: 0.4272, Validation loss: 0.3595
Epoch 17, Training loss: 0.4253, Validation loss: 0.3574
Epoch 18, Training loss: 0.4236, Validation loss: 0.3579
Epoch 19, Training loss: 0.4220, Validation loss: 0.3558
Epoch 20, Training loss: 0.4208, Validation loss: 0.3531
Epoch 21, Training loss: 0.4204, Validation loss: 0.3619
Epoch 22, Training loss: 0.4193, Validation loss: 0.3633
Epoch 23, Training loss: 0.4179, Validation loss: 0.3629
Epoch 24, Training loss: 0.4156, Validation loss: 0.3551
Epoch 25, Training loss: 0.4147, Validation loss: 0.3530
Epoch 26, Training loss: 0.4137, Validation loss: 0.3499
Epoch 27, Training loss: 0.4132, Validation loss: 0.3526
Epoch 28, Training loss: 0.4123, Validation loss: 0.3512
Epoch 29, Training loss: 0.4113, Validation loss: 0.3470
Epoch 30, Training loss: 0.4107, Validation loss: 0.3483
Epoch 31, Training loss: 0.4100, Validation loss: 0.3444
Epoch 32, Training loss: 0.4094, Validation loss: 0.3453
Epoch 33, Training loss: 0.4088, Validation loss: 0.3453
Epoch 34, Training loss: 0.4082, Validation loss: 0.3441
Epoch 35, Training loss: 0.4077, Validation loss: 0.3435
Epoch 36, Training loss: 0.4074, Validation loss: 0.3410
Epoch 37, Training loss: 0.4070, Validation loss: 0.3405
Epoch 38, Training loss: 0.4063, Validation loss: 0.3435
Epoch 39, Training loss: 0.4060, Validation loss: 0.3461
Epoch 40, Training loss: 0.4056, Validation loss: 0.3458
Epoch 41, Training loss: 0.4048, Validation loss: 0.3410
Epoch 42, Training loss: 0.4046, Validation loss: 0.3389
Epoch 43, Training loss: 0.4042, Validation loss: 0.3371
Epoch 44, Training loss: 0.4042, Validation loss: 0.3355
Epoch 45, Training loss: 0.4033, Validation loss: 0.3372
Epoch 46, Training loss: 0.4029, Validation loss: 0.3419
Epoch 47, Training loss: 0.4025, Validation loss: 0.3388
Epoch 48, Training loss: 0.4021, Validation loss: 0.3371
Epoch 49, Training loss: 0.4017, Validation loss: 0.3371
Epoch 50, Training loss: 0.4014, Validation loss: 0.3382
Epoch 51, Training loss: 0.4012, Validation loss: 0.3363
Epoch 52, Training loss: 0.4009, Validation loss: 0.3388
Epoch 53, Training loss: 0.4006, Validation loss: 0.3413
Epoch 54, Training loss: 0.4007, Validation loss: 0.3367
Early stopping.
Epoch 0, Training loss: 0.8653, Validation loss: 0.6032
Epoch 1, Training loss: 0.6737, Validation loss: 0.4922
Epoch 2, Training loss: 0.6149, Validation loss: 0.4643
Epoch 3, Training loss: 0.5846, Validation loss: 0.4498
Epoch 4, Training loss: 0.5631, Validation loss: 0.4342
Epoch 5, Training loss: 0.5460, Validation loss: 0.4238
Epoch 6, Training loss: 0.5271, Validation loss: 0.4018
Epoch 7, Training loss: 0.5137, Validation loss: 0.3916
Epoch 8, Training loss: 0.5014, Validation loss: 0.3874
Epoch 9, Training loss: 0.4934, Validation loss: 0.3816
Epoch 10, Training loss: 0.4856, Validation loss: 0.3897
Epoch 11, Training loss: 0.4788, Validation loss: 0.3863
Epoch 12, Training loss: 0.4718, Validation loss: 0.3747
Epoch 13, Training loss: 0.4660, Validation loss: 0.3704
Epoch 14, Training loss: 0.4615, Validation loss: 0.3652
Epoch 15, Training loss: 0.4574, Validation loss: 0.3637
Epoch 16, Training loss: 0.4544, Validation loss: 0.3617
Epoch 17, Training loss: 0.4513, Validation loss: 0.3622
Epoch 18, Training loss: 0.4484, Validation loss: 0.3586
Epoch 19, Training loss: 0.4447, Validation loss: 0.3595
Epoch 20, Training loss: 0.4422, Validation loss: 0.3542
Epoch 21, Training loss: 0.4396, Validation loss: 0.3499
Epoch 22, Training loss: 0.4375, Validation loss: 0.3510
Epoch 23, Training loss: 0.4351, Validation loss: 0.3500
Epoch 24, Training loss: 0.4331, Validation loss: 0.3507
Epoch 25, Training loss: 0.4311, Validation loss: 0.3517
Epoch 26, Training loss: 0.4290, Validation loss: 0.3505
Epoch 27, Training loss: 0.4273, Validation loss: 0.3510
Epoch 28, Training loss: 0.4262, Validation loss: 0.3472
Epoch 29, Training loss: 0.4241, Validation loss: 0.3529
Epoch 30, Training loss: 0.4227, Validation loss: 0.3546
Epoch 31, Training loss: 0.4213, Validation loss: 0.3594
Epoch 32, Training loss: 0.4203, Validation loss: 0.3586
Epoch 33, Training loss: 0.4191, Validation loss: 0.3558
Epoch 34, Training loss: 0.4182, Validation loss: 0.3537
Epoch 35, Training loss: 0.4173, Validation loss: 0.3538
Epoch 36, Training loss: 0.4166, Validation loss: 0.3531
Epoch 37, Training loss: 0.4161, Validation loss: 0.3489
Epoch 38, Training loss: 0.4152, Validation loss: 0.3495
Early stopping.
