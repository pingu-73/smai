Epoch 0, Training loss: 1.1909, Validation loss: 0.9357
Epoch 1, Training loss: 1.1776, Validation loss: 0.9253
Epoch 2, Training loss: 1.1638, Validation loss: 0.9147
Epoch 3, Training loss: 1.1500, Validation loss: 0.9041
Epoch 4, Training loss: 1.1375, Validation loss: 0.8945
Epoch 5, Training loss: 1.1252, Validation loss: 0.8853
Epoch 6, Training loss: 1.1132, Validation loss: 0.8763
Epoch 7, Training loss: 1.1012, Validation loss: 0.8675
Epoch 8, Training loss: 1.0897, Validation loss: 0.8589
Epoch 9, Training loss: 1.0782, Validation loss: 0.8505
Epoch 10, Training loss: 1.0670, Validation loss: 0.8422
Epoch 11, Training loss: 1.0557, Validation loss: 0.8339
Epoch 12, Training loss: 1.0452, Validation loss: 0.8260
Epoch 13, Training loss: 1.0348, Validation loss: 0.8182
Epoch 14, Training loss: 1.0248, Validation loss: 0.8104
Epoch 15, Training loss: 1.0152, Validation loss: 0.8028
Epoch 16, Training loss: 1.0058, Validation loss: 0.7954
Epoch 17, Training loss: 0.9967, Validation loss: 0.7881
Epoch 18, Training loss: 0.9879, Validation loss: 0.7811
Epoch 19, Training loss: 0.9798, Validation loss: 0.7744
Epoch 20, Training loss: 0.9717, Validation loss: 0.7677
Epoch 21, Training loss: 0.9638, Validation loss: 0.7612
Epoch 22, Training loss: 0.9564, Validation loss: 0.7550
Epoch 23, Training loss: 0.9491, Validation loss: 0.7489
Epoch 24, Training loss: 0.9415, Validation loss: 0.7425
Epoch 25, Training loss: 0.9342, Validation loss: 0.7365
Epoch 26, Training loss: 0.9263, Validation loss: 0.7304
Epoch 27, Training loss: 0.9193, Validation loss: 0.7249
Epoch 28, Training loss: 0.9117, Validation loss: 0.7190
Epoch 29, Training loss: 0.9049, Validation loss: 0.7141
Epoch 30, Training loss: 0.8988, Validation loss: 0.7101
Epoch 31, Training loss: 0.8922, Validation loss: 0.7056
Epoch 32, Training loss: 0.8864, Validation loss: 0.7017
Epoch 33, Training loss: 0.8807, Validation loss: 0.6979
Epoch 34, Training loss: 0.8750, Validation loss: 0.6942
Epoch 35, Training loss: 0.8690, Validation loss: 0.6902
Epoch 36, Training loss: 0.8637, Validation loss: 0.6868
Epoch 37, Training loss: 0.8585, Validation loss: 0.6833
Epoch 38, Training loss: 0.8533, Validation loss: 0.6799
Epoch 39, Training loss: 0.8481, Validation loss: 0.6764
Epoch 40, Training loss: 0.8434, Validation loss: 0.6733
Epoch 41, Training loss: 0.8386, Validation loss: 0.6701
Epoch 42, Training loss: 0.8337, Validation loss: 0.6668
Epoch 43, Training loss: 0.8289, Validation loss: 0.6637
Epoch 44, Training loss: 0.8243, Validation loss: 0.6606
Epoch 45, Training loss: 0.8193, Validation loss: 0.6572
Epoch 46, Training loss: 0.8148, Validation loss: 0.6543
Epoch 47, Training loss: 0.8104, Validation loss: 0.6513
Epoch 48, Training loss: 0.8056, Validation loss: 0.6482
Epoch 49, Training loss: 0.8011, Validation loss: 0.6451
Epoch 50, Training loss: 0.7968, Validation loss: 0.6421
Epoch 51, Training loss: 0.7931, Validation loss: 0.6395
Epoch 52, Training loss: 0.7893, Validation loss: 0.6370
Epoch 53, Training loss: 0.7857, Validation loss: 0.6346
Epoch 54, Training loss: 0.7822, Validation loss: 0.6323
Epoch 55, Training loss: 0.7783, Validation loss: 0.6298
Epoch 56, Training loss: 0.7748, Validation loss: 0.6276
Epoch 57, Training loss: 0.7716, Validation loss: 0.6254
Epoch 58, Training loss: 0.7682, Validation loss: 0.6232
Epoch 59, Training loss: 0.7649, Validation loss: 0.6210
Epoch 60, Training loss: 0.7617, Validation loss: 0.6189
Epoch 61, Training loss: 0.7587, Validation loss: 0.6169
Epoch 62, Training loss: 0.7556, Validation loss: 0.6149
Epoch 63, Training loss: 0.7525, Validation loss: 0.6128
Epoch 64, Training loss: 0.7491, Validation loss: 0.6106
Epoch 65, Training loss: 0.7462, Validation loss: 0.6086
Epoch 66, Training loss: 0.7429, Validation loss: 0.6065
Epoch 67, Training loss: 0.7401, Validation loss: 0.6046
Epoch 68, Training loss: 0.7374, Validation loss: 0.6028
Epoch 69, Training loss: 0.7340, Validation loss: 0.6004
Epoch 70, Training loss: 0.7311, Validation loss: 0.5985
Epoch 71, Training loss: 0.7285, Validation loss: 0.5968
Epoch 72, Training loss: 0.7260, Validation loss: 0.5951
Epoch 73, Training loss: 0.7235, Validation loss: 0.5934
Epoch 74, Training loss: 0.7211, Validation loss: 0.5918
Epoch 75, Training loss: 0.7187, Validation loss: 0.5902
Epoch 76, Training loss: 0.7163, Validation loss: 0.5886
Epoch 77, Training loss: 0.7140, Validation loss: 0.5870
Epoch 78, Training loss: 0.7116, Validation loss: 0.5853
Epoch 79, Training loss: 0.7093, Validation loss: 0.5838
Epoch 80, Training loss: 0.7070, Validation loss: 0.5822
Epoch 81, Training loss: 0.7049, Validation loss: 0.5808
Epoch 82, Training loss: 0.7028, Validation loss: 0.5793
Epoch 83, Training loss: 0.7010, Validation loss: 0.5779
Epoch 84, Training loss: 0.6987, Validation loss: 0.5762
Epoch 85, Training loss: 0.6968, Validation loss: 0.5748
Epoch 86, Training loss: 0.6951, Validation loss: 0.5736
Epoch 87, Training loss: 0.6934, Validation loss: 0.5723
Epoch 88, Training loss: 0.6915, Validation loss: 0.5710
Epoch 89, Training loss: 0.6897, Validation loss: 0.5697
Epoch 90, Training loss: 0.6881, Validation loss: 0.5686
Epoch 91, Training loss: 0.6864, Validation loss: 0.5676
Epoch 92, Training loss: 0.6848, Validation loss: 0.5666
Epoch 93, Training loss: 0.6833, Validation loss: 0.5657
Epoch 94, Training loss: 0.6816, Validation loss: 0.5647
Epoch 95, Training loss: 0.6801, Validation loss: 0.5638
Epoch 96, Training loss: 0.6785, Validation loss: 0.5628
Epoch 97, Training loss: 0.6769, Validation loss: 0.5619
Epoch 98, Training loss: 0.6754, Validation loss: 0.5610
Epoch 99, Training loss: 0.6740, Validation loss: 0.5602
Epoch 100, Training loss: 0.6727, Validation loss: 0.5594
Epoch 101, Training loss: 0.6714, Validation loss: 0.5586
Epoch 102, Training loss: 0.6701, Validation loss: 0.5579
Epoch 103, Training loss: 0.6686, Validation loss: 0.5570
Epoch 104, Training loss: 0.6674, Validation loss: 0.5562
Epoch 105, Training loss: 0.6662, Validation loss: 0.5554
Epoch 106, Training loss: 0.6651, Validation loss: 0.5547
Epoch 107, Training loss: 0.6639, Validation loss: 0.5540
Epoch 108, Training loss: 0.6628, Validation loss: 0.5533
Epoch 109, Training loss: 0.6617, Validation loss: 0.5526
Epoch 110, Training loss: 0.6606, Validation loss: 0.5519
Epoch 111, Training loss: 0.6596, Validation loss: 0.5512
Epoch 112, Training loss: 0.6585, Validation loss: 0.5505
Epoch 113, Training loss: 0.6574, Validation loss: 0.5498
Epoch 114, Training loss: 0.6564, Validation loss: 0.5492
Epoch 115, Training loss: 0.6553, Validation loss: 0.5484
Epoch 116, Training loss: 0.6543, Validation loss: 0.5478
Epoch 117, Training loss: 0.6533, Validation loss: 0.5471
Epoch 118, Training loss: 0.6524, Validation loss: 0.5465
Epoch 119, Training loss: 0.6515, Validation loss: 0.5460
Epoch 120, Training loss: 0.6506, Validation loss: 0.5454
Epoch 121, Training loss: 0.6496, Validation loss: 0.5447
Epoch 122, Training loss: 0.6487, Validation loss: 0.5442
Epoch 123, Training loss: 0.6478, Validation loss: 0.5436
Epoch 124, Training loss: 0.6470, Validation loss: 0.5431
Epoch 125, Training loss: 0.6461, Validation loss: 0.5425
Epoch 126, Training loss: 0.6452, Validation loss: 0.5420
Epoch 127, Training loss: 0.6442, Validation loss: 0.5414
Epoch 128, Training loss: 0.6434, Validation loss: 0.5408
Epoch 129, Training loss: 0.6425, Validation loss: 0.5403
Epoch 130, Training loss: 0.6417, Validation loss: 0.5399
Epoch 131, Training loss: 0.6409, Validation loss: 0.5396
Epoch 132, Training loss: 0.6401, Validation loss: 0.5392
Epoch 133, Training loss: 0.6393, Validation loss: 0.5388
Epoch 134, Training loss: 0.6386, Validation loss: 0.5385
Epoch 135, Training loss: 0.6376, Validation loss: 0.5380
Epoch 136, Training loss: 0.6369, Validation loss: 0.5377
Epoch 137, Training loss: 0.6362, Validation loss: 0.5373
Epoch 138, Training loss: 0.6354, Validation loss: 0.5369
Epoch 139, Training loss: 0.6346, Validation loss: 0.5365
Epoch 140, Training loss: 0.6340, Validation loss: 0.5361
Epoch 141, Training loss: 0.6332, Validation loss: 0.5357
Epoch 142, Training loss: 0.6325, Validation loss: 0.5353
Epoch 143, Training loss: 0.6318, Validation loss: 0.5350
Epoch 144, Training loss: 0.6312, Validation loss: 0.5346
Epoch 145, Training loss: 0.6305, Validation loss: 0.5343
Epoch 146, Training loss: 0.6299, Validation loss: 0.5339
Epoch 147, Training loss: 0.6293, Validation loss: 0.5336
Epoch 148, Training loss: 0.6286, Validation loss: 0.5332
Epoch 149, Training loss: 0.6280, Validation loss: 0.5329
Epoch 150, Training loss: 0.6273, Validation loss: 0.5326
Epoch 151, Training loss: 0.6267, Validation loss: 0.5322
Epoch 152, Training loss: 0.6259, Validation loss: 0.5318
Epoch 153, Training loss: 0.6253, Validation loss: 0.5315
Epoch 154, Training loss: 0.6246, Validation loss: 0.5311
Epoch 155, Training loss: 0.6240, Validation loss: 0.5308
Epoch 156, Training loss: 0.6234, Validation loss: 0.5304
Epoch 157, Training loss: 0.6229, Validation loss: 0.5301
Epoch 158, Training loss: 0.6223, Validation loss: 0.5298
Epoch 159, Training loss: 0.6216, Validation loss: 0.5295
Epoch 160, Training loss: 0.6209, Validation loss: 0.5292
Epoch 161, Training loss: 0.6203, Validation loss: 0.5288
Epoch 162, Training loss: 0.6198, Validation loss: 0.5286
Epoch 163, Training loss: 0.6193, Validation loss: 0.5283
Epoch 164, Training loss: 0.6188, Validation loss: 0.5280
Epoch 165, Training loss: 0.6183, Validation loss: 0.5277
Epoch 166, Training loss: 0.6178, Validation loss: 0.5274
Epoch 167, Training loss: 0.6173, Validation loss: 0.5271
Epoch 168, Training loss: 0.6168, Validation loss: 0.5268
Epoch 169, Training loss: 0.6163, Validation loss: 0.5266
Epoch 170, Training loss: 0.6158, Validation loss: 0.5263
Epoch 171, Training loss: 0.6153, Validation loss: 0.5260
Epoch 172, Training loss: 0.6148, Validation loss: 0.5257
Epoch 173, Training loss: 0.6144, Validation loss: 0.5255
Epoch 174, Training loss: 0.6139, Validation loss: 0.5252
Epoch 175, Training loss: 0.6135, Validation loss: 0.5250
Epoch 176, Training loss: 0.6132, Validation loss: 0.5247
Epoch 177, Training loss: 0.6127, Validation loss: 0.5245
Epoch 178, Training loss: 0.6123, Validation loss: 0.5242
Epoch 179, Training loss: 0.6118, Validation loss: 0.5240
Epoch 180, Training loss: 0.6114, Validation loss: 0.5237
Epoch 181, Training loss: 0.6109, Validation loss: 0.5234
Epoch 182, Training loss: 0.6105, Validation loss: 0.5232
Epoch 183, Training loss: 0.6101, Validation loss: 0.5229
Epoch 184, Training loss: 0.6097, Validation loss: 0.5227
Epoch 185, Training loss: 0.6092, Validation loss: 0.5224
Epoch 186, Training loss: 0.6088, Validation loss: 0.5222
Epoch 187, Training loss: 0.6084, Validation loss: 0.5219
Epoch 188, Training loss: 0.6080, Validation loss: 0.5217
Epoch 189, Training loss: 0.6076, Validation loss: 0.5214
Epoch 190, Training loss: 0.6072, Validation loss: 0.5212
Epoch 191, Training loss: 0.6068, Validation loss: 0.5210
Epoch 192, Training loss: 0.6064, Validation loss: 0.5207
Epoch 193, Training loss: 0.6060, Validation loss: 0.5205
Epoch 194, Training loss: 0.6056, Validation loss: 0.5203
Epoch 195, Training loss: 0.6051, Validation loss: 0.5199
Epoch 196, Training loss: 0.6047, Validation loss: 0.5197
Epoch 197, Training loss: 0.6043, Validation loss: 0.5195
Epoch 198, Training loss: 0.6040, Validation loss: 0.5193
Epoch 199, Training loss: 0.6035, Validation loss: 0.5190
Epoch 200, Training loss: 0.6031, Validation loss: 0.5188
Epoch 201, Training loss: 0.6027, Validation loss: 0.5185
Epoch 202, Training loss: 0.6023, Validation loss: 0.5183
Epoch 203, Training loss: 0.6020, Validation loss: 0.5181
Epoch 204, Training loss: 0.6016, Validation loss: 0.5178
Epoch 205, Training loss: 0.6013, Validation loss: 0.5176
Epoch 206, Training loss: 0.6009, Validation loss: 0.5174
Epoch 207, Training loss: 0.6006, Validation loss: 0.5172
Epoch 208, Training loss: 0.6002, Validation loss: 0.5170
Epoch 209, Training loss: 0.5998, Validation loss: 0.5168
Epoch 210, Training loss: 0.5995, Validation loss: 0.5165
Epoch 211, Training loss: 0.5991, Validation loss: 0.5163
Epoch 212, Training loss: 0.5988, Validation loss: 0.5161
Epoch 213, Training loss: 0.5985, Validation loss: 0.5159
Epoch 214, Training loss: 0.5981, Validation loss: 0.5157
Epoch 215, Training loss: 0.5978, Validation loss: 0.5155
Epoch 216, Training loss: 0.5975, Validation loss: 0.5153
Epoch 217, Training loss: 0.5972, Validation loss: 0.5151
Epoch 218, Training loss: 0.5968, Validation loss: 0.5149
Epoch 219, Training loss: 0.5965, Validation loss: 0.5148
Epoch 220, Training loss: 0.5962, Validation loss: 0.5146
Epoch 221, Training loss: 0.5958, Validation loss: 0.5144
Epoch 222, Training loss: 0.5955, Validation loss: 0.5142
Epoch 223, Training loss: 0.5952, Validation loss: 0.5141
Epoch 224, Training loss: 0.5949, Validation loss: 0.5139
Epoch 225, Training loss: 0.5946, Validation loss: 0.5137
Epoch 226, Training loss: 0.5943, Validation loss: 0.5135
Epoch 227, Training loss: 0.5940, Validation loss: 0.5134
Epoch 228, Training loss: 0.5936, Validation loss: 0.5131
Epoch 229, Training loss: 0.5933, Validation loss: 0.5130
Epoch 230, Training loss: 0.5929, Validation loss: 0.5129
Epoch 231, Training loss: 0.5927, Validation loss: 0.5127
Epoch 232, Training loss: 0.5924, Validation loss: 0.5125
Epoch 233, Training loss: 0.5921, Validation loss: 0.5124
Epoch 234, Training loss: 0.5918, Validation loss: 0.5122
Epoch 235, Training loss: 0.5915, Validation loss: 0.5120
Epoch 236, Training loss: 0.5912, Validation loss: 0.5119
Epoch 237, Training loss: 0.5909, Validation loss: 0.5117
Epoch 238, Training loss: 0.5907, Validation loss: 0.5115
Epoch 239, Training loss: 0.5904, Validation loss: 0.5114
Epoch 240, Training loss: 0.5901, Validation loss: 0.5112
Epoch 241, Training loss: 0.5898, Validation loss: 0.5111
Epoch 242, Training loss: 0.5896, Validation loss: 0.5109
Epoch 243, Training loss: 0.5893, Validation loss: 0.5108
Epoch 244, Training loss: 0.5890, Validation loss: 0.5106
Epoch 245, Training loss: 0.5888, Validation loss: 0.5105
Epoch 246, Training loss: 0.5885, Validation loss: 0.5103
Epoch 247, Training loss: 0.5882, Validation loss: 0.5102
Epoch 248, Training loss: 0.5880, Validation loss: 0.5100
Epoch 249, Training loss: 0.5877, Validation loss: 0.5098
Epoch 250, Training loss: 0.5875, Validation loss: 0.5097
Epoch 251, Training loss: 0.5871, Validation loss: 0.5095
Epoch 252, Training loss: 0.5867, Validation loss: 0.5094
Epoch 253, Training loss: 0.5865, Validation loss: 0.5092
Epoch 254, Training loss: 0.5862, Validation loss: 0.5091
Epoch 255, Training loss: 0.5860, Validation loss: 0.5089
Epoch 256, Training loss: 0.5857, Validation loss: 0.5087
Epoch 257, Training loss: 0.5855, Validation loss: 0.5085
Epoch 258, Training loss: 0.5852, Validation loss: 0.5084
Epoch 259, Training loss: 0.5849, Validation loss: 0.5083
Epoch 260, Training loss: 0.5847, Validation loss: 0.5081
Epoch 261, Training loss: 0.5844, Validation loss: 0.5080
Epoch 262, Training loss: 0.5842, Validation loss: 0.5078
Epoch 263, Training loss: 0.5839, Validation loss: 0.5077
Epoch 264, Training loss: 0.5837, Validation loss: 0.5075
Epoch 265, Training loss: 0.5835, Validation loss: 0.5074
Epoch 266, Training loss: 0.5832, Validation loss: 0.5072
Epoch 267, Training loss: 0.5830, Validation loss: 0.5071
Epoch 268, Training loss: 0.5827, Validation loss: 0.5070
Epoch 269, Training loss: 0.5825, Validation loss: 0.5068
Epoch 270, Training loss: 0.5823, Validation loss: 0.5067
Epoch 271, Training loss: 0.5820, Validation loss: 0.5066
Epoch 272, Training loss: 0.5818, Validation loss: 0.5064
Epoch 273, Training loss: 0.5816, Validation loss: 0.5063
Epoch 274, Training loss: 0.5814, Validation loss: 0.5062
Epoch 275, Training loss: 0.5812, Validation loss: 0.5061
Epoch 276, Training loss: 0.5809, Validation loss: 0.5059
Epoch 277, Training loss: 0.5807, Validation loss: 0.5058
Epoch 278, Training loss: 0.5805, Validation loss: 0.5056
Epoch 279, Training loss: 0.5802, Validation loss: 0.5055
Epoch 280, Training loss: 0.5800, Validation loss: 0.5054
Epoch 281, Training loss: 0.5798, Validation loss: 0.5052
Epoch 282, Training loss: 0.5796, Validation loss: 0.5051
Epoch 283, Training loss: 0.5794, Validation loss: 0.5050
Epoch 284, Training loss: 0.5792, Validation loss: 0.5049
Epoch 285, Training loss: 0.5790, Validation loss: 0.5048
Epoch 286, Training loss: 0.5788, Validation loss: 0.5046
Epoch 287, Training loss: 0.5785, Validation loss: 0.5045
Epoch 288, Training loss: 0.5783, Validation loss: 0.5044
Epoch 289, Training loss: 0.5781, Validation loss: 0.5043
Epoch 290, Training loss: 0.5779, Validation loss: 0.5042
Epoch 291, Training loss: 0.5777, Validation loss: 0.5040
Epoch 292, Training loss: 0.5775, Validation loss: 0.5039
Epoch 293, Training loss: 0.5773, Validation loss: 0.5038
Epoch 294, Training loss: 0.5771, Validation loss: 0.5036
Epoch 295, Training loss: 0.5769, Validation loss: 0.5035
Epoch 296, Training loss: 0.5767, Validation loss: 0.5033
Epoch 297, Training loss: 0.5765, Validation loss: 0.5032
Epoch 298, Training loss: 0.5764, Validation loss: 0.5031
Epoch 299, Training loss: 0.5761, Validation loss: 0.5030
Epoch 300, Training loss: 0.5759, Validation loss: 0.5029
Epoch 301, Training loss: 0.5757, Validation loss: 0.5028
Epoch 302, Training loss: 0.5755, Validation loss: 0.5026
Epoch 303, Training loss: 0.5753, Validation loss: 0.5025
Epoch 304, Training loss: 0.5752, Validation loss: 0.5024
Epoch 305, Training loss: 0.5750, Validation loss: 0.5023
Epoch 306, Training loss: 0.5748, Validation loss: 0.5021
Epoch 307, Training loss: 0.5745, Validation loss: 0.5020
Epoch 308, Training loss: 0.5744, Validation loss: 0.5019
Epoch 309, Training loss: 0.5742, Validation loss: 0.5018
Epoch 310, Training loss: 0.5740, Validation loss: 0.5017
Epoch 311, Training loss: 0.5738, Validation loss: 0.5016
Epoch 312, Training loss: 0.5736, Validation loss: 0.5015
Epoch 313, Training loss: 0.5734, Validation loss: 0.5013
Epoch 314, Training loss: 0.5733, Validation loss: 0.5011
Epoch 315, Training loss: 0.5731, Validation loss: 0.5010
Epoch 316, Training loss: 0.5729, Validation loss: 0.5010
Epoch 317, Training loss: 0.5727, Validation loss: 0.5009
Epoch 318, Training loss: 0.5725, Validation loss: 0.5007
Epoch 319, Training loss: 0.5723, Validation loss: 0.5006
Epoch 320, Training loss: 0.5721, Validation loss: 0.5005
Epoch 321, Training loss: 0.5720, Validation loss: 0.5004
Epoch 322, Training loss: 0.5717, Validation loss: 0.5003
Epoch 323, Training loss: 0.5715, Validation loss: 0.5002
Epoch 324, Training loss: 0.5713, Validation loss: 0.5001
Epoch 325, Training loss: 0.5712, Validation loss: 0.5000
Epoch 326, Training loss: 0.5711, Validation loss: 0.5000
Epoch 327, Training loss: 0.5708, Validation loss: 0.4999
Epoch 328, Training loss: 0.5707, Validation loss: 0.4998
Epoch 329, Training loss: 0.5705, Validation loss: 0.4997
Epoch 330, Training loss: 0.5704, Validation loss: 0.4996
Epoch 331, Training loss: 0.5702, Validation loss: 0.4995
Epoch 332, Training loss: 0.5700, Validation loss: 0.4993
Epoch 333, Training loss: 0.5699, Validation loss: 0.4992
Epoch 334, Training loss: 0.5697, Validation loss: 0.4992
Epoch 335, Training loss: 0.5695, Validation loss: 0.4991
Epoch 336, Training loss: 0.5694, Validation loss: 0.4990
Epoch 337, Training loss: 0.5692, Validation loss: 0.4989
Epoch 338, Training loss: 0.5690, Validation loss: 0.4988
Epoch 339, Training loss: 0.5689, Validation loss: 0.4987
Epoch 340, Training loss: 0.5687, Validation loss: 0.4986
Epoch 341, Training loss: 0.5685, Validation loss: 0.4985
Epoch 342, Training loss: 0.5684, Validation loss: 0.4984
Epoch 343, Training loss: 0.5682, Validation loss: 0.4983
Epoch 344, Training loss: 0.5681, Validation loss: 0.4982
Epoch 345, Training loss: 0.5679, Validation loss: 0.4981
Epoch 346, Training loss: 0.5678, Validation loss: 0.4980
Epoch 347, Training loss: 0.5677, Validation loss: 0.4979
Epoch 348, Training loss: 0.5675, Validation loss: 0.4978
Epoch 349, Training loss: 0.5673, Validation loss: 0.4977
Epoch 350, Training loss: 0.5672, Validation loss: 0.4976
Epoch 351, Training loss: 0.5671, Validation loss: 0.4975
Epoch 352, Training loss: 0.5669, Validation loss: 0.4974
Epoch 353, Training loss: 0.5668, Validation loss: 0.4974
Epoch 354, Training loss: 0.5667, Validation loss: 0.4973
Epoch 355, Training loss: 0.5665, Validation loss: 0.4972
Epoch 356, Training loss: 0.5663, Validation loss: 0.4971
Epoch 357, Training loss: 0.5662, Validation loss: 0.4970
Epoch 358, Training loss: 0.5661, Validation loss: 0.4969
Epoch 359, Training loss: 0.5660, Validation loss: 0.4968
Epoch 360, Training loss: 0.5658, Validation loss: 0.4968
Epoch 361, Training loss: 0.5657, Validation loss: 0.4967
Epoch 362, Training loss: 0.5655, Validation loss: 0.4966
Epoch 363, Training loss: 0.5654, Validation loss: 0.4965
Epoch 364, Training loss: 0.5652, Validation loss: 0.4964
Epoch 365, Training loss: 0.5651, Validation loss: 0.4964
Epoch 366, Training loss: 0.5650, Validation loss: 0.4963
Epoch 367, Training loss: 0.5649, Validation loss: 0.4962
Epoch 368, Training loss: 0.5647, Validation loss: 0.4961
Epoch 369, Training loss: 0.5646, Validation loss: 0.4960
Epoch 370, Training loss: 0.5645, Validation loss: 0.4960
Epoch 371, Training loss: 0.5643, Validation loss: 0.4959
Epoch 372, Training loss: 0.5642, Validation loss: 0.4958
Epoch 373, Training loss: 0.5641, Validation loss: 0.4957
Epoch 374, Training loss: 0.5640, Validation loss: 0.4956
Epoch 375, Training loss: 0.5638, Validation loss: 0.4955
Epoch 376, Training loss: 0.5637, Validation loss: 0.4954
Epoch 377, Training loss: 0.5636, Validation loss: 0.4953
Epoch 378, Training loss: 0.5635, Validation loss: 0.4952
Epoch 379, Training loss: 0.5634, Validation loss: 0.4952
Epoch 380, Training loss: 0.5633, Validation loss: 0.4951
Epoch 381, Training loss: 0.5631, Validation loss: 0.4950
Epoch 382, Training loss: 0.5630, Validation loss: 0.4949
Epoch 383, Training loss: 0.5629, Validation loss: 0.4948
Epoch 384, Training loss: 0.5628, Validation loss: 0.4948
Epoch 385, Training loss: 0.5627, Validation loss: 0.4947
Epoch 386, Training loss: 0.5625, Validation loss: 0.4946
Epoch 387, Training loss: 0.5624, Validation loss: 0.4945
Epoch 388, Training loss: 0.5623, Validation loss: 0.4944
Epoch 389, Training loss: 0.5622, Validation loss: 0.4943
Epoch 390, Training loss: 0.5621, Validation loss: 0.4942
Epoch 391, Training loss: 0.5620, Validation loss: 0.4941
Epoch 392, Training loss: 0.5618, Validation loss: 0.4940
Epoch 393, Training loss: 0.5617, Validation loss: 0.4940
Epoch 394, Training loss: 0.5616, Validation loss: 0.4939
Epoch 395, Training loss: 0.5615, Validation loss: 0.4938
Epoch 396, Training loss: 0.5614, Validation loss: 0.4937
Epoch 397, Training loss: 0.5613, Validation loss: 0.4936
Epoch 398, Training loss: 0.5611, Validation loss: 0.4936
Epoch 399, Training loss: 0.5610, Validation loss: 0.4935
Epoch 400, Training loss: 0.5609, Validation loss: 0.4934
Epoch 401, Training loss: 0.5608, Validation loss: 0.4933
Epoch 402, Training loss: 0.5607, Validation loss: 0.4932
Epoch 403, Training loss: 0.5606, Validation loss: 0.4932
Epoch 404, Training loss: 0.5604, Validation loss: 0.4931
Epoch 405, Training loss: 0.5603, Validation loss: 0.4931
Epoch 406, Training loss: 0.5602, Validation loss: 0.4930
Epoch 407, Training loss: 0.5601, Validation loss: 0.4929
Epoch 408, Training loss: 0.5600, Validation loss: 0.4929
Epoch 409, Training loss: 0.5599, Validation loss: 0.4928
Epoch 410, Training loss: 0.5598, Validation loss: 0.4927
Epoch 411, Training loss: 0.5597, Validation loss: 0.4926
Epoch 412, Training loss: 0.5596, Validation loss: 0.4926
Epoch 413, Training loss: 0.5595, Validation loss: 0.4925
Epoch 414, Training loss: 0.5594, Validation loss: 0.4925
Epoch 415, Training loss: 0.5593, Validation loss: 0.4924
Epoch 416, Training loss: 0.5592, Validation loss: 0.4923
Epoch 417, Training loss: 0.5591, Validation loss: 0.4922
Epoch 418, Training loss: 0.5590, Validation loss: 0.4921
Epoch 419, Training loss: 0.5589, Validation loss: 0.4920
Epoch 420, Training loss: 0.5588, Validation loss: 0.4919
Epoch 421, Training loss: 0.5586, Validation loss: 0.4919
Epoch 422, Training loss: 0.5585, Validation loss: 0.4918
Epoch 423, Training loss: 0.5584, Validation loss: 0.4917
Epoch 424, Training loss: 0.5583, Validation loss: 0.4917
Epoch 425, Training loss: 0.5582, Validation loss: 0.4916
Epoch 426, Training loss: 0.5581, Validation loss: 0.4915
Epoch 427, Training loss: 0.5580, Validation loss: 0.4915
Epoch 428, Training loss: 0.5579, Validation loss: 0.4915
Epoch 429, Training loss: 0.5578, Validation loss: 0.4914
Epoch 430, Training loss: 0.5577, Validation loss: 0.4913
Epoch 431, Training loss: 0.5576, Validation loss: 0.4912
Epoch 432, Training loss: 0.5575, Validation loss: 0.4912
Epoch 433, Training loss: 0.5574, Validation loss: 0.4911
Epoch 434, Training loss: 0.5573, Validation loss: 0.4910
Epoch 435, Training loss: 0.5572, Validation loss: 0.4910
Epoch 436, Training loss: 0.5572, Validation loss: 0.4909
Epoch 437, Training loss: 0.5571, Validation loss: 0.4908
Epoch 438, Training loss: 0.5570, Validation loss: 0.4908
Epoch 439, Training loss: 0.5569, Validation loss: 0.4907
Epoch 440, Training loss: 0.5568, Validation loss: 0.4907
Epoch 441, Training loss: 0.5567, Validation loss: 0.4906
Epoch 442, Training loss: 0.5566, Validation loss: 0.4905
Epoch 443, Training loss: 0.5565, Validation loss: 0.4905
Epoch 444, Training loss: 0.5564, Validation loss: 0.4904
Epoch 445, Training loss: 0.5563, Validation loss: 0.4904
Epoch 446, Training loss: 0.5562, Validation loss: 0.4903
Epoch 447, Training loss: 0.5561, Validation loss: 0.4902
Epoch 448, Training loss: 0.5560, Validation loss: 0.4902
Epoch 449, Training loss: 0.5559, Validation loss: 0.4901
Epoch 450, Training loss: 0.5559, Validation loss: 0.4900
Epoch 451, Training loss: 0.5558, Validation loss: 0.4900
Epoch 452, Training loss: 0.5557, Validation loss: 0.4899
Epoch 453, Training loss: 0.5556, Validation loss: 0.4899
Epoch 454, Training loss: 0.5555, Validation loss: 0.4898
Epoch 455, Training loss: 0.5554, Validation loss: 0.4897
Epoch 456, Training loss: 0.5553, Validation loss: 0.4897
Epoch 457, Training loss: 0.5552, Validation loss: 0.4896
Epoch 458, Training loss: 0.5552, Validation loss: 0.4895
Epoch 459, Training loss: 0.5551, Validation loss: 0.4895
Epoch 460, Training loss: 0.5550, Validation loss: 0.4894
Epoch 461, Training loss: 0.5549, Validation loss: 0.4893
Epoch 462, Training loss: 0.5548, Validation loss: 0.4892
Epoch 463, Training loss: 0.5547, Validation loss: 0.4892
Epoch 464, Training loss: 0.5547, Validation loss: 0.4891
Epoch 465, Training loss: 0.5546, Validation loss: 0.4890
Epoch 466, Training loss: 0.5545, Validation loss: 0.4890
Epoch 467, Training loss: 0.5544, Validation loss: 0.4889
Epoch 468, Training loss: 0.5543, Validation loss: 0.4888
Epoch 469, Training loss: 0.5542, Validation loss: 0.4888
Epoch 470, Training loss: 0.5542, Validation loss: 0.4887
Epoch 471, Training loss: 0.5541, Validation loss: 0.4886
Epoch 472, Training loss: 0.5540, Validation loss: 0.4885
Epoch 473, Training loss: 0.5539, Validation loss: 0.4885
Epoch 474, Training loss: 0.5538, Validation loss: 0.4884
Epoch 475, Training loss: 0.5538, Validation loss: 0.4883
Epoch 476, Training loss: 0.5537, Validation loss: 0.4883
Epoch 477, Training loss: 0.5536, Validation loss: 0.4882
Epoch 478, Training loss: 0.5535, Validation loss: 0.4881
Epoch 479, Training loss: 0.5534, Validation loss: 0.4881
Epoch 480, Training loss: 0.5533, Validation loss: 0.4880
Epoch 481, Training loss: 0.5533, Validation loss: 0.4879
Epoch 482, Training loss: 0.5532, Validation loss: 0.4879
Epoch 483, Training loss: 0.5531, Validation loss: 0.4878
Epoch 484, Training loss: 0.5530, Validation loss: 0.4878
Epoch 485, Training loss: 0.5529, Validation loss: 0.4877
Epoch 486, Training loss: 0.5529, Validation loss: 0.4876
Epoch 487, Training loss: 0.5528, Validation loss: 0.4875
Epoch 488, Training loss: 0.5527, Validation loss: 0.4875
Epoch 489, Training loss: 0.5526, Validation loss: 0.4874
Epoch 490, Training loss: 0.5525, Validation loss: 0.4873
Epoch 491, Training loss: 0.5525, Validation loss: 0.4872
Epoch 492, Training loss: 0.5524, Validation loss: 0.4871
Epoch 493, Training loss: 0.5523, Validation loss: 0.4870
Epoch 494, Training loss: 0.5522, Validation loss: 0.4870
Epoch 495, Training loss: 0.5521, Validation loss: 0.4869
Epoch 496, Training loss: 0.5521, Validation loss: 0.4869
Epoch 497, Training loss: 0.5520, Validation loss: 0.4869
Epoch 498, Training loss: 0.5519, Validation loss: 0.4867
Epoch 499, Training loss: 0.5518, Validation loss: 0.4867
Epoch 500, Training loss: 0.5517, Validation loss: 0.4867
Epoch 501, Training loss: 0.5517, Validation loss: 0.4866
Epoch 502, Training loss: 0.5516, Validation loss: 0.4865
Epoch 503, Training loss: 0.5515, Validation loss: 0.4865
Epoch 504, Training loss: 0.5514, Validation loss: 0.4864
Epoch 505, Training loss: 0.5514, Validation loss: 0.4864
Epoch 506, Training loss: 0.5513, Validation loss: 0.4863
Epoch 507, Training loss: 0.5512, Validation loss: 0.4863
Epoch 508, Training loss: 0.5512, Validation loss: 0.4862
Epoch 509, Training loss: 0.5511, Validation loss: 0.4862
Epoch 510, Training loss: 0.5510, Validation loss: 0.4861
Epoch 511, Training loss: 0.5509, Validation loss: 0.4860
Epoch 512, Training loss: 0.5509, Validation loss: 0.4860
Epoch 513, Training loss: 0.5508, Validation loss: 0.4859
Epoch 514, Training loss: 0.5507, Validation loss: 0.4859
Epoch 515, Training loss: 0.5506, Validation loss: 0.4858
Epoch 516, Training loss: 0.5506, Validation loss: 0.4858
Epoch 517, Training loss: 0.5505, Validation loss: 0.4857
Epoch 518, Training loss: 0.5504, Validation loss: 0.4857
Epoch 519, Training loss: 0.5504, Validation loss: 0.4857
Epoch 520, Training loss: 0.5503, Validation loss: 0.4857
Epoch 521, Training loss: 0.5502, Validation loss: 0.4856
Epoch 522, Training loss: 0.5502, Validation loss: 0.4855
Epoch 523, Training loss: 0.5501, Validation loss: 0.4854
Epoch 524, Training loss: 0.5501, Validation loss: 0.4854
Epoch 525, Training loss: 0.5500, Validation loss: 0.4853
Epoch 526, Training loss: 0.5499, Validation loss: 0.4853
Epoch 527, Training loss: 0.5499, Validation loss: 0.4852
Epoch 528, Training loss: 0.5498, Validation loss: 0.4852
Epoch 529, Training loss: 0.5498, Validation loss: 0.4851
Epoch 530, Training loss: 0.5497, Validation loss: 0.4851
Epoch 531, Training loss: 0.5496, Validation loss: 0.4851
Epoch 532, Training loss: 0.5496, Validation loss: 0.4850
Epoch 533, Training loss: 0.5495, Validation loss: 0.4850
Epoch 534, Training loss: 0.5494, Validation loss: 0.4850
Epoch 535, Training loss: 0.5494, Validation loss: 0.4849
Epoch 536, Training loss: 0.5493, Validation loss: 0.4849
Epoch 537, Training loss: 0.5493, Validation loss: 0.4848
Epoch 538, Training loss: 0.5492, Validation loss: 0.4848
Epoch 539, Training loss: 0.5491, Validation loss: 0.4847
Epoch 540, Training loss: 0.5491, Validation loss: 0.4847
Epoch 541, Training loss: 0.5490, Validation loss: 0.4846
Epoch 542, Training loss: 0.5490, Validation loss: 0.4847
Epoch 543, Training loss: 0.5489, Validation loss: 0.4846
Epoch 544, Training loss: 0.5488, Validation loss: 0.4846
Epoch 545, Training loss: 0.5488, Validation loss: 0.4846
Epoch 546, Training loss: 0.5487, Validation loss: 0.4845
Epoch 547, Training loss: 0.5487, Validation loss: 0.4845
Epoch 548, Training loss: 0.5486, Validation loss: 0.4844
Epoch 549, Training loss: 0.5486, Validation loss: 0.4844
Epoch 550, Training loss: 0.5485, Validation loss: 0.4844
Epoch 551, Training loss: 0.5484, Validation loss: 0.4843
Epoch 552, Training loss: 0.5484, Validation loss: 0.4842
Epoch 553, Training loss: 0.5483, Validation loss: 0.4842
Epoch 554, Training loss: 0.5483, Validation loss: 0.4841
Epoch 555, Training loss: 0.5482, Validation loss: 0.4840
Epoch 556, Training loss: 0.5481, Validation loss: 0.4840
Epoch 557, Training loss: 0.5481, Validation loss: 0.4839
Epoch 558, Training loss: 0.5480, Validation loss: 0.4839
Epoch 559, Training loss: 0.5480, Validation loss: 0.4839
Epoch 560, Training loss: 0.5479, Validation loss: 0.4838
Epoch 561, Training loss: 0.5479, Validation loss: 0.4838
Epoch 562, Training loss: 0.5478, Validation loss: 0.4837
Epoch 563, Training loss: 0.5478, Validation loss: 0.4837
Epoch 564, Training loss: 0.5477, Validation loss: 0.4836
Epoch 565, Training loss: 0.5477, Validation loss: 0.4836
Epoch 566, Training loss: 0.5476, Validation loss: 0.4836
Epoch 567, Training loss: 0.5476, Validation loss: 0.4835
Epoch 568, Training loss: 0.5475, Validation loss: 0.4835
Epoch 569, Training loss: 0.5475, Validation loss: 0.4835
Epoch 570, Training loss: 0.5474, Validation loss: 0.4834
Epoch 571, Training loss: 0.5473, Validation loss: 0.4833
Epoch 572, Training loss: 0.5473, Validation loss: 0.4833
Epoch 573, Training loss: 0.5472, Validation loss: 0.4832
Epoch 574, Training loss: 0.5472, Validation loss: 0.4832
Epoch 575, Training loss: 0.5471, Validation loss: 0.4832
Epoch 576, Training loss: 0.5471, Validation loss: 0.4831
Epoch 577, Training loss: 0.5470, Validation loss: 0.4831
Epoch 578, Training loss: 0.5470, Validation loss: 0.4830
Epoch 579, Training loss: 0.5469, Validation loss: 0.4830
Epoch 580, Training loss: 0.5469, Validation loss: 0.4829
Epoch 581, Training loss: 0.5468, Validation loss: 0.4829
Epoch 582, Training loss: 0.5468, Validation loss: 0.4829
Epoch 583, Training loss: 0.5467, Validation loss: 0.4828
Epoch 584, Training loss: 0.5467, Validation loss: 0.4828
Epoch 585, Training loss: 0.5466, Validation loss: 0.4827
Epoch 586, Training loss: 0.5466, Validation loss: 0.4826
Epoch 587, Training loss: 0.5465, Validation loss: 0.4826
Epoch 588, Training loss: 0.5465, Validation loss: 0.4826
Epoch 589, Training loss: 0.5464, Validation loss: 0.4825
Epoch 590, Training loss: 0.5464, Validation loss: 0.4824
Epoch 591, Training loss: 0.5463, Validation loss: 0.4824
Epoch 592, Training loss: 0.5463, Validation loss: 0.4824
Epoch 593, Training loss: 0.5462, Validation loss: 0.4823
Epoch 594, Training loss: 0.5462, Validation loss: 0.4822
Epoch 595, Training loss: 0.5461, Validation loss: 0.4822
Epoch 596, Training loss: 0.5461, Validation loss: 0.4822
Epoch 597, Training loss: 0.5460, Validation loss: 0.4821
Epoch 598, Training loss: 0.5460, Validation loss: 0.4821
Epoch 599, Training loss: 0.5459, Validation loss: 0.4821
Epoch 600, Training loss: 0.5459, Validation loss: 0.4821
Epoch 601, Training loss: 0.5458, Validation loss: 0.4821
Epoch 602, Training loss: 0.5458, Validation loss: 0.4820
Epoch 603, Training loss: 0.5457, Validation loss: 0.4820
Epoch 604, Training loss: 0.5457, Validation loss: 0.4819
Epoch 605, Training loss: 0.5456, Validation loss: 0.4819
Epoch 606, Training loss: 0.5456, Validation loss: 0.4819
Epoch 607, Training loss: 0.5455, Validation loss: 0.4818
Epoch 608, Training loss: 0.5455, Validation loss: 0.4818
Epoch 609, Training loss: 0.5455, Validation loss: 0.4818
Epoch 610, Training loss: 0.5454, Validation loss: 0.4818
Epoch 611, Training loss: 0.5454, Validation loss: 0.4817
Epoch 612, Training loss: 0.5453, Validation loss: 0.4816
Epoch 613, Training loss: 0.5453, Validation loss: 0.4816
Epoch 614, Training loss: 0.5452, Validation loss: 0.4816
Epoch 615, Training loss: 0.5452, Validation loss: 0.4816
Epoch 616, Training loss: 0.5452, Validation loss: 0.4816
Epoch 617, Training loss: 0.5451, Validation loss: 0.4815
Epoch 618, Training loss: 0.5451, Validation loss: 0.4814
Epoch 619, Training loss: 0.5450, Validation loss: 0.4813
Epoch 620, Training loss: 0.5450, Validation loss: 0.4813
Epoch 621, Training loss: 0.5449, Validation loss: 0.4813
Epoch 622, Training loss: 0.5449, Validation loss: 0.4812
Epoch 623, Training loss: 0.5448, Validation loss: 0.4812
Epoch 624, Training loss: 0.5448, Validation loss: 0.4812
Epoch 625, Training loss: 0.5448, Validation loss: 0.4811
Epoch 626, Training loss: 0.5447, Validation loss: 0.4811
Epoch 627, Training loss: 0.5447, Validation loss: 0.4811
Epoch 628, Training loss: 0.5446, Validation loss: 0.4810
Epoch 629, Training loss: 0.5446, Validation loss: 0.4810
Epoch 630, Training loss: 0.5445, Validation loss: 0.4810
Epoch 631, Training loss: 0.5445, Validation loss: 0.4809
Epoch 632, Training loss: 0.5444, Validation loss: 0.4809
Epoch 633, Training loss: 0.5444, Validation loss: 0.4809
Epoch 634, Training loss: 0.5444, Validation loss: 0.4808
Epoch 635, Training loss: 0.5443, Validation loss: 0.4808
Epoch 636, Training loss: 0.5443, Validation loss: 0.4808
Epoch 637, Training loss: 0.5442, Validation loss: 0.4808
Epoch 638, Training loss: 0.5442, Validation loss: 0.4807
Epoch 639, Training loss: 0.5441, Validation loss: 0.4807
Epoch 640, Training loss: 0.5441, Validation loss: 0.4806
Epoch 641, Training loss: 0.5441, Validation loss: 0.4806
Epoch 642, Training loss: 0.5440, Validation loss: 0.4805
Epoch 643, Training loss: 0.5440, Validation loss: 0.4805
Epoch 644, Training loss: 0.5439, Validation loss: 0.4804
Epoch 645, Training loss: 0.5439, Validation loss: 0.4804
Epoch 646, Training loss: 0.5438, Validation loss: 0.4804
Epoch 647, Training loss: 0.5438, Validation loss: 0.4804
Epoch 648, Training loss: 0.5437, Validation loss: 0.4803
Epoch 649, Training loss: 0.5437, Validation loss: 0.4803
Epoch 650, Training loss: 0.5437, Validation loss: 0.4803
Epoch 651, Training loss: 0.5436, Validation loss: 0.4803
Epoch 652, Training loss: 0.5436, Validation loss: 0.4802
Epoch 653, Training loss: 0.5435, Validation loss: 0.4802
Epoch 654, Training loss: 0.5435, Validation loss: 0.4802
Epoch 655, Training loss: 0.5435, Validation loss: 0.4802
Epoch 656, Training loss: 0.5434, Validation loss: 0.4802
Epoch 657, Training loss: 0.5434, Validation loss: 0.4801
Epoch 658, Training loss: 0.5433, Validation loss: 0.4801
Epoch 659, Training loss: 0.5433, Validation loss: 0.4801
Epoch 660, Training loss: 0.5432, Validation loss: 0.4800
Epoch 661, Training loss: 0.5432, Validation loss: 0.4800
Epoch 662, Training loss: 0.5432, Validation loss: 0.4800
Epoch 663, Training loss: 0.5431, Validation loss: 0.4800
Epoch 664, Training loss: 0.5431, Validation loss: 0.4799
Epoch 665, Training loss: 0.5430, Validation loss: 0.4799
Epoch 666, Training loss: 0.5430, Validation loss: 0.4799
Epoch 667, Training loss: 0.5429, Validation loss: 0.4799
Epoch 668, Training loss: 0.5429, Validation loss: 0.4798
Epoch 669, Training loss: 0.5429, Validation loss: 0.4797
Epoch 670, Training loss: 0.5428, Validation loss: 0.4797
Epoch 671, Training loss: 0.5428, Validation loss: 0.4797
Epoch 672, Training loss: 0.5427, Validation loss: 0.4797
Epoch 673, Training loss: 0.5427, Validation loss: 0.4797
Epoch 674, Training loss: 0.5426, Validation loss: 0.4797
Epoch 675, Training loss: 0.5426, Validation loss: 0.4797
Epoch 676, Training loss: 0.5426, Validation loss: 0.4796
Epoch 677, Training loss: 0.5425, Validation loss: 0.4796
Epoch 678, Training loss: 0.5425, Validation loss: 0.4797
Epoch 679, Training loss: 0.5424, Validation loss: 0.4796
Epoch 680, Training loss: 0.5424, Validation loss: 0.4796
Epoch 681, Training loss: 0.5424, Validation loss: 0.4795
Epoch 682, Training loss: 0.5423, Validation loss: 0.4795
Epoch 683, Training loss: 0.5423, Validation loss: 0.4794
Epoch 684, Training loss: 0.5422, Validation loss: 0.4794
Epoch 685, Training loss: 0.5422, Validation loss: 0.4794
Epoch 686, Training loss: 0.5422, Validation loss: 0.4794
Epoch 687, Training loss: 0.5421, Validation loss: 0.4794
Epoch 688, Training loss: 0.5421, Validation loss: 0.4793
Epoch 689, Training loss: 0.5420, Validation loss: 0.4793
Epoch 690, Training loss: 0.5420, Validation loss: 0.4792
Epoch 691, Training loss: 0.5420, Validation loss: 0.4793
Epoch 692, Training loss: 0.5419, Validation loss: 0.4792
Epoch 693, Training loss: 0.5419, Validation loss: 0.4792
Epoch 694, Training loss: 0.5419, Validation loss: 0.4791
Epoch 695, Training loss: 0.5418, Validation loss: 0.4791
Epoch 696, Training loss: 0.5418, Validation loss: 0.4791
Epoch 697, Training loss: 0.5417, Validation loss: 0.4790
Epoch 698, Training loss: 0.5417, Validation loss: 0.4790
Epoch 699, Training loss: 0.5417, Validation loss: 0.4790
Epoch 700, Training loss: 0.5416, Validation loss: 0.4789
Epoch 701, Training loss: 0.5416, Validation loss: 0.4789
Epoch 702, Training loss: 0.5416, Validation loss: 0.4789
Epoch 703, Training loss: 0.5415, Validation loss: 0.4788
Epoch 704, Training loss: 0.5415, Validation loss: 0.4789
Epoch 705, Training loss: 0.5414, Validation loss: 0.4789
Epoch 706, Training loss: 0.5414, Validation loss: 0.4788
Epoch 707, Training loss: 0.5414, Validation loss: 0.4788
Epoch 708, Training loss: 0.5413, Validation loss: 0.4788
Epoch 709, Training loss: 0.5413, Validation loss: 0.4788
Epoch 710, Training loss: 0.5413, Validation loss: 0.4788
Epoch 711, Training loss: 0.5412, Validation loss: 0.4787
Epoch 712, Training loss: 0.5412, Validation loss: 0.4787
Epoch 713, Training loss: 0.5411, Validation loss: 0.4786
Epoch 714, Training loss: 0.5411, Validation loss: 0.4786
Epoch 715, Training loss: 0.5411, Validation loss: 0.4786
Epoch 716, Training loss: 0.5410, Validation loss: 0.4784
Epoch 717, Training loss: 0.5410, Validation loss: 0.4784
Epoch 718, Training loss: 0.5410, Validation loss: 0.4784
Epoch 719, Training loss: 0.5409, Validation loss: 0.4783
Epoch 720, Training loss: 0.5409, Validation loss: 0.4783
Epoch 721, Training loss: 0.5408, Validation loss: 0.4783
Epoch 722, Training loss: 0.5408, Validation loss: 0.4783
Epoch 723, Training loss: 0.5408, Validation loss: 0.4783
Epoch 724, Training loss: 0.5407, Validation loss: 0.4782
Epoch 725, Training loss: 0.5407, Validation loss: 0.4782
Epoch 726, Training loss: 0.5407, Validation loss: 0.4782
Epoch 727, Training loss: 0.5406, Validation loss: 0.4781
Epoch 728, Training loss: 0.5406, Validation loss: 0.4781
Epoch 729, Training loss: 0.5405, Validation loss: 0.4780
Epoch 730, Training loss: 0.5405, Validation loss: 0.4780
Epoch 731, Training loss: 0.5405, Validation loss: 0.4780
Epoch 732, Training loss: 0.5404, Validation loss: 0.4780
Epoch 733, Training loss: 0.5404, Validation loss: 0.4779
Epoch 734, Training loss: 0.5404, Validation loss: 0.4779
Epoch 735, Training loss: 0.5403, Validation loss: 0.4779
Epoch 736, Training loss: 0.5403, Validation loss: 0.4779
Epoch 737, Training loss: 0.5402, Validation loss: 0.4778
Epoch 738, Training loss: 0.5402, Validation loss: 0.4778
Epoch 739, Training loss: 0.5402, Validation loss: 0.4778
Epoch 740, Training loss: 0.5401, Validation loss: 0.4777
Epoch 741, Training loss: 0.5401, Validation loss: 0.4777
Epoch 742, Training loss: 0.5401, Validation loss: 0.4777
Epoch 743, Training loss: 0.5400, Validation loss: 0.4776
Epoch 744, Training loss: 0.5400, Validation loss: 0.4776
Epoch 745, Training loss: 0.5400, Validation loss: 0.4776
Epoch 746, Training loss: 0.5399, Validation loss: 0.4775
Epoch 747, Training loss: 0.5399, Validation loss: 0.4775
Epoch 748, Training loss: 0.5399, Validation loss: 0.4775
Epoch 749, Training loss: 0.5398, Validation loss: 0.4774
Epoch 750, Training loss: 0.5398, Validation loss: 0.4774
Epoch 751, Training loss: 0.5398, Validation loss: 0.4773
Epoch 752, Training loss: 0.5397, Validation loss: 0.4773
Epoch 753, Training loss: 0.5397, Validation loss: 0.4773
Epoch 754, Training loss: 0.5397, Validation loss: 0.4773
Epoch 755, Training loss: 0.5396, Validation loss: 0.4773
Epoch 756, Training loss: 0.5396, Validation loss: 0.4772
Epoch 757, Training loss: 0.5395, Validation loss: 0.4772
Epoch 758, Training loss: 0.5395, Validation loss: 0.4772
Epoch 759, Training loss: 0.5395, Validation loss: 0.4771
Epoch 760, Training loss: 0.5394, Validation loss: 0.4771
Epoch 761, Training loss: 0.5394, Validation loss: 0.4771
Epoch 762, Training loss: 0.5394, Validation loss: 0.4771
Epoch 763, Training loss: 0.5393, Validation loss: 0.4769
Epoch 764, Training loss: 0.5393, Validation loss: 0.4769
Epoch 765, Training loss: 0.5393, Validation loss: 0.4769
Epoch 766, Training loss: 0.5392, Validation loss: 0.4769
Epoch 767, Training loss: 0.5392, Validation loss: 0.4769
Epoch 768, Training loss: 0.5392, Validation loss: 0.4768
Epoch 769, Training loss: 0.5391, Validation loss: 0.4768
Epoch 770, Training loss: 0.5391, Validation loss: 0.4768
Epoch 771, Training loss: 0.5391, Validation loss: 0.4767
Epoch 772, Training loss: 0.5390, Validation loss: 0.4767
Epoch 773, Training loss: 0.5390, Validation loss: 0.4767
Epoch 774, Training loss: 0.5390, Validation loss: 0.4767
Epoch 775, Training loss: 0.5389, Validation loss: 0.4766
Epoch 776, Training loss: 0.5389, Validation loss: 0.4766
Epoch 777, Training loss: 0.5389, Validation loss: 0.4766
Epoch 778, Training loss: 0.5388, Validation loss: 0.4765
Epoch 779, Training loss: 0.5388, Validation loss: 0.4765
Epoch 780, Training loss: 0.5388, Validation loss: 0.4765
Epoch 781, Training loss: 0.5387, Validation loss: 0.4764
Epoch 782, Training loss: 0.5387, Validation loss: 0.4764
Epoch 783, Training loss: 0.5387, Validation loss: 0.4764
Epoch 784, Training loss: 0.5386, Validation loss: 0.4764
Epoch 785, Training loss: 0.5386, Validation loss: 0.4764
Epoch 786, Training loss: 0.5386, Validation loss: 0.4763
Epoch 787, Training loss: 0.5385, Validation loss: 0.4763
Epoch 788, Training loss: 0.5385, Validation loss: 0.4763
Epoch 789, Training loss: 0.5385, Validation loss: 0.4763
Epoch 790, Training loss: 0.5384, Validation loss: 0.4763
Epoch 791, Training loss: 0.5384, Validation loss: 0.4762
Epoch 792, Training loss: 0.5384, Validation loss: 0.4762
Epoch 793, Training loss: 0.5383, Validation loss: 0.4762
Epoch 794, Training loss: 0.5383, Validation loss: 0.4761
Epoch 795, Training loss: 0.5383, Validation loss: 0.4761
Epoch 796, Training loss: 0.5382, Validation loss: 0.4760
Epoch 797, Training loss: 0.5382, Validation loss: 0.4760
Epoch 798, Training loss: 0.5382, Validation loss: 0.4760
Epoch 799, Training loss: 0.5381, Validation loss: 0.4760
Epoch 800, Training loss: 0.5381, Validation loss: 0.4759
Epoch 801, Training loss: 0.5381, Validation loss: 0.4759
Epoch 802, Training loss: 0.5381, Validation loss: 0.4759
Epoch 803, Training loss: 0.5380, Validation loss: 0.4758
Epoch 804, Training loss: 0.5380, Validation loss: 0.4758
Epoch 805, Training loss: 0.5380, Validation loss: 0.4758
Epoch 806, Training loss: 0.5379, Validation loss: 0.4758
Epoch 807, Training loss: 0.5379, Validation loss: 0.4757
Epoch 808, Training loss: 0.5379, Validation loss: 0.4757
Epoch 809, Training loss: 0.5378, Validation loss: 0.4756
Epoch 810, Training loss: 0.5378, Validation loss: 0.4757
Epoch 811, Training loss: 0.5377, Validation loss: 0.4757
Epoch 812, Training loss: 0.5377, Validation loss: 0.4756
Epoch 813, Training loss: 0.5377, Validation loss: 0.4756
Epoch 814, Training loss: 0.5377, Validation loss: 0.4756
Epoch 815, Training loss: 0.5376, Validation loss: 0.4756
Epoch 816, Training loss: 0.5376, Validation loss: 0.4755
Epoch 817, Training loss: 0.5376, Validation loss: 0.4755
Epoch 818, Training loss: 0.5375, Validation loss: 0.4755
Epoch 819, Training loss: 0.5375, Validation loss: 0.4755
Epoch 820, Training loss: 0.5375, Validation loss: 0.4755
Epoch 821, Training loss: 0.5374, Validation loss: 0.4755
Epoch 822, Training loss: 0.5374, Validation loss: 0.4754
Epoch 823, Training loss: 0.5374, Validation loss: 0.4754
Epoch 824, Training loss: 0.5373, Validation loss: 0.4754
Epoch 825, Training loss: 0.5373, Validation loss: 0.4753
Epoch 826, Training loss: 0.5373, Validation loss: 0.4753
Epoch 827, Training loss: 0.5372, Validation loss: 0.4753
Epoch 828, Training loss: 0.5372, Validation loss: 0.4753
Epoch 829, Training loss: 0.5372, Validation loss: 0.4753
Epoch 830, Training loss: 0.5371, Validation loss: 0.4753
Epoch 831, Training loss: 0.5371, Validation loss: 0.4753
Epoch 832, Training loss: 0.5371, Validation loss: 0.4753
Epoch 833, Training loss: 0.5371, Validation loss: 0.4752
Epoch 834, Training loss: 0.5370, Validation loss: 0.4752
Epoch 835, Training loss: 0.5370, Validation loss: 0.4752
Epoch 836, Training loss: 0.5370, Validation loss: 0.4752
Epoch 837, Training loss: 0.5369, Validation loss: 0.4752
Epoch 838, Training loss: 0.5369, Validation loss: 0.4751
Epoch 839, Training loss: 0.5369, Validation loss: 0.4751
Epoch 840, Training loss: 0.5368, Validation loss: 0.4751
Epoch 841, Training loss: 0.5368, Validation loss: 0.4750
Epoch 842, Training loss: 0.5368, Validation loss: 0.4751
Epoch 843, Training loss: 0.5367, Validation loss: 0.4750
Epoch 844, Training loss: 0.5367, Validation loss: 0.4750
Epoch 845, Training loss: 0.5367, Validation loss: 0.4750
Epoch 846, Training loss: 0.5367, Validation loss: 0.4750
Epoch 847, Training loss: 0.5366, Validation loss: 0.4750
Epoch 848, Training loss: 0.5366, Validation loss: 0.4750
Epoch 849, Training loss: 0.5366, Validation loss: 0.4750
Epoch 850, Training loss: 0.5365, Validation loss: 0.4749
Epoch 851, Training loss: 0.5365, Validation loss: 0.4749
Epoch 852, Training loss: 0.5365, Validation loss: 0.4749
Epoch 853, Training loss: 0.5365, Validation loss: 0.4748
Epoch 854, Training loss: 0.5364, Validation loss: 0.4748
Epoch 855, Training loss: 0.5364, Validation loss: 0.4747
Epoch 856, Training loss: 0.5364, Validation loss: 0.4747
Epoch 857, Training loss: 0.5363, Validation loss: 0.4747
Epoch 858, Training loss: 0.5363, Validation loss: 0.4746
Epoch 859, Training loss: 0.5363, Validation loss: 0.4746
Epoch 860, Training loss: 0.5362, Validation loss: 0.4745
Epoch 861, Training loss: 0.5362, Validation loss: 0.4745
Epoch 862, Training loss: 0.5362, Validation loss: 0.4745
Epoch 863, Training loss: 0.5362, Validation loss: 0.4745
Epoch 864, Training loss: 0.5361, Validation loss: 0.4745
Epoch 865, Training loss: 0.5361, Validation loss: 0.4744
Epoch 866, Training loss: 0.5361, Validation loss: 0.4744
Epoch 867, Training loss: 0.5360, Validation loss: 0.4744
Epoch 868, Training loss: 0.5360, Validation loss: 0.4743
Epoch 869, Training loss: 0.5360, Validation loss: 0.4743
Epoch 870, Training loss: 0.5359, Validation loss: 0.4743
Epoch 871, Training loss: 0.5359, Validation loss: 0.4743
Epoch 872, Training loss: 0.5359, Validation loss: 0.4743
Epoch 873, Training loss: 0.5359, Validation loss: 0.4743
Epoch 874, Training loss: 0.5358, Validation loss: 0.4743
Epoch 875, Training loss: 0.5358, Validation loss: 0.4742
Epoch 876, Training loss: 0.5358, Validation loss: 0.4742
Epoch 877, Training loss: 0.5357, Validation loss: 0.4742
Epoch 878, Training loss: 0.5357, Validation loss: 0.4742
Epoch 879, Training loss: 0.5357, Validation loss: 0.4742
Epoch 880, Training loss: 0.5357, Validation loss: 0.4742
Epoch 881, Training loss: 0.5356, Validation loss: 0.4741
Epoch 882, Training loss: 0.5356, Validation loss: 0.4741
Epoch 883, Training loss: 0.5356, Validation loss: 0.4740
Epoch 884, Training loss: 0.5355, Validation loss: 0.4740
Epoch 885, Training loss: 0.5355, Validation loss: 0.4740
Epoch 886, Training loss: 0.5355, Validation loss: 0.4740
Epoch 887, Training loss: 0.5355, Validation loss: 0.4740
Epoch 888, Training loss: 0.5354, Validation loss: 0.4740
Epoch 889, Training loss: 0.5354, Validation loss: 0.4739
Epoch 890, Training loss: 0.5354, Validation loss: 0.4739
Epoch 891, Training loss: 0.5354, Validation loss: 0.4739
Epoch 892, Training loss: 0.5353, Validation loss: 0.4739
Epoch 893, Training loss: 0.5353, Validation loss: 0.4738
Epoch 894, Training loss: 0.5353, Validation loss: 0.4737
Epoch 895, Training loss: 0.5352, Validation loss: 0.4737
Epoch 896, Training loss: 0.5352, Validation loss: 0.4737
Epoch 897, Training loss: 0.5352, Validation loss: 0.4737
Epoch 898, Training loss: 0.5352, Validation loss: 0.4737
Epoch 899, Training loss: 0.5351, Validation loss: 0.4736
Epoch 900, Training loss: 0.5351, Validation loss: 0.4736
Epoch 901, Training loss: 0.5351, Validation loss: 0.4736
Epoch 902, Training loss: 0.5351, Validation loss: 0.4736
Epoch 903, Training loss: 0.5350, Validation loss: 0.4736
Epoch 904, Training loss: 0.5350, Validation loss: 0.4735
Epoch 905, Training loss: 0.5350, Validation loss: 0.4734
Epoch 906, Training loss: 0.5349, Validation loss: 0.4734
Epoch 907, Training loss: 0.5349, Validation loss: 0.4734
Epoch 908, Training loss: 0.5349, Validation loss: 0.4734
Epoch 909, Training loss: 0.5349, Validation loss: 0.4734
Epoch 910, Training loss: 0.5348, Validation loss: 0.4734
Epoch 911, Training loss: 0.5348, Validation loss: 0.4734
Epoch 912, Training loss: 0.5348, Validation loss: 0.4733
Epoch 913, Training loss: 0.5348, Validation loss: 0.4733
Epoch 914, Training loss: 0.5347, Validation loss: 0.4733
Epoch 915, Training loss: 0.5347, Validation loss: 0.4732
Epoch 916, Training loss: 0.5347, Validation loss: 0.4732
Epoch 917, Training loss: 0.5346, Validation loss: 0.4733
Epoch 918, Training loss: 0.5346, Validation loss: 0.4733
Epoch 919, Training loss: 0.5346, Validation loss: 0.4733
Epoch 920, Training loss: 0.5346, Validation loss: 0.4732
Epoch 921, Training loss: 0.5345, Validation loss: 0.4732
Epoch 922, Training loss: 0.5345, Validation loss: 0.4732
Epoch 923, Training loss: 0.5345, Validation loss: 0.4732
Epoch 924, Training loss: 0.5344, Validation loss: 0.4732
Epoch 925, Training loss: 0.5344, Validation loss: 0.4732
Epoch 926, Training loss: 0.5344, Validation loss: 0.4732
Epoch 927, Training loss: 0.5344, Validation loss: 0.4731
Epoch 928, Training loss: 0.5343, Validation loss: 0.4731
Epoch 929, Training loss: 0.5343, Validation loss: 0.4731
Epoch 930, Training loss: 0.5343, Validation loss: 0.4731
Epoch 931, Training loss: 0.5343, Validation loss: 0.4731
Epoch 932, Training loss: 0.5342, Validation loss: 0.4730
Epoch 933, Training loss: 0.5342, Validation loss: 0.4730
Epoch 934, Training loss: 0.5342, Validation loss: 0.4730
Epoch 935, Training loss: 0.5342, Validation loss: 0.4730
Epoch 936, Training loss: 0.5341, Validation loss: 0.4729
Epoch 937, Training loss: 0.5341, Validation loss: 0.4729
Epoch 938, Training loss: 0.5341, Validation loss: 0.4728
Epoch 939, Training loss: 0.5341, Validation loss: 0.4728
Epoch 940, Training loss: 0.5340, Validation loss: 0.4728
Epoch 941, Training loss: 0.5340, Validation loss: 0.4728
Epoch 942, Training loss: 0.5340, Validation loss: 0.4728
Epoch 943, Training loss: 0.5340, Validation loss: 0.4727
Epoch 944, Training loss: 0.5339, Validation loss: 0.4727
Epoch 945, Training loss: 0.5339, Validation loss: 0.4727
Epoch 946, Training loss: 0.5339, Validation loss: 0.4727
Epoch 947, Training loss: 0.5338, Validation loss: 0.4727
Epoch 948, Training loss: 0.5338, Validation loss: 0.4727
Epoch 949, Training loss: 0.5338, Validation loss: 0.4726
Epoch 950, Training loss: 0.5338, Validation loss: 0.4726
Epoch 951, Training loss: 0.5337, Validation loss: 0.4726
Epoch 952, Training loss: 0.5337, Validation loss: 0.4726
Epoch 953, Training loss: 0.5337, Validation loss: 0.4726
Epoch 954, Training loss: 0.5337, Validation loss: 0.4726
Epoch 955, Training loss: 0.5336, Validation loss: 0.4725
Epoch 956, Training loss: 0.5336, Validation loss: 0.4725
Epoch 957, Training loss: 0.5336, Validation loss: 0.4724
Epoch 958, Training loss: 0.5336, Validation loss: 0.4724
Epoch 959, Training loss: 0.5335, Validation loss: 0.4724
Epoch 960, Training loss: 0.5335, Validation loss: 0.4723
Epoch 961, Training loss: 0.5335, Validation loss: 0.4723
Epoch 962, Training loss: 0.5335, Validation loss: 0.4723
Epoch 963, Training loss: 0.5334, Validation loss: 0.4723
Epoch 964, Training loss: 0.5334, Validation loss: 0.4723
Epoch 965, Training loss: 0.5334, Validation loss: 0.4723
Epoch 966, Training loss: 0.5334, Validation loss: 0.4723
Epoch 967, Training loss: 0.5333, Validation loss: 0.4722
Epoch 968, Training loss: 0.5333, Validation loss: 0.4722
Epoch 969, Training loss: 0.5333, Validation loss: 0.4722
Epoch 970, Training loss: 0.5333, Validation loss: 0.4722
Epoch 971, Training loss: 0.5332, Validation loss: 0.4722
Epoch 972, Training loss: 0.5332, Validation loss: 0.4722
Epoch 973, Training loss: 0.5332, Validation loss: 0.4722
Epoch 974, Training loss: 0.5332, Validation loss: 0.4722
Epoch 975, Training loss: 0.5331, Validation loss: 0.4722
Epoch 976, Training loss: 0.5331, Validation loss: 0.4722
Epoch 977, Training loss: 0.5331, Validation loss: 0.4722
Epoch 978, Training loss: 0.5331, Validation loss: 0.4721
Epoch 979, Training loss: 0.5330, Validation loss: 0.4721
Epoch 980, Training loss: 0.5330, Validation loss: 0.4721
Epoch 981, Training loss: 0.5330, Validation loss: 0.4721
Epoch 982, Training loss: 0.5330, Validation loss: 0.4721
Epoch 983, Training loss: 0.5329, Validation loss: 0.4721
Epoch 984, Training loss: 0.5329, Validation loss: 0.4720
Epoch 985, Training loss: 0.5329, Validation loss: 0.4720
Epoch 986, Training loss: 0.5329, Validation loss: 0.4720
Epoch 987, Training loss: 0.5328, Validation loss: 0.4719
Epoch 988, Training loss: 0.5328, Validation loss: 0.4719
Epoch 989, Training loss: 0.5328, Validation loss: 0.4719
Epoch 990, Training loss: 0.5328, Validation loss: 0.4719
Epoch 991, Training loss: 0.5327, Validation loss: 0.4719
Epoch 992, Training loss: 0.5327, Validation loss: 0.4719
Epoch 993, Training loss: 0.5327, Validation loss: 0.4719
Epoch 994, Training loss: 0.5327, Validation loss: 0.4719
Epoch 995, Training loss: 0.5326, Validation loss: 0.4719
Epoch 996, Training loss: 0.5326, Validation loss: 0.4719
Epoch 997, Training loss: 0.5326, Validation loss: 0.4718
Epoch 998, Training loss: 0.5326, Validation loss: 0.4718
Epoch 999, Training loss: 0.5325, Validation loss: 0.4718
[34m[1mwandb[0m: [32m[41mERROR[0m Attempted to change value of key "batch_size" from 16 to 32
[34m[1mwandb[0m: [32m[41mERROR[0m If you really want to do this, pass allow_val_change=True to config.update()
Traceback (most recent call last):
  File "/Users/dikshant/Desktop/college/smai/smai-m24-assignments-pingu-73/assignments/3/a3.py", line 366, in <module>
    train_and_log_model(params)
  File "/Users/dikshant/Desktop/college/smai/smai-m24-assignments-pingu-73/assignments/3/a3.py", line 308, in train_and_log_model
    wandb.config.update(params)
  File "/Users/dikshant/Desktop/college/smai/env/lib/python3.12/site-packages/wandb/sdk/wandb_config.py", line 187, in update
    sanitized = self._update(d, allow_val_change)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/dikshant/Desktop/college/smai/env/lib/python3.12/site-packages/wandb/sdk/wandb_config.py", line 180, in _update
    sanitized = self._sanitize_dict(
                ^^^^^^^^^^^^^^^^^^^^
  File "/Users/dikshant/Desktop/college/smai/env/lib/python3.12/site-packages/wandb/sdk/wandb_config.py", line 267, in _sanitize_dict
    k, v = self._sanitize(k, v, allow_val_change)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/dikshant/Desktop/college/smai/env/lib/python3.12/site-packages/wandb/sdk/wandb_config.py", line 288, in _sanitize
    raise config_util.ConfigError(
wandb.sdk.lib.config_util.ConfigError: Attempted to change value of key "batch_size" from 16 to 32
If you really want to do this, pass allow_val_change=True to config.update()
