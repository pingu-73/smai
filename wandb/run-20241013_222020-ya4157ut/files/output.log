Epoch 0, Training loss: 0.6275, Validation loss: 0.5624
Epoch 1, Training loss: 0.6249, Validation loss: 0.5358
Epoch 2, Training loss: 0.5355, Validation loss: 0.4889
Epoch 3, Training loss: 0.5127, Validation loss: 0.4860
Epoch 4, Training loss: 0.5066, Validation loss: 0.4739
Epoch 5, Training loss: 0.4977, Validation loss: 0.4758
Epoch 6, Training loss: 0.4965, Validation loss: 0.4733
Epoch 7, Training loss: 0.4947, Validation loss: 0.4703
Epoch 8, Training loss: 0.4892, Validation loss: 0.4753
Epoch 9, Training loss: 0.4893, Validation loss: 0.4678
Epoch 10, Training loss: 0.4891, Validation loss: 0.4680
Epoch 11, Training loss: 0.4893, Validation loss: 0.4653
Epoch 12, Training loss: 0.4894, Validation loss: 0.4657
Epoch 13, Training loss: 0.4885, Validation loss: 0.4632
Epoch 14, Training loss: 0.4890, Validation loss: 0.4644
Epoch 15, Training loss: 0.4876, Validation loss: 0.4631
Epoch 16, Training loss: 0.4899, Validation loss: 0.4579
Epoch 17, Training loss: 0.4903, Validation loss: 0.4570
Epoch 18, Training loss: 0.4917, Validation loss: 0.4577
Epoch 19, Training loss: 0.4915, Validation loss: 0.4567
Epoch 20, Training loss: 0.4897, Validation loss: 0.4580
Epoch 21, Training loss: 0.4889, Validation loss: 0.4600
Epoch 22, Training loss: 0.4884, Validation loss: 0.4597
Epoch 23, Training loss: 0.4900, Validation loss: 0.4568
Epoch 24, Training loss: 0.4901, Validation loss: 0.4582
Epoch 25, Training loss: 0.4910, Validation loss: 0.4581
Epoch 26, Training loss: 0.4924, Validation loss: 0.4562
Epoch 27, Training loss: 0.4929, Validation loss: 0.4565
Epoch 28, Training loss: 0.4931, Validation loss: 0.4561
Epoch 29, Training loss: 0.4935, Validation loss: 0.4574
Epoch 30, Training loss: 0.4938, Validation loss: 0.4578
Epoch 31, Training loss: 0.4945, Validation loss: 0.4557
Epoch 32, Training loss: 0.4936, Validation loss: 0.4590
Epoch 33, Training loss: 0.4957, Validation loss: 0.4557
Epoch 34, Training loss: 0.4962, Validation loss: 0.4550
Epoch 35, Training loss: 0.4957, Validation loss: 0.4554
Epoch 36, Training loss: 0.4941, Validation loss: 0.4581
Epoch 37, Training loss: 0.4972, Validation loss: 0.4568
Epoch 38, Training loss: 0.4990, Validation loss: 0.4558
Epoch 39, Training loss: 0.4992, Validation loss: 0.4563
Epoch 40, Training loss: 0.4996, Validation loss: 0.4580
Epoch 41, Training loss: 0.4994, Validation loss: 0.4575
Epoch 42, Training loss: 0.4990, Validation loss: 0.4571
Epoch 43, Training loss: 0.5005, Validation loss: 0.4557
Epoch 44, Training loss: 0.4989, Validation loss: 0.4581
Early stopping.
Epoch 0, Training loss: 0.7601, Validation loss: 0.6449
Epoch 1, Training loss: 0.6488, Validation loss: 0.5414
Epoch 2, Training loss: 0.5955, Validation loss: 0.5024
Epoch 3, Training loss: 0.5647, Validation loss: 0.4887
Epoch 4, Training loss: 0.5520, Validation loss: 0.4720
Epoch 5, Training loss: 0.5413, Validation loss: 0.4738
Epoch 6, Training loss: 0.5334, Validation loss: 0.4679
Epoch 7, Training loss: 0.5309, Validation loss: 0.4642
Epoch 8, Training loss: 0.5261, Validation loss: 0.4646
Epoch 9, Training loss: 0.5235, Validation loss: 0.4640
Epoch 10, Training loss: 0.5199, Validation loss: 0.4661
Epoch 11, Training loss: 0.5186, Validation loss: 0.4654
Epoch 12, Training loss: 0.5170, Validation loss: 0.4677
Epoch 13, Training loss: 0.5169, Validation loss: 0.4644
Epoch 14, Training loss: 0.5154, Validation loss: 0.4662
Epoch 15, Training loss: 0.5155, Validation loss: 0.4639
Epoch 16, Training loss: 0.5153, Validation loss: 0.4634
Epoch 17, Training loss: 0.5124, Validation loss: 0.4664
Epoch 18, Training loss: 0.5132, Validation loss: 0.4632
Epoch 19, Training loss: 0.5134, Validation loss: 0.4623
Epoch 20, Training loss: 0.5138, Validation loss: 0.4613
Epoch 21, Training loss: 0.5109, Validation loss: 0.4632
Epoch 22, Training loss: 0.5117, Validation loss: 0.4615
Epoch 23, Training loss: 0.5121, Validation loss: 0.4609
Epoch 24, Training loss: 0.5122, Validation loss: 0.4607
Epoch 25, Training loss: 0.5136, Validation loss: 0.4589
Epoch 26, Training loss: 0.5103, Validation loss: 0.4617
Epoch 27, Training loss: 0.5105, Validation loss: 0.4616
Epoch 28, Training loss: 0.5112, Validation loss: 0.4600
Epoch 29, Training loss: 0.5120, Validation loss: 0.4592
Epoch 30, Training loss: 0.5115, Validation loss: 0.4596
Epoch 31, Training loss: 0.5117, Validation loss: 0.4597
Epoch 32, Training loss: 0.5122, Validation loss: 0.4595
Epoch 33, Training loss: 0.5147, Validation loss: 0.4582
Epoch 34, Training loss: 0.5140, Validation loss: 0.4590
Epoch 35, Training loss: 0.5135, Validation loss: 0.4596
Epoch 36, Training loss: 0.5138, Validation loss: 0.4592
Epoch 37, Training loss: 0.5126, Validation loss: 0.4606
Epoch 38, Training loss: 0.5137, Validation loss: 0.4591
Epoch 39, Training loss: 0.5113, Validation loss: 0.4616
Epoch 40, Training loss: 0.5123, Validation loss: 0.4597
Epoch 41, Training loss: 0.5123, Validation loss: 0.4595
Epoch 42, Training loss: 0.5121, Validation loss: 0.4596
Epoch 43, Training loss: 0.5137, Validation loss: 0.4581
Epoch 44, Training loss: 0.5103, Validation loss: 0.4617
Epoch 45, Training loss: 0.5115, Validation loss: 0.4592
Epoch 46, Training loss: 0.5119, Validation loss: 0.4587
Epoch 47, Training loss: 0.5112, Validation loss: 0.4584
Epoch 48, Training loss: 0.5085, Validation loss: 0.4596
Epoch 49, Training loss: 0.5083, Validation loss: 0.4603
Epoch 50, Training loss: 0.5076, Validation loss: 0.4643
Epoch 51, Training loss: 0.5089, Validation loss: 0.4588
Epoch 52, Training loss: 0.5092, Validation loss: 0.4581
Epoch 53, Training loss: 0.5077, Validation loss: 0.4585
Epoch 54, Training loss: 0.5071, Validation loss: 0.4583
Epoch 55, Training loss: 0.5066, Validation loss: 0.4585
Epoch 56, Training loss: 0.5059, Validation loss: 0.4587
Epoch 57, Training loss: 0.5068, Validation loss: 0.4576
Epoch 58, Training loss: 0.5064, Validation loss: 0.4579
Epoch 59, Training loss: 0.5048, Validation loss: 0.4596
Epoch 60, Training loss: 0.5065, Validation loss: 0.4579
Epoch 61, Training loss: 0.5057, Validation loss: 0.4583
Epoch 62, Training loss: 0.5050, Validation loss: 0.4586
Epoch 63, Training loss: 0.5047, Validation loss: 0.4588
Epoch 64, Training loss: 0.5045, Validation loss: 0.4592
Epoch 65, Training loss: 0.5015, Validation loss: 0.4692
Epoch 66, Training loss: 0.5011, Validation loss: 0.4626
Epoch 67, Training loss: 0.5022, Validation loss: 0.4611
Early stopping.
Epoch 0, Training loss: 0.8381, Validation loss: 0.7566
Epoch 1, Training loss: 0.6820, Validation loss: 0.6096
Epoch 2, Training loss: 0.6169, Validation loss: 0.5712
Epoch 3, Training loss: 0.5587, Validation loss: 0.5034
Epoch 4, Training loss: 0.5426, Validation loss: 0.4899
Epoch 5, Training loss: 0.5319, Validation loss: 0.4712
Epoch 6, Training loss: 0.5250, Validation loss: 0.4686
Epoch 7, Training loss: 0.5205, Validation loss: 0.4660
Epoch 8, Training loss: 0.5165, Validation loss: 0.4621
Epoch 9, Training loss: 0.5141, Validation loss: 0.4609
Epoch 10, Training loss: 0.5098, Validation loss: 0.4648
Epoch 11, Training loss: 0.5133, Validation loss: 0.4525
Epoch 12, Training loss: 0.5106, Validation loss: 0.4523
Epoch 13, Training loss: 0.5036, Validation loss: 0.4576
Epoch 14, Training loss: 0.5030, Validation loss: 0.4555
Epoch 15, Training loss: 0.5019, Validation loss: 0.4626
Epoch 16, Training loss: 0.5006, Validation loss: 0.4572
Epoch 17, Training loss: 0.5004, Validation loss: 0.4545
Epoch 18, Training loss: 0.5000, Validation loss: 0.4589
Epoch 19, Training loss: 0.4996, Validation loss: 0.4570
Epoch 20, Training loss: 0.4991, Validation loss: 0.4561
Epoch 21, Training loss: 0.4994, Validation loss: 0.4541
Epoch 22, Training loss: 0.4992, Validation loss: 0.4529
Early stopping.
Epoch 0, Training loss: 0.5974, Validation loss: 0.4611
Epoch 1, Training loss: 0.5237, Validation loss: 0.4251
Epoch 2, Training loss: 0.4850, Validation loss: 0.3958
Epoch 3, Training loss: 0.4599, Validation loss: 0.3804
Epoch 4, Training loss: 0.4451, Validation loss: 0.3692
Epoch 5, Training loss: 0.4347, Validation loss: 0.3665
Epoch 6, Training loss: 0.4280, Validation loss: 0.3626
Epoch 7, Training loss: 0.4230, Validation loss: 0.3598
Epoch 8, Training loss: 0.4189, Validation loss: 0.3585
Epoch 9, Training loss: 0.4159, Validation loss: 0.3545
Epoch 10, Training loss: 0.4141, Validation loss: 0.3518
Epoch 11, Training loss: 0.4118, Validation loss: 0.3529
Epoch 12, Training loss: 0.4098, Validation loss: 0.3544
Epoch 13, Training loss: 0.4089, Validation loss: 0.3550
Epoch 14, Training loss: 0.4081, Validation loss: 0.3534
Epoch 15, Training loss: 0.4072, Validation loss: 0.3511
Epoch 16, Training loss: 0.4070, Validation loss: 0.3496
Epoch 17, Training loss: 0.4072, Validation loss: 0.3478
Epoch 18, Training loss: 0.4068, Validation loss: 0.3469
Epoch 19, Training loss: 0.4069, Validation loss: 0.3462
Epoch 20, Training loss: 0.4063, Validation loss: 0.3483
Epoch 21, Training loss: 0.4063, Validation loss: 0.3469
Epoch 22, Training loss: 0.4055, Validation loss: 0.3478
Epoch 23, Training loss: 0.4052, Validation loss: 0.3480
Epoch 24, Training loss: 0.4055, Validation loss: 0.3447
Epoch 25, Training loss: 0.4050, Validation loss: 0.3475
Epoch 26, Training loss: 0.4050, Validation loss: 0.3493
Epoch 27, Training loss: 0.4052, Validation loss: 0.3482
Epoch 28, Training loss: 0.4052, Validation loss: 0.3503
Epoch 29, Training loss: 0.4056, Validation loss: 0.3493
Epoch 30, Training loss: 0.4055, Validation loss: 0.3497
Epoch 31, Training loss: 0.4055, Validation loss: 0.3499
Epoch 32, Training loss: 0.4062, Validation loss: 0.3551
Epoch 33, Training loss: 0.4062, Validation loss: 0.3519
Epoch 34, Training loss: 0.4060, Validation loss: 0.3499
Early stopping.
Epoch 0, Training loss: 0.8377, Validation loss: 0.8123
Epoch 1, Training loss: 0.5745, Validation loss: 0.5603
Epoch 2, Training loss: 0.5143, Validation loss: 0.4962
Epoch 3, Training loss: 0.4833, Validation loss: 0.4627
Epoch 4, Training loss: 0.4670, Validation loss: 0.4438
Epoch 5, Training loss: 0.4542, Validation loss: 0.4274
Epoch 6, Training loss: 0.4451, Validation loss: 0.4166
Epoch 7, Training loss: 0.4384, Validation loss: 0.4047
Epoch 8, Training loss: 0.4352, Validation loss: 0.4056
Epoch 9, Training loss: 0.4304, Validation loss: 0.3956
Epoch 10, Training loss: 0.4273, Validation loss: 0.3906
Epoch 11, Training loss: 0.4242, Validation loss: 0.3867
Epoch 12, Training loss: 0.4220, Validation loss: 0.3802
Epoch 13, Training loss: 0.4206, Validation loss: 0.3723
Epoch 14, Training loss: 0.4184, Validation loss: 0.3690
Epoch 15, Training loss: 0.4144, Validation loss: 0.3711
Epoch 16, Training loss: 0.4136, Validation loss: 0.3676
Epoch 17, Training loss: 0.4122, Validation loss: 0.3685
Epoch 18, Training loss: 0.4114, Validation loss: 0.3701
Epoch 19, Training loss: 0.4103, Validation loss: 0.3649
Epoch 20, Training loss: 0.4091, Validation loss: 0.3631
Epoch 21, Training loss: 0.4085, Validation loss: 0.3619
Epoch 22, Training loss: 0.4081, Validation loss: 0.3633
Epoch 23, Training loss: 0.4075, Validation loss: 0.3608
Epoch 24, Training loss: 0.4070, Validation loss: 0.3585
Epoch 25, Training loss: 0.4070, Validation loss: 0.3613
Epoch 26, Training loss: 0.4063, Validation loss: 0.3580
Epoch 27, Training loss: 0.4063, Validation loss: 0.3592
Epoch 28, Training loss: 0.4058, Validation loss: 0.3581
Epoch 29, Training loss: 0.4052, Validation loss: 0.3575
Epoch 30, Training loss: 0.4049, Validation loss: 0.3551
Epoch 31, Training loss: 0.4049, Validation loss: 0.3534
Epoch 32, Training loss: 0.4048, Validation loss: 0.3513
Epoch 33, Training loss: 0.4043, Validation loss: 0.3552
Epoch 34, Training loss: 0.4041, Validation loss: 0.3558
Epoch 35, Training loss: 0.4040, Validation loss: 0.3558
Epoch 36, Training loss: 0.4038, Validation loss: 0.3533
Epoch 37, Training loss: 0.4037, Validation loss: 0.3502
Epoch 38, Training loss: 0.4038, Validation loss: 0.3504
Epoch 39, Training loss: 0.4040, Validation loss: 0.3481
Epoch 40, Training loss: 0.4042, Validation loss: 0.3487
Epoch 41, Training loss: 0.4038, Validation loss: 0.3493
Epoch 42, Training loss: 0.4035, Validation loss: 0.3490
Epoch 43, Training loss: 0.4037, Validation loss: 0.3485
Epoch 44, Training loss: 0.4041, Validation loss: 0.3486
Epoch 45, Training loss: 0.4039, Validation loss: 0.3481
Epoch 46, Training loss: 0.4040, Validation loss: 0.3490
Epoch 47, Training loss: 0.4043, Validation loss: 0.3472
Epoch 48, Training loss: 0.4038, Validation loss: 0.3476
Epoch 49, Training loss: 0.4070, Validation loss: 0.3456
Epoch 50, Training loss: 0.4057, Validation loss: 0.3477
Epoch 51, Training loss: 0.4054, Validation loss: 0.3466
Epoch 52, Training loss: 0.4046, Validation loss: 0.3465
Epoch 53, Training loss: 0.4050, Validation loss: 0.3428
Epoch 54, Training loss: 0.4043, Validation loss: 0.3437
Epoch 55, Training loss: 0.4047, Validation loss: 0.3431
Epoch 56, Training loss: 0.4042, Validation loss: 0.3437
Epoch 57, Training loss: 0.4043, Validation loss: 0.3424
Epoch 58, Training loss: 0.4039, Validation loss: 0.3435
Epoch 59, Training loss: 0.4038, Validation loss: 0.3445
Epoch 60, Training loss: 0.4033, Validation loss: 0.3472
Epoch 61, Training loss: 0.4036, Validation loss: 0.3469
Epoch 62, Training loss: 0.4040, Validation loss: 0.3444
Epoch 63, Training loss: 0.4028, Validation loss: 0.3460
Epoch 64, Training loss: 0.4039, Validation loss: 0.3438
Epoch 65, Training loss: 0.4033, Validation loss: 0.3446
Epoch 66, Training loss: 0.4029, Validation loss: 0.3473
Epoch 67, Training loss: 0.4033, Validation loss: 0.3482
Early stopping.
Epoch 0, Training loss: 0.7854, Validation loss: 0.7083
Epoch 1, Training loss: 0.6990, Validation loss: 0.6345
Epoch 2, Training loss: 0.6569, Validation loss: 0.5954
Epoch 3, Training loss: 0.6253, Validation loss: 0.5660
Epoch 4, Training loss: 0.5985, Validation loss: 0.5387
Epoch 5, Training loss: 0.5735, Validation loss: 0.5134
Epoch 6, Training loss: 0.5471, Validation loss: 0.4927
Epoch 7, Training loss: 0.5326, Validation loss: 0.4791
Epoch 8, Training loss: 0.5149, Validation loss: 0.4616
Epoch 9, Training loss: 0.5019, Validation loss: 0.4486
Epoch 10, Training loss: 0.4906, Validation loss: 0.4381
Epoch 11, Training loss: 0.4821, Validation loss: 0.4309
Epoch 12, Training loss: 0.4727, Validation loss: 0.4174
Epoch 13, Training loss: 0.4659, Validation loss: 0.4133
Epoch 14, Training loss: 0.4623, Validation loss: 0.4097
Epoch 15, Training loss: 0.4584, Validation loss: 0.4078
Epoch 16, Training loss: 0.4523, Validation loss: 0.3961
Epoch 17, Training loss: 0.4469, Validation loss: 0.3892
Epoch 18, Training loss: 0.4445, Validation loss: 0.3859
Epoch 19, Training loss: 0.4415, Validation loss: 0.3802
Epoch 20, Training loss: 0.4383, Validation loss: 0.3753
Epoch 21, Training loss: 0.4354, Validation loss: 0.3686
Epoch 22, Training loss: 0.4313, Validation loss: 0.3684
Epoch 23, Training loss: 0.4299, Validation loss: 0.3717
Epoch 24, Training loss: 0.4277, Validation loss: 0.3635
Epoch 25, Training loss: 0.4251, Validation loss: 0.3601
Epoch 26, Training loss: 0.4227, Validation loss: 0.3604
Epoch 27, Training loss: 0.4208, Validation loss: 0.3595
Epoch 28, Training loss: 0.4195, Validation loss: 0.3603
Epoch 29, Training loss: 0.4178, Validation loss: 0.3569
Epoch 30, Training loss: 0.4161, Validation loss: 0.3577
Epoch 31, Training loss: 0.4153, Validation loss: 0.3558
Epoch 32, Training loss: 0.4146, Validation loss: 0.3557
Epoch 33, Training loss: 0.4136, Validation loss: 0.3540
Epoch 34, Training loss: 0.4127, Validation loss: 0.3545
Epoch 35, Training loss: 0.4117, Validation loss: 0.3572
Epoch 36, Training loss: 0.4087, Validation loss: 0.3384
Epoch 37, Training loss: 0.4071, Validation loss: 0.3410
Epoch 38, Training loss: 0.4067, Validation loss: 0.3398
Epoch 39, Training loss: 0.4064, Validation loss: 0.3400
Epoch 40, Training loss: 0.4060, Validation loss: 0.3418
Epoch 41, Training loss: 0.4065, Validation loss: 0.3399
Epoch 42, Training loss: 0.4070, Validation loss: 0.3392
Epoch 43, Training loss: 0.4068, Validation loss: 0.3393
Epoch 44, Training loss: 0.4061, Validation loss: 0.3387
Epoch 45, Training loss: 0.4060, Validation loss: 0.3385
Epoch 46, Training loss: 0.4064, Validation loss: 0.3409
Early stopping.
Epoch 0, Training loss: 0.5994, Validation loss: 0.5126
Epoch 1, Training loss: 0.5345, Validation loss: 0.4750
Epoch 2, Training loss: 0.5089, Validation loss: 0.4653
Epoch 3, Training loss: 0.4983, Validation loss: 0.4615
Epoch 4, Training loss: 0.4918, Validation loss: 0.4577
Epoch 5, Training loss: 0.4861, Validation loss: 0.4606
Epoch 6, Training loss: 0.4824, Validation loss: 0.4577
Epoch 7, Training loss: 0.4804, Validation loss: 0.4553
Epoch 8, Training loss: 0.4772, Validation loss: 0.4565
Epoch 9, Training loss: 0.4746, Validation loss: 0.4582
Epoch 10, Training loss: 0.4730, Validation loss: 0.4561
Epoch 11, Training loss: 0.4720, Validation loss: 0.4528
Epoch 12, Training loss: 0.4699, Validation loss: 0.4516
Epoch 13, Training loss: 0.4695, Validation loss: 0.4489
Epoch 14, Training loss: 0.4677, Validation loss: 0.4485
Epoch 15, Training loss: 0.4669, Validation loss: 0.4450
Epoch 16, Training loss: 0.4658, Validation loss: 0.4441
Epoch 17, Training loss: 0.4649, Validation loss: 0.4426
Epoch 18, Training loss: 0.4644, Validation loss: 0.4439
Epoch 19, Training loss: 0.4660, Validation loss: 0.4336
Epoch 20, Training loss: 0.4629, Validation loss: 0.4337
Epoch 21, Training loss: 0.4621, Validation loss: 0.4328
Epoch 22, Training loss: 0.4614, Validation loss: 0.4336
Epoch 23, Training loss: 0.4615, Validation loss: 0.4310
Epoch 24, Training loss: 0.4607, Validation loss: 0.4323
Epoch 25, Training loss: 0.4604, Validation loss: 0.4317
Epoch 26, Training loss: 0.4601, Validation loss: 0.4316
Epoch 27, Training loss: 0.4601, Validation loss: 0.4304
Epoch 28, Training loss: 0.4602, Validation loss: 0.4307
Epoch 29, Training loss: 0.4595, Validation loss: 0.4320
Epoch 30, Training loss: 0.4600, Validation loss: 0.4297
Epoch 31, Training loss: 0.4599, Validation loss: 0.4299
Epoch 32, Training loss: 0.4585, Validation loss: 0.4310
Epoch 33, Training loss: 0.4591, Validation loss: 0.4294
Epoch 34, Training loss: 0.4588, Validation loss: 0.4306
Epoch 35, Training loss: 0.4581, Validation loss: 0.4316
Epoch 36, Training loss: 0.4582, Validation loss: 0.4312
Epoch 37, Training loss: 0.4584, Validation loss: 0.4341
Epoch 38, Training loss: 0.4582, Validation loss: 0.4298
Epoch 39, Training loss: 0.4580, Validation loss: 0.4298
Epoch 40, Training loss: 0.4575, Validation loss: 0.4341
Epoch 41, Training loss: 0.4574, Validation loss: 0.4309
Epoch 42, Training loss: 0.4592, Validation loss: 0.4224
Epoch 43, Training loss: 0.4574, Validation loss: 0.4224
Epoch 44, Training loss: 0.4567, Validation loss: 0.4260
Epoch 45, Training loss: 0.4566, Validation loss: 0.4263
Epoch 46, Training loss: 0.4565, Validation loss: 0.4281
Epoch 47, Training loss: 0.4567, Validation loss: 0.4245
Epoch 48, Training loss: 0.4574, Validation loss: 0.4339
Epoch 49, Training loss: 0.4572, Validation loss: 0.4326
Epoch 50, Training loss: 0.4572, Validation loss: 0.4328
Epoch 51, Training loss: 0.4571, Validation loss: 0.4353
Epoch 52, Training loss: 0.4561, Validation loss: 0.4281
Epoch 53, Training loss: 0.4574, Validation loss: 0.4252
Early stopping.
Epoch 0, Training loss: 0.7319, Validation loss: 0.6110
Epoch 1, Training loss: 0.6178, Validation loss: 0.5122
Epoch 2, Training loss: 0.5618, Validation loss: 0.4708
Epoch 3, Training loss: 0.5291, Validation loss: 0.4402
Epoch 4, Training loss: 0.5134, Validation loss: 0.4296
Epoch 5, Training loss: 0.5031, Validation loss: 0.4261
Epoch 6, Training loss: 0.4968, Validation loss: 0.4262
Epoch 7, Training loss: 0.4920, Validation loss: 0.4214
Epoch 8, Training loss: 0.4891, Validation loss: 0.4183
Epoch 9, Training loss: 0.4865, Validation loss: 0.4155
Epoch 10, Training loss: 0.4844, Validation loss: 0.4136
Epoch 11, Training loss: 0.4817, Validation loss: 0.4160
Epoch 12, Training loss: 0.4793, Validation loss: 0.4106
Epoch 13, Training loss: 0.4776, Validation loss: 0.4098
Epoch 14, Training loss: 0.4769, Validation loss: 0.4088
Epoch 15, Training loss: 0.4749, Validation loss: 0.4093
Epoch 16, Training loss: 0.4735, Validation loss: 0.4088
Epoch 17, Training loss: 0.4721, Validation loss: 0.4093
Epoch 18, Training loss: 0.4709, Validation loss: 0.4102
Epoch 19, Training loss: 0.4700, Validation loss: 0.4093
Epoch 20, Training loss: 0.4691, Validation loss: 0.4091
Epoch 21, Training loss: 0.4883, Validation loss: 0.4238
Epoch 22, Training loss: 0.4759, Validation loss: 0.4189
Epoch 23, Training loss: 0.4712, Validation loss: 0.4160
Epoch 24, Training loss: 0.4683, Validation loss: 0.4145
Early stopping.
Epoch 0, Training loss: 1.0818, Validation loss: 0.8325
Epoch 1, Training loss: 1.0811, Validation loss: 0.8313
Epoch 2, Training loss: 1.0807, Validation loss: 0.8307
Epoch 3, Training loss: 1.0804, Validation loss: 0.8304
Epoch 4, Training loss: 1.0800, Validation loss: 0.8302
Epoch 5, Training loss: 1.0798, Validation loss: 0.8299
Epoch 6, Training loss: 1.0796, Validation loss: 0.8297
Epoch 7, Training loss: 1.0794, Validation loss: 0.8295
Epoch 8, Training loss: 1.0792, Validation loss: 0.8293
Epoch 9, Training loss: 1.0791, Validation loss: 0.8292
Epoch 10, Training loss: 1.0791, Validation loss: 0.8290
Epoch 11, Training loss: 1.0791, Validation loss: 0.8289
Epoch 12, Training loss: 1.0790, Validation loss: 0.8288
Epoch 13, Training loss: 1.0790, Validation loss: 0.8287
Epoch 14, Training loss: 1.0789, Validation loss: 0.8285
Epoch 15, Training loss: 1.0789, Validation loss: 0.8284
Epoch 16, Training loss: 1.0789, Validation loss: 0.8283
Epoch 17, Training loss: 1.0788, Validation loss: 0.8282
Epoch 18, Training loss: 1.0788, Validation loss: 0.8281
Epoch 19, Training loss: 1.0788, Validation loss: 0.8280
Epoch 20, Training loss: 1.0788, Validation loss: 0.8279
Epoch 21, Training loss: 1.0787, Validation loss: 0.8278
Epoch 22, Training loss: 1.0787, Validation loss: 0.8277
Epoch 23, Training loss: 1.0787, Validation loss: 0.8277
Epoch 24, Training loss: 1.0787, Validation loss: 0.8277
Epoch 25, Training loss: 1.0787, Validation loss: 0.8277
Epoch 26, Training loss: 1.0787, Validation loss: 0.8276
Epoch 27, Training loss: 1.0787, Validation loss: 0.8276
Epoch 28, Training loss: 1.0787, Validation loss: 0.8276
Epoch 29, Training loss: 1.0787, Validation loss: 0.8276
Epoch 30, Training loss: 1.0787, Validation loss: 0.8275
Epoch 31, Training loss: 1.0787, Validation loss: 0.8275
Epoch 32, Training loss: 1.0787, Validation loss: 0.8275
Epoch 33, Training loss: 1.0787, Validation loss: 0.8275
Epoch 34, Training loss: 1.0787, Validation loss: 0.8275
Epoch 35, Training loss: 1.0787, Validation loss: 0.8274
Epoch 36, Training loss: 1.0787, Validation loss: 0.8274
Epoch 37, Training loss: 1.0787, Validation loss: 0.8274
Epoch 38, Training loss: 1.0787, Validation loss: 0.8274
Epoch 39, Training loss: 1.0787, Validation loss: 0.8274
Epoch 40, Training loss: 1.0787, Validation loss: 0.8274
Epoch 41, Training loss: 1.0787, Validation loss: 0.8273
Epoch 42, Training loss: 1.0787, Validation loss: 0.8273
Epoch 43, Training loss: 1.0787, Validation loss: 0.8273
Epoch 44, Training loss: 1.0787, Validation loss: 0.8273
Epoch 45, Training loss: 1.0787, Validation loss: 0.8273
Epoch 46, Training loss: 1.0787, Validation loss: 0.8273
Epoch 47, Training loss: 1.0787, Validation loss: 0.8273
Epoch 48, Training loss: 1.0787, Validation loss: 0.8272
Epoch 49, Training loss: 1.0787, Validation loss: 0.8272
Epoch 50, Training loss: 1.0787, Validation loss: 0.8272
Epoch 51, Training loss: 1.0787, Validation loss: 0.8272
Epoch 52, Training loss: 1.0787, Validation loss: 0.8272
Epoch 53, Training loss: 1.0787, Validation loss: 0.8272
Epoch 54, Training loss: 1.0787, Validation loss: 0.8272
Epoch 55, Training loss: 1.0787, Validation loss: 0.8272
Epoch 56, Training loss: 1.0787, Validation loss: 0.8271
Epoch 57, Training loss: 1.0787, Validation loss: 0.8271
Epoch 58, Training loss: 1.0787, Validation loss: 0.8271
Epoch 59, Training loss: 1.0787, Validation loss: 0.8271
Epoch 60, Training loss: 1.0787, Validation loss: 0.8271
Epoch 61, Training loss: 1.0787, Validation loss: 0.8271
Epoch 62, Training loss: 1.0787, Validation loss: 0.8271
Epoch 63, Training loss: 1.0787, Validation loss: 0.8271
Epoch 64, Training loss: 1.0787, Validation loss: 0.8270
Epoch 65, Training loss: 1.0787, Validation loss: 0.8270
Epoch 66, Training loss: 1.0787, Validation loss: 0.8270
Epoch 67, Training loss: 1.0787, Validation loss: 0.8270
Epoch 68, Training loss: 1.0787, Validation loss: 0.8270
Epoch 69, Training loss: 1.0787, Validation loss: 0.8270
Epoch 70, Training loss: 1.0787, Validation loss: 0.8270
Epoch 71, Training loss: 1.0787, Validation loss: 0.8270
Epoch 72, Training loss: 1.0787, Validation loss: 0.8269
Epoch 73, Training loss: 1.0787, Validation loss: 0.8269
Epoch 74, Training loss: 1.0787, Validation loss: 0.8269
Epoch 75, Training loss: 1.0787, Validation loss: 0.8269
Epoch 76, Training loss: 1.0787, Validation loss: 0.8269
Epoch 77, Training loss: 1.0787, Validation loss: 0.8269
Epoch 78, Training loss: 1.0787, Validation loss: 0.8269
Epoch 79, Training loss: 1.0787, Validation loss: 0.8269
Epoch 80, Training loss: 1.0787, Validation loss: 0.8269
Epoch 81, Training loss: 1.0787, Validation loss: 0.8268
Epoch 82, Training loss: 1.0787, Validation loss: 0.8268
Epoch 83, Training loss: 1.0787, Validation loss: 0.8268
Epoch 84, Training loss: 1.0787, Validation loss: 0.8268
Epoch 85, Training loss: 1.0787, Validation loss: 0.8268
Epoch 86, Training loss: 1.0787, Validation loss: 0.8268
Epoch 87, Training loss: 1.0787, Validation loss: 0.8268
Epoch 88, Training loss: 1.0787, Validation loss: 0.8268
Epoch 89, Training loss: 1.0787, Validation loss: 0.8268
Epoch 90, Training loss: 1.0787, Validation loss: 0.8268
Epoch 91, Training loss: 1.0787, Validation loss: 0.8267
Epoch 92, Training loss: 1.0787, Validation loss: 0.8267
Epoch 93, Training loss: 1.0787, Validation loss: 0.8267
Epoch 94, Training loss: 1.0787, Validation loss: 0.8267
Epoch 95, Training loss: 1.0787, Validation loss: 0.8267
Epoch 96, Training loss: 1.0787, Validation loss: 0.8267
Epoch 97, Training loss: 1.0787, Validation loss: 0.8267
Epoch 98, Training loss: 1.0787, Validation loss: 0.8267
Epoch 99, Training loss: 1.0787, Validation loss: 0.8267
Epoch 100, Training loss: 1.0787, Validation loss: 0.8267
Epoch 101, Training loss: 1.0787, Validation loss: 0.8267
Epoch 102, Training loss: 1.0787, Validation loss: 0.8266
Epoch 103, Training loss: 1.0787, Validation loss: 0.8266
Epoch 104, Training loss: 1.0787, Validation loss: 0.8266
Epoch 105, Training loss: 1.0787, Validation loss: 0.8266
Epoch 106, Training loss: 1.0787, Validation loss: 0.8266
Epoch 107, Training loss: 1.0787, Validation loss: 0.8266
Epoch 108, Training loss: 1.0787, Validation loss: 0.8266
Epoch 109, Training loss: 1.0787, Validation loss: 0.8266
Epoch 110, Training loss: 1.0787, Validation loss: 0.8266
Epoch 111, Training loss: 1.0787, Validation loss: 0.8266
Epoch 112, Training loss: 1.0787, Validation loss: 0.8266
Epoch 113, Training loss: 1.0787, Validation loss: 0.8265
Epoch 114, Training loss: 1.0787, Validation loss: 0.8265
Epoch 115, Training loss: 1.0787, Validation loss: 0.8265
Epoch 116, Training loss: 1.0787, Validation loss: 0.8265
Epoch 117, Training loss: 1.0787, Validation loss: 0.8265
Epoch 118, Training loss: 1.0787, Validation loss: 0.8265
Epoch 119, Training loss: 1.0787, Validation loss: 0.8265
Epoch 120, Training loss: 1.0787, Validation loss: 0.8265
Epoch 121, Training loss: 1.0787, Validation loss: 0.8265
Epoch 122, Training loss: 1.0787, Validation loss: 0.8265
Epoch 123, Training loss: 1.0787, Validation loss: 0.8265
Epoch 124, Training loss: 1.0787, Validation loss: 0.8265
Epoch 125, Training loss: 1.0787, Validation loss: 0.8264
Epoch 126, Training loss: 1.0787, Validation loss: 0.8264
Epoch 127, Training loss: 1.0787, Validation loss: 0.8264
Epoch 128, Training loss: 1.0787, Validation loss: 0.8264
Epoch 129, Training loss: 1.0787, Validation loss: 0.8264
Epoch 130, Training loss: 1.0787, Validation loss: 0.8264
Epoch 131, Training loss: 1.0787, Validation loss: 0.8264
Epoch 132, Training loss: 1.0787, Validation loss: 0.8264
Epoch 133, Training loss: 1.0787, Validation loss: 0.8264
Epoch 134, Training loss: 1.0787, Validation loss: 0.8264
Epoch 135, Training loss: 1.0787, Validation loss: 0.8264
Epoch 136, Training loss: 1.0787, Validation loss: 0.8264
Epoch 137, Training loss: 1.0787, Validation loss: 0.8264
Epoch 138, Training loss: 1.0787, Validation loss: 0.8263
Epoch 139, Training loss: 1.0787, Validation loss: 0.8263
Epoch 140, Training loss: 1.0787, Validation loss: 0.8263
Epoch 141, Training loss: 1.0787, Validation loss: 0.8263
Epoch 142, Training loss: 1.0787, Validation loss: 0.8263
Epoch 143, Training loss: 1.0787, Validation loss: 0.8263
Epoch 144, Training loss: 1.0787, Validation loss: 0.8263
Epoch 145, Training loss: 1.0787, Validation loss: 0.8263
Epoch 146, Training loss: 1.0787, Validation loss: 0.8263
Epoch 147, Training loss: 1.0787, Validation loss: 0.8263
Epoch 148, Training loss: 1.0787, Validation loss: 0.8263
Epoch 149, Training loss: 1.0787, Validation loss: 0.8263
Epoch 150, Training loss: 1.0787, Validation loss: 0.8263
Epoch 151, Training loss: 1.0787, Validation loss: 0.8263
Epoch 152, Training loss: 1.0787, Validation loss: 0.8262
Epoch 153, Training loss: 1.0787, Validation loss: 0.8262
Epoch 154, Training loss: 1.0787, Validation loss: 0.8262
Epoch 155, Training loss: 1.0787, Validation loss: 0.8262
Epoch 156, Training loss: 1.0787, Validation loss: 0.8262
Epoch 157, Training loss: 1.0787, Validation loss: 0.8262
Epoch 158, Training loss: 1.0787, Validation loss: 0.8262
Epoch 159, Training loss: 1.0787, Validation loss: 0.8262
Epoch 160, Training loss: 1.0787, Validation loss: 0.8262
Epoch 161, Training loss: 1.0787, Validation loss: 0.8262
Epoch 162, Training loss: 1.0787, Validation loss: 0.8262
Epoch 163, Training loss: 1.0787, Validation loss: 0.8262
Epoch 164, Training loss: 1.0787, Validation loss: 0.8262
Epoch 165, Training loss: 1.0787, Validation loss: 0.8262
Epoch 166, Training loss: 1.0787, Validation loss: 0.8262
Epoch 167, Training loss: 1.0787, Validation loss: 0.8262
Epoch 168, Training loss: 1.0787, Validation loss: 0.8261
Epoch 169, Training loss: 1.0787, Validation loss: 0.8261
Epoch 170, Training loss: 1.0787, Validation loss: 0.8261
Epoch 171, Training loss: 1.0787, Validation loss: 0.8261
Epoch 172, Training loss: 1.0787, Validation loss: 0.8261
Epoch 173, Training loss: 1.0787, Validation loss: 0.8261
Epoch 174, Training loss: 1.0787, Validation loss: 0.8261
Epoch 175, Training loss: 1.0787, Validation loss: 0.8261
Epoch 176, Training loss: 1.0787, Validation loss: 0.8261
Epoch 177, Training loss: 1.0787, Validation loss: 0.8261
Epoch 178, Training loss: 1.0787, Validation loss: 0.8261
Epoch 179, Training loss: 1.0787, Validation loss: 0.8261
Epoch 180, Training loss: 1.0787, Validation loss: 0.8261
Epoch 181, Training loss: 1.0787, Validation loss: 0.8261
Epoch 182, Training loss: 1.0787, Validation loss: 0.8261
Epoch 183, Training loss: 1.0787, Validation loss: 0.8261
Epoch 184, Training loss: 1.0787, Validation loss: 0.8261
Epoch 185, Training loss: 1.0787, Validation loss: 0.8261
Epoch 186, Training loss: 1.0787, Validation loss: 0.8260
Epoch 187, Training loss: 1.0787, Validation loss: 0.8260
Epoch 188, Training loss: 1.0787, Validation loss: 0.8260
Epoch 189, Training loss: 1.0787, Validation loss: 0.8260
Epoch 190, Training loss: 1.0787, Validation loss: 0.8260
Epoch 191, Training loss: 1.0787, Validation loss: 0.8260
Epoch 192, Training loss: 1.0787, Validation loss: 0.8260
Epoch 193, Training loss: 1.0787, Validation loss: 0.8260
Epoch 194, Training loss: 1.0787, Validation loss: 0.8260
Epoch 195, Training loss: 1.0787, Validation loss: 0.8260
Epoch 196, Training loss: 1.0787, Validation loss: 0.8260
Epoch 197, Training loss: 1.0787, Validation loss: 0.8260
Epoch 198, Training loss: 1.0787, Validation loss: 0.8260
Epoch 199, Training loss: 1.0787, Validation loss: 0.8260
Epoch 200, Training loss: 1.0787, Validation loss: 0.8260
Epoch 201, Training loss: 1.0787, Validation loss: 0.8260
Epoch 202, Training loss: 1.0787, Validation loss: 0.8260
Epoch 203, Training loss: 1.0787, Validation loss: 0.8260
Epoch 204, Training loss: 1.0787, Validation loss: 0.8260
Epoch 205, Training loss: 1.0787, Validation loss: 0.8260
Epoch 206, Training loss: 1.0787, Validation loss: 0.8259
Epoch 207, Training loss: 1.0787, Validation loss: 0.8259
Epoch 208, Training loss: 1.0787, Validation loss: 0.8259
Epoch 209, Training loss: 1.0787, Validation loss: 0.8259
Epoch 210, Training loss: 1.0787, Validation loss: 0.8259
Epoch 211, Training loss: 1.0787, Validation loss: 0.8259
Epoch 212, Training loss: 1.0787, Validation loss: 0.8259
Epoch 213, Training loss: 1.0787, Validation loss: 0.8259
Epoch 214, Training loss: 1.0787, Validation loss: 0.8259
Epoch 215, Training loss: 1.0787, Validation loss: 0.8259
Epoch 216, Training loss: 1.0787, Validation loss: 0.8259
Epoch 217, Training loss: 1.0787, Validation loss: 0.8259
Epoch 218, Training loss: 1.0787, Validation loss: 0.8259
Epoch 219, Training loss: 1.0787, Validation loss: 0.8259
Epoch 220, Training loss: 1.0787, Validation loss: 0.8259
Epoch 221, Training loss: 1.0787, Validation loss: 0.8259
Epoch 222, Training loss: 1.0787, Validation loss: 0.8259
Epoch 223, Training loss: 1.0787, Validation loss: 0.8259
Epoch 224, Training loss: 1.0787, Validation loss: 0.8259
Epoch 225, Training loss: 1.0787, Validation loss: 0.8259
Epoch 226, Training loss: 1.0787, Validation loss: 0.8259
Epoch 227, Training loss: 1.0787, Validation loss: 0.8259
Epoch 228, Training loss: 1.0787, Validation loss: 0.8258
Epoch 229, Training loss: 1.0787, Validation loss: 0.8258
Epoch 230, Training loss: 1.0787, Validation loss: 0.8258
Epoch 231, Training loss: 1.0787, Validation loss: 0.8258
Epoch 232, Training loss: 1.0787, Validation loss: 0.8258
Epoch 233, Training loss: 1.0787, Validation loss: 0.8258
Epoch 234, Training loss: 1.0787, Validation loss: 0.8258
Epoch 235, Training loss: 1.0787, Validation loss: 0.8258
Epoch 236, Training loss: 1.0787, Validation loss: 0.8258
Epoch 237, Training loss: 1.0787, Validation loss: 0.8258
Epoch 238, Training loss: 1.0787, Validation loss: 0.8258
Epoch 239, Training loss: 1.0787, Validation loss: 0.8258
Epoch 240, Training loss: 1.0787, Validation loss: 0.8258
Epoch 241, Training loss: 1.0787, Validation loss: 0.8258
Epoch 242, Training loss: 1.0787, Validation loss: 0.8258
Epoch 243, Training loss: 1.0787, Validation loss: 0.8258
Epoch 244, Training loss: 1.0787, Validation loss: 0.8258
Epoch 245, Training loss: 1.0787, Validation loss: 0.8258
Epoch 246, Training loss: 1.0787, Validation loss: 0.8258
Epoch 247, Training loss: 1.0787, Validation loss: 0.8258
Epoch 248, Training loss: 1.0787, Validation loss: 0.8258
Epoch 249, Training loss: 1.0787, Validation loss: 0.8258
Epoch 250, Training loss: 1.0787, Validation loss: 0.8258
Epoch 251, Training loss: 1.0787, Validation loss: 0.8258
Epoch 252, Training loss: 1.0787, Validation loss: 0.8258
Epoch 253, Training loss: 1.0787, Validation loss: 0.8258
Epoch 254, Training loss: 1.0787, Validation loss: 0.8258
Epoch 255, Training loss: 1.0787, Validation loss: 0.8257
Epoch 256, Training loss: 1.0787, Validation loss: 0.8257
Epoch 257, Training loss: 1.0787, Validation loss: 0.8257
Epoch 258, Training loss: 1.0787, Validation loss: 0.8257
Epoch 259, Training loss: 1.0787, Validation loss: 0.8257
Epoch 260, Training loss: 1.0787, Validation loss: 0.8257
Epoch 261, Training loss: 1.0787, Validation loss: 0.8257
Epoch 262, Training loss: 1.0787, Validation loss: 0.8257
Epoch 263, Training loss: 1.0787, Validation loss: 0.8257
Epoch 264, Training loss: 1.0787, Validation loss: 0.8257
Epoch 265, Training loss: 1.0787, Validation loss: 0.8257
Epoch 266, Training loss: 1.0787, Validation loss: 0.8257
Epoch 267, Training loss: 1.0787, Validation loss: 0.8257
Epoch 268, Training loss: 1.0787, Validation loss: 0.8257
Epoch 269, Training loss: 1.0787, Validation loss: 0.8257
Epoch 270, Training loss: 1.0787, Validation loss: 0.8257
Epoch 271, Training loss: 1.0787, Validation loss: 0.8257
Epoch 272, Training loss: 1.0787, Validation loss: 0.8257
Epoch 273, Training loss: 1.0787, Validation loss: 0.8257
Epoch 274, Training loss: 1.0787, Validation loss: 0.8257
Epoch 275, Training loss: 1.0787, Validation loss: 0.8257
Epoch 276, Training loss: 1.0787, Validation loss: 0.8257
Epoch 277, Training loss: 1.0787, Validation loss: 0.8257
Epoch 278, Training loss: 1.0787, Validation loss: 0.8257
Epoch 279, Training loss: 1.0787, Validation loss: 0.8257
Epoch 280, Training loss: 1.0787, Validation loss: 0.8257
Epoch 281, Training loss: 1.0787, Validation loss: 0.8257
Epoch 282, Training loss: 1.0787, Validation loss: 0.8257
Epoch 283, Training loss: 1.0787, Validation loss: 0.8257
Epoch 284, Training loss: 1.0787, Validation loss: 0.8257
Epoch 285, Training loss: 1.0787, Validation loss: 0.8257
Epoch 286, Training loss: 1.0787, Validation loss: 0.8256
Epoch 287, Training loss: 1.0787, Validation loss: 0.8256
Epoch 288, Training loss: 1.0787, Validation loss: 0.8256
Epoch 289, Training loss: 1.0787, Validation loss: 0.8256
Epoch 290, Training loss: 1.0787, Validation loss: 0.8256
Epoch 291, Training loss: 1.0787, Validation loss: 0.8256
Epoch 292, Training loss: 1.0787, Validation loss: 0.8256
Epoch 293, Training loss: 1.0787, Validation loss: 0.8256
Epoch 294, Training loss: 1.0787, Validation loss: 0.8256
Epoch 295, Training loss: 1.0787, Validation loss: 0.8256
Epoch 296, Training loss: 1.0787, Validation loss: 0.8256
Epoch 297, Training loss: 1.0787, Validation loss: 0.8256
Epoch 298, Training loss: 1.0787, Validation loss: 0.8256
Epoch 299, Training loss: 1.0787, Validation loss: 0.8256
Epoch 300, Training loss: 1.0787, Validation loss: 0.8256
Epoch 301, Training loss: 1.0787, Validation loss: 0.8256
Epoch 302, Training loss: 1.0787, Validation loss: 0.8256
Epoch 303, Training loss: 1.0787, Validation loss: 0.8256
Epoch 304, Training loss: 1.0787, Validation loss: 0.8256
Epoch 305, Training loss: 1.0787, Validation loss: 0.8256
Epoch 306, Training loss: 1.0787, Validation loss: 0.8256
Epoch 307, Training loss: 1.0787, Validation loss: 0.8256
Epoch 308, Training loss: 1.0787, Validation loss: 0.8256
Epoch 309, Training loss: 1.0787, Validation loss: 0.8256
Epoch 310, Training loss: 1.0787, Validation loss: 0.8256
Epoch 311, Training loss: 1.0787, Validation loss: 0.8256
Epoch 312, Training loss: 1.0787, Validation loss: 0.8256
Epoch 313, Training loss: 1.0787, Validation loss: 0.8256
Epoch 314, Training loss: 1.0787, Validation loss: 0.8256
Epoch 315, Training loss: 1.0787, Validation loss: 0.8256
Epoch 316, Training loss: 1.0787, Validation loss: 0.8256
Epoch 317, Training loss: 1.0787, Validation loss: 0.8256
Epoch 318, Training loss: 1.0787, Validation loss: 0.8256
Epoch 319, Training loss: 1.0787, Validation loss: 0.8256
Epoch 320, Training loss: 1.0787, Validation loss: 0.8256
Epoch 321, Training loss: 1.0787, Validation loss: 0.8256
Epoch 322, Training loss: 1.0787, Validation loss: 0.8256
Epoch 323, Training loss: 1.0787, Validation loss: 0.8256
Epoch 324, Training loss: 1.0787, Validation loss: 0.8256
Epoch 325, Training loss: 1.0787, Validation loss: 0.8255
Epoch 326, Training loss: 1.0787, Validation loss: 0.8255
Epoch 327, Training loss: 1.0787, Validation loss: 0.8255
Epoch 328, Training loss: 1.0787, Validation loss: 0.8255
Epoch 329, Training loss: 1.0787, Validation loss: 0.8255
Epoch 330, Training loss: 1.0787, Validation loss: 0.8255
Epoch 331, Training loss: 1.0787, Validation loss: 0.8255
Epoch 332, Training loss: 1.0787, Validation loss: 0.8255
Epoch 333, Training loss: 1.0787, Validation loss: 0.8255
Epoch 334, Training loss: 1.0787, Validation loss: 0.8255
Epoch 335, Training loss: 1.0787, Validation loss: 0.8255
Epoch 336, Training loss: 1.0787, Validation loss: 0.8255
Epoch 337, Training loss: 1.0787, Validation loss: 0.8255
Epoch 338, Training loss: 1.0787, Validation loss: 0.8255
Epoch 339, Training loss: 1.0787, Validation loss: 0.8255
Epoch 340, Training loss: 1.0787, Validation loss: 0.8255
Epoch 341, Training loss: 1.0787, Validation loss: 0.8255
Epoch 342, Training loss: 1.0787, Validation loss: 0.8255
Epoch 343, Training loss: 1.0787, Validation loss: 0.8255
Epoch 344, Training loss: 1.0787, Validation loss: 0.8255
Epoch 345, Training loss: 1.0787, Validation loss: 0.8255
Epoch 346, Training loss: 1.0787, Validation loss: 0.8255
Epoch 347, Training loss: 1.0787, Validation loss: 0.8255
Epoch 348, Training loss: 1.0787, Validation loss: 0.8255
Epoch 349, Training loss: 1.0787, Validation loss: 0.8255
Epoch 350, Training loss: 1.0787, Validation loss: 0.8255
Epoch 351, Training loss: 1.0787, Validation loss: 0.8255
Epoch 352, Training loss: 1.0787, Validation loss: 0.8255
Epoch 353, Training loss: 1.0787, Validation loss: 0.8255
Epoch 354, Training loss: 1.0787, Validation loss: 0.8255
Epoch 355, Training loss: 1.0787, Validation loss: 0.8255
Epoch 356, Training loss: 1.0787, Validation loss: 0.8255
Epoch 357, Training loss: 1.0787, Validation loss: 0.8255
Epoch 358, Training loss: 1.0787, Validation loss: 0.8255
Epoch 359, Training loss: 1.0787, Validation loss: 0.8255
Epoch 360, Training loss: 1.0787, Validation loss: 0.8255
Epoch 361, Training loss: 1.0787, Validation loss: 0.8255
Epoch 362, Training loss: 1.0787, Validation loss: 0.8255
Epoch 363, Training loss: 1.0787, Validation loss: 0.8255
Epoch 364, Training loss: 1.0787, Validation loss: 0.8255
Epoch 365, Training loss: 1.0787, Validation loss: 0.8255
Epoch 366, Training loss: 1.0787, Validation loss: 0.8255
Epoch 367, Training loss: 1.0787, Validation loss: 0.8255
Epoch 368, Training loss: 1.0787, Validation loss: 0.8255
Epoch 369, Training loss: 1.0787, Validation loss: 0.8255
Epoch 370, Training loss: 1.0787, Validation loss: 0.8255
Epoch 371, Training loss: 1.0787, Validation loss: 0.8255
Epoch 372, Training loss: 1.0787, Validation loss: 0.8255
Epoch 373, Training loss: 1.0787, Validation loss: 0.8255
Epoch 374, Training loss: 1.0787, Validation loss: 0.8255
Epoch 375, Training loss: 1.0787, Validation loss: 0.8254
Epoch 376, Training loss: 1.0787, Validation loss: 0.8254
Epoch 377, Training loss: 1.0787, Validation loss: 0.8254
Epoch 378, Training loss: 1.0787, Validation loss: 0.8254
Epoch 379, Training loss: 1.0787, Validation loss: 0.8254
Epoch 380, Training loss: 1.0787, Validation loss: 0.8254
Epoch 381, Training loss: 1.0787, Validation loss: 0.8254
Epoch 382, Training loss: 1.0787, Validation loss: 0.8254
Epoch 383, Training loss: 1.0787, Validation loss: 0.8254
Epoch 384, Training loss: 1.0787, Validation loss: 0.8254
Epoch 385, Training loss: 1.0787, Validation loss: 0.8254
Epoch 386, Training loss: 1.0787, Validation loss: 0.8254
Epoch 387, Training loss: 1.0787, Validation loss: 0.8254
Epoch 388, Training loss: 1.0787, Validation loss: 0.8254
Epoch 389, Training loss: 1.0787, Validation loss: 0.8254
Epoch 390, Training loss: 1.0787, Validation loss: 0.8254
Epoch 391, Training loss: 1.0787, Validation loss: 0.8254
Epoch 392, Training loss: 1.0787, Validation loss: 0.8254
Epoch 393, Training loss: 1.0787, Validation loss: 0.8254
Epoch 394, Training loss: 1.0787, Validation loss: 0.8254
Epoch 395, Training loss: 1.0787, Validation loss: 0.8254
Epoch 396, Training loss: 1.0787, Validation loss: 0.8254
Epoch 397, Training loss: 1.0787, Validation loss: 0.8254
Epoch 398, Training loss: 1.0787, Validation loss: 0.8254
Epoch 399, Training loss: 1.0787, Validation loss: 0.8254
Epoch 400, Training loss: 1.0787, Validation loss: 0.8254
Epoch 401, Training loss: 1.0787, Validation loss: 0.8254
Epoch 402, Training loss: 1.0787, Validation loss: 0.8254
Epoch 403, Training loss: 1.0787, Validation loss: 0.8254
Epoch 404, Training loss: 1.0787, Validation loss: 0.8254
Epoch 405, Training loss: 1.0787, Validation loss: 0.8254
Epoch 406, Training loss: 1.0787, Validation loss: 0.8254
Epoch 407, Training loss: 1.0787, Validation loss: 0.8254
Epoch 408, Training loss: 1.0787, Validation loss: 0.8254
Epoch 409, Training loss: 1.0787, Validation loss: 0.8254
Epoch 410, Training loss: 1.0787, Validation loss: 0.8254
Epoch 411, Training loss: 1.0787, Validation loss: 0.8254
Epoch 412, Training loss: 1.0787, Validation loss: 0.8254
Epoch 413, Training loss: 1.0787, Validation loss: 0.8254
Epoch 414, Training loss: 1.0787, Validation loss: 0.8254
Epoch 415, Training loss: 1.0787, Validation loss: 0.8254
Epoch 416, Training loss: 1.0787, Validation loss: 0.8254
Epoch 417, Training loss: 1.0787, Validation loss: 0.8254
Epoch 418, Training loss: 1.0787, Validation loss: 0.8254
Epoch 419, Training loss: 1.0787, Validation loss: 0.8254
Epoch 420, Training loss: 1.0787, Validation loss: 0.8254
Epoch 421, Training loss: 1.0787, Validation loss: 0.8254
Epoch 422, Training loss: 1.0787, Validation loss: 0.8254
Epoch 423, Training loss: 1.0787, Validation loss: 0.8254
Epoch 424, Training loss: 1.0787, Validation loss: 0.8254
Epoch 425, Training loss: 1.0787, Validation loss: 0.8254
Epoch 426, Training loss: 1.0787, Validation loss: 0.8254
Epoch 427, Training loss: 1.0787, Validation loss: 0.8254
Epoch 428, Training loss: 1.0787, Validation loss: 0.8254
Epoch 429, Training loss: 1.0787, Validation loss: 0.8254
Epoch 430, Training loss: 1.0787, Validation loss: 0.8254
Epoch 431, Training loss: 1.0787, Validation loss: 0.8254
Epoch 432, Training loss: 1.0787, Validation loss: 0.8254
Epoch 433, Training loss: 1.0787, Validation loss: 0.8254
Epoch 434, Training loss: 1.0787, Validation loss: 0.8254
Epoch 435, Training loss: 1.0787, Validation loss: 0.8254
Epoch 436, Training loss: 1.0787, Validation loss: 0.8254
Epoch 437, Training loss: 1.0787, Validation loss: 0.8254
Epoch 438, Training loss: 1.0787, Validation loss: 0.8254
Epoch 439, Training loss: 1.0787, Validation loss: 0.8254
Epoch 440, Training loss: 1.0787, Validation loss: 0.8254
Epoch 441, Training loss: 1.0787, Validation loss: 0.8254
Epoch 442, Training loss: 1.0787, Validation loss: 0.8254
Epoch 443, Training loss: 1.0787, Validation loss: 0.8254
Epoch 444, Training loss: 1.0787, Validation loss: 0.8254
Epoch 445, Training loss: 1.0787, Validation loss: 0.8253
Epoch 446, Training loss: 1.0787, Validation loss: 0.8253
Epoch 447, Training loss: 1.0787, Validation loss: 0.8253
Epoch 448, Training loss: 1.0787, Validation loss: 0.8253
Epoch 449, Training loss: 1.0787, Validation loss: 0.8253
Epoch 450, Training loss: 1.0787, Validation loss: 0.8253
Epoch 451, Training loss: 1.0787, Validation loss: 0.8253
Epoch 452, Training loss: 1.0787, Validation loss: 0.8253
Epoch 453, Training loss: 1.0787, Validation loss: 0.8253
Epoch 454, Training loss: 1.0787, Validation loss: 0.8253
Epoch 455, Training loss: 1.0787, Validation loss: 0.8253
Epoch 456, Training loss: 1.0787, Validation loss: 0.8253
Epoch 457, Training loss: 1.0787, Validation loss: 0.8253
Epoch 458, Training loss: 1.0787, Validation loss: 0.8253
Epoch 459, Training loss: 1.0787, Validation loss: 0.8253
Epoch 460, Training loss: 1.0787, Validation loss: 0.8253
Epoch 461, Training loss: 1.0787, Validation loss: 0.8253
Epoch 462, Training loss: 1.0787, Validation loss: 0.8253
Epoch 463, Training loss: 1.0787, Validation loss: 0.8253
Epoch 464, Training loss: 1.0787, Validation loss: 0.8253
Epoch 465, Training loss: 1.0787, Validation loss: 0.8253
Epoch 466, Training loss: 1.0787, Validation loss: 0.8253
Epoch 467, Training loss: 1.0787, Validation loss: 0.8253
Epoch 468, Training loss: 1.0787, Validation loss: 0.8253
Epoch 469, Training loss: 1.0787, Validation loss: 0.8253
Epoch 470, Training loss: 1.0787, Validation loss: 0.8253
Epoch 471, Training loss: 1.0787, Validation loss: 0.8253
Epoch 472, Training loss: 1.0787, Validation loss: 0.8253
Epoch 473, Training loss: 1.0787, Validation loss: 0.8253
Epoch 474, Training loss: 1.0787, Validation loss: 0.8253
Epoch 475, Training loss: 1.0787, Validation loss: 0.8253
Epoch 476, Training loss: 1.0787, Validation loss: 0.8253
Epoch 477, Training loss: 1.0787, Validation loss: 0.8253
Epoch 478, Training loss: 1.0787, Validation loss: 0.8253
Epoch 479, Training loss: 1.0787, Validation loss: 0.8253
Epoch 480, Training loss: 1.0787, Validation loss: 0.8253
Epoch 481, Training loss: 1.0787, Validation loss: 0.8253
Epoch 482, Training loss: 1.0787, Validation loss: 0.8253
Epoch 483, Training loss: 1.0787, Validation loss: 0.8253
Epoch 484, Training loss: 1.0787, Validation loss: 0.8253
Epoch 485, Training loss: 1.0787, Validation loss: 0.8253
Epoch 486, Training loss: 1.0787, Validation loss: 0.8253
Epoch 487, Training loss: 1.0787, Validation loss: 0.8253
Epoch 488, Training loss: 1.0787, Validation loss: 0.8253
Epoch 489, Training loss: 1.0787, Validation loss: 0.8253
Epoch 490, Training loss: 1.0787, Validation loss: 0.8253
Epoch 491, Training loss: 1.0787, Validation loss: 0.8253
Epoch 492, Training loss: 1.0787, Validation loss: 0.8253
Epoch 493, Training loss: 1.0787, Validation loss: 0.8253
Epoch 494, Training loss: 1.0787, Validation loss: 0.8253
Epoch 495, Training loss: 1.0787, Validation loss: 0.8253
Epoch 496, Training loss: 1.0787, Validation loss: 0.8253
Epoch 497, Training loss: 1.0787, Validation loss: 0.8253
Epoch 498, Training loss: 1.0787, Validation loss: 0.8253
Epoch 499, Training loss: 1.0787, Validation loss: 0.8253
Epoch 0, Training loss: 0.4362, Validation loss: 0.4039
Epoch 1, Training loss: 0.4221, Validation loss: 0.3711
Epoch 2, Training loss: 0.4283, Validation loss: 0.3602
Epoch 3, Training loss: 0.4091, Validation loss: 0.3565
Epoch 4, Training loss: 0.4080, Validation loss: 0.3469
Epoch 5, Training loss: 0.4042, Validation loss: 0.3503
Epoch 6, Training loss: 0.4019, Validation loss: 0.3434
Epoch 7, Training loss: 0.4378, Validation loss: 0.3438
Epoch 8, Training loss: 0.3994, Validation loss: 0.3352
Epoch 9, Training loss: 0.3980, Validation loss: 0.3371
Epoch 10, Training loss: 0.3975, Validation loss: 0.3361
Epoch 11, Training loss: 0.3972, Validation loss: 0.3404
Epoch 12, Training loss: 0.3974, Validation loss: 0.3397
Epoch 13, Training loss: 0.3974, Validation loss: 0.3384
Epoch 14, Training loss: 0.4005, Validation loss: 0.3340
Epoch 15, Training loss: 0.3977, Validation loss: 0.3415
Epoch 16, Training loss: 0.3975, Validation loss: 0.3410
Epoch 17, Training loss: 0.3982, Validation loss: 0.3472
Epoch 18, Training loss: 0.3979, Validation loss: 0.3429
Epoch 19, Training loss: 0.3980, Validation loss: 0.3447
Epoch 20, Training loss: 0.3982, Validation loss: 0.3422
Epoch 21, Training loss: 0.3986, Validation loss: 0.3381
Epoch 22, Training loss: 0.3987, Validation loss: 0.3438
Epoch 23, Training loss: 0.3988, Validation loss: 0.3426
Epoch 24, Training loss: 0.3992, Validation loss: 0.3400
Early stopping.
Epoch 0, Training loss: 0.5029, Validation loss: 0.4490
Epoch 1, Training loss: 0.4508, Validation loss: 0.3801
Epoch 2, Training loss: 0.4336, Validation loss: 0.3587
Epoch 3, Training loss: 0.4249, Validation loss: 0.3426
Epoch 4, Training loss: 0.4203, Validation loss: 0.3361
Epoch 5, Training loss: 0.4132, Validation loss: 0.3409
Epoch 6, Training loss: 0.4098, Validation loss: 0.3404
Epoch 7, Training loss: 0.4087, Validation loss: 0.3354
Epoch 8, Training loss: 0.4070, Validation loss: 0.3363
Epoch 9, Training loss: 0.4061, Validation loss: 0.3484
Epoch 10, Training loss: 0.4049, Validation loss: 0.3454
Epoch 11, Training loss: 0.4050, Validation loss: 0.3469
Epoch 12, Training loss: 0.4032, Validation loss: 0.3413
Epoch 13, Training loss: 0.4032, Validation loss: 0.3391
Epoch 14, Training loss: 0.4031, Validation loss: 0.3456
Epoch 15, Training loss: 0.4025, Validation loss: 0.3457
Epoch 16, Training loss: 0.4017, Validation loss: 0.3441
Epoch 17, Training loss: 0.4011, Validation loss: 0.3377
Early stopping.
Epoch 0, Training loss: 0.5181, Validation loss: 0.4281
Epoch 1, Training loss: 0.4597, Validation loss: 0.3929
Epoch 2, Training loss: 0.4417, Validation loss: 0.3823
Epoch 3, Training loss: 0.4326, Validation loss: 0.3733
Epoch 4, Training loss: 0.4279, Validation loss: 0.3725
Epoch 5, Training loss: 0.4227, Validation loss: 0.3622
Epoch 6, Training loss: 0.4196, Validation loss: 0.3583
Epoch 7, Training loss: 0.4167, Validation loss: 0.3567
Epoch 8, Training loss: 0.4141, Validation loss: 0.3496
Epoch 9, Training loss: 0.4131, Validation loss: 0.3433
Epoch 10, Training loss: 0.4112, Validation loss: 0.3446
Epoch 11, Training loss: 0.4107, Validation loss: 0.3443
Epoch 12, Training loss: 0.4107, Validation loss: 0.3393
Epoch 13, Training loss: 0.4098, Validation loss: 0.3426
Epoch 14, Training loss: 0.4081, Validation loss: 0.3406
Epoch 15, Training loss: 0.4100, Validation loss: 0.3540
Epoch 16, Training loss: 0.4086, Validation loss: 0.3485
Epoch 17, Training loss: 0.4074, Validation loss: 0.3412
Epoch 18, Training loss: 0.4064, Validation loss: 0.3409
Epoch 19, Training loss: 0.4055, Validation loss: 0.3407
Epoch 20, Training loss: 0.4042, Validation loss: 0.3353
Epoch 21, Training loss: 0.4077, Validation loss: 0.3182
Epoch 22, Training loss: 0.4040, Validation loss: 0.3198
Epoch 23, Training loss: 0.4281, Validation loss: 0.3275
Epoch 24, Training loss: 0.4067, Validation loss: 0.3211
Epoch 25, Training loss: 0.4009, Validation loss: 0.3239
Epoch 26, Training loss: 0.4009, Validation loss: 0.3237
Epoch 27, Training loss: 0.3989, Validation loss: 0.3281
Epoch 28, Training loss: 0.3991, Validation loss: 0.3359
Epoch 29, Training loss: 0.3995, Validation loss: 0.3375
Epoch 30, Training loss: 0.3991, Validation loss: 0.3354
Epoch 31, Training loss: 0.3989, Validation loss: 0.3342
Early stopping.
Epoch 0, Training loss: 0.5211, Validation loss: 0.5009
Epoch 1, Training loss: 0.4940, Validation loss: 0.4950
Epoch 2, Training loss: 0.4815, Validation loss: 0.4866
Epoch 3, Training loss: 0.4739, Validation loss: 0.4797
Epoch 4, Training loss: 0.4639, Validation loss: 0.4685
Epoch 5, Training loss: 0.4698, Validation loss: 0.4571
Epoch 6, Training loss: 0.5235, Validation loss: 0.5748
Epoch 7, Training loss: 0.4517, Validation loss: 0.4537
Epoch 8, Training loss: 0.4703, Validation loss: 0.5171
Epoch 9, Training loss: 0.4495, Validation loss: 0.4778
Epoch 10, Training loss: 0.4296, Validation loss: 0.4383
Epoch 11, Training loss: 0.4256, Validation loss: 0.4397
Epoch 12, Training loss: 0.4270, Validation loss: 0.4032
Epoch 13, Training loss: 0.4198, Validation loss: 0.4092
Epoch 14, Training loss: 0.4117, Validation loss: 0.4221
Epoch 15, Training loss: 0.4139, Validation loss: 0.4340
Epoch 16, Training loss: 0.4214, Validation loss: 0.4525
Epoch 17, Training loss: 0.4813, Validation loss: 0.5443
Epoch 18, Training loss: 0.4022, Validation loss: 0.4168
Epoch 19, Training loss: 0.4013, Validation loss: 0.4055
Epoch 20, Training loss: 0.3982, Validation loss: 0.4017
Epoch 21, Training loss: 0.3987, Validation loss: 0.4165
Epoch 22, Training loss: 0.4048, Validation loss: 0.4174
Epoch 23, Training loss: 0.3951, Validation loss: 0.3938
Epoch 24, Training loss: 0.3956, Validation loss: 0.3906
Epoch 25, Training loss: 0.3955, Validation loss: 0.3884
Epoch 26, Training loss: 0.3954, Validation loss: 0.3843
Epoch 27, Training loss: 0.3918, Validation loss: 0.3953
Epoch 28, Training loss: 0.3930, Validation loss: 0.4067
Epoch 29, Training loss: 0.3925, Validation loss: 0.4005
Epoch 30, Training loss: 0.4505, Validation loss: 0.4163
Epoch 31, Training loss: 0.4224, Validation loss: 0.4372
Epoch 32, Training loss: 0.3882, Validation loss: 0.3997
Epoch 33, Training loss: 0.4098, Validation loss: 0.3796
Epoch 34, Training loss: 0.4289, Validation loss: 0.4680
Epoch 35, Training loss: 0.3884, Validation loss: 0.3894
Epoch 36, Training loss: 0.4424, Validation loss: 0.4519
Epoch 37, Training loss: 0.3964, Validation loss: 0.3945
Epoch 38, Training loss: 0.3867, Validation loss: 0.4117
Epoch 39, Training loss: 0.3851, Validation loss: 0.3955
Epoch 40, Training loss: 0.3873, Validation loss: 0.4131
Epoch 41, Training loss: 0.3885, Validation loss: 0.3979
Epoch 42, Training loss: 0.3897, Validation loss: 0.4103
Epoch 43, Training loss: 0.3904, Validation loss: 0.3925
Early stopping.
Epoch 0, Training loss: 0.9535, Validation loss: 0.7576
Epoch 1, Training loss: 0.5927, Validation loss: 0.5842
Epoch 2, Training loss: 0.5102, Validation loss: 0.4542
Epoch 3, Training loss: 0.4886, Validation loss: 0.4792
Epoch 4, Training loss: 0.5012, Validation loss: 0.5000
Epoch 5, Training loss: 0.4748, Validation loss: 0.4520
Epoch 6, Training loss: 0.4688, Validation loss: 0.4587
Epoch 7, Training loss: 0.4667, Validation loss: 0.4486
Epoch 8, Training loss: 0.4690, Validation loss: 0.4378
Epoch 9, Training loss: 0.4709, Validation loss: 0.4755
Epoch 10, Training loss: 0.8133, Validation loss: 0.6291
Epoch 11, Training loss: 0.5673, Validation loss: 0.5698
Epoch 12, Training loss: 0.4768, Validation loss: 0.4525
Epoch 13, Training loss: 0.4919, Validation loss: 0.5173
Epoch 14, Training loss: 0.4768, Validation loss: 0.4301
Epoch 15, Training loss: 0.4500, Validation loss: 0.4363
Epoch 16, Training loss: 0.4689, Validation loss: 0.4222
Epoch 17, Training loss: 0.4693, Validation loss: 0.4202
Epoch 18, Training loss: 0.4429, Validation loss: 0.4310
Epoch 19, Training loss: 0.4416, Validation loss: 0.4205
Epoch 20, Training loss: 0.4672, Validation loss: 0.4821
Epoch 21, Training loss: 0.4396, Validation loss: 0.4199
Epoch 22, Training loss: 0.4385, Validation loss: 0.4302
Epoch 23, Training loss: 0.4351, Validation loss: 0.4117
Epoch 24, Training loss: 0.4573, Validation loss: 0.4039
Epoch 25, Training loss: 0.4582, Validation loss: 0.4142
Epoch 26, Training loss: 0.4423, Validation loss: 0.4027
Epoch 27, Training loss: 0.4266, Validation loss: 0.4165
Epoch 28, Training loss: 0.4254, Validation loss: 0.4097
Epoch 29, Training loss: 0.4238, Validation loss: 0.4171
Epoch 30, Training loss: 0.4518, Validation loss: 0.3960
Epoch 31, Training loss: 0.4222, Validation loss: 0.4045
Epoch 32, Training loss: 0.5154, Validation loss: 0.5582
Epoch 33, Training loss: 0.4201, Validation loss: 0.4041
Epoch 34, Training loss: 0.4191, Validation loss: 0.4142
Epoch 35, Training loss: 0.4164, Validation loss: 0.4064
Epoch 36, Training loss: 0.4152, Validation loss: 0.4045
Epoch 37, Training loss: 0.4155, Validation loss: 0.3986
Epoch 38, Training loss: 0.4664, Validation loss: 0.4962
Epoch 39, Training loss: 0.4139, Validation loss: 0.4104
Epoch 40, Training loss: 0.4130, Validation loss: 0.3940
Epoch 41, Training loss: 0.4114, Validation loss: 0.3958
Epoch 42, Training loss: 0.4117, Validation loss: 0.4084
Epoch 43, Training loss: 0.4150, Validation loss: 0.4189
Epoch 44, Training loss: 0.4461, Validation loss: 0.3832
Epoch 45, Training loss: 0.4135, Validation loss: 0.3838
Epoch 46, Training loss: 0.4191, Validation loss: 0.4231
Epoch 47, Training loss: 0.4082, Validation loss: 0.3923
Epoch 48, Training loss: 0.4061, Validation loss: 0.3941
Epoch 49, Training loss: 0.4328, Validation loss: 0.3788
Epoch 50, Training loss: 0.4051, Validation loss: 0.3947
Epoch 51, Training loss: 0.4168, Validation loss: 0.3838
Epoch 52, Training loss: 0.4717, Validation loss: 0.4881
Epoch 53, Training loss: 0.4038, Validation loss: 0.3831
Epoch 54, Training loss: 0.4034, Validation loss: 0.3812
Epoch 55, Training loss: 0.4804, Validation loss: 0.4798
Epoch 56, Training loss: 0.4118, Validation loss: 0.3898
Epoch 57, Training loss: 0.4535, Validation loss: 0.4647
Epoch 58, Training loss: 0.4018, Validation loss: 0.3735
Epoch 59, Training loss: 0.3995, Validation loss: 0.3892
Epoch 60, Training loss: 0.3984, Validation loss: 0.3848
Epoch 61, Training loss: 0.3969, Validation loss: 0.3804
Epoch 62, Training loss: 0.4028, Validation loss: 0.3882
Epoch 63, Training loss: 0.3996, Validation loss: 0.3744
Epoch 64, Training loss: 0.3957, Validation loss: 0.3819
Epoch 65, Training loss: 0.3951, Validation loss: 0.3818
Epoch 66, Training loss: 0.3949, Validation loss: 0.3842
Epoch 67, Training loss: 0.3949, Validation loss: 0.3764
Epoch 68, Training loss: 0.3964, Validation loss: 0.3698
Epoch 69, Training loss: 0.4290, Validation loss: 0.4514
Epoch 70, Training loss: 0.3936, Validation loss: 0.3785
Epoch 71, Training loss: 0.3931, Validation loss: 0.3848
Epoch 72, Training loss: 0.3941, Validation loss: 0.3909
Epoch 73, Training loss: 0.3928, Validation loss: 0.3794
Epoch 74, Training loss: 0.4313, Validation loss: 0.3893
Epoch 75, Training loss: 0.3969, Validation loss: 0.3770
Epoch 76, Training loss: 0.4141, Validation loss: 0.3708
Epoch 77, Training loss: 0.4539, Validation loss: 0.4662
Epoch 78, Training loss: 0.3918, Validation loss: 0.3661
Epoch 79, Training loss: 0.3909, Validation loss: 0.3687
Epoch 80, Training loss: 0.4001, Validation loss: 0.4065
Epoch 81, Training loss: 0.3890, Validation loss: 0.3686
Epoch 82, Training loss: 0.3912, Validation loss: 0.3936
Epoch 83, Training loss: 0.3875, Validation loss: 0.3749
Epoch 84, Training loss: 0.4245, Validation loss: 0.3650
Epoch 85, Training loss: 0.3879, Validation loss: 0.3729
Epoch 86, Training loss: 0.3939, Validation loss: 0.3643
Epoch 87, Training loss: 0.3889, Validation loss: 0.3861
Epoch 88, Training loss: 0.3873, Validation loss: 0.3699
Epoch 89, Training loss: 0.4853, Validation loss: 0.5245
Epoch 90, Training loss: 0.4099, Validation loss: 0.4278
Epoch 91, Training loss: 0.4015, Validation loss: 0.3611
Epoch 92, Training loss: 0.3862, Validation loss: 0.3762
Epoch 93, Training loss: 0.3898, Validation loss: 0.3645
Epoch 94, Training loss: 0.3916, Validation loss: 0.3687
Epoch 95, Training loss: 0.3862, Validation loss: 0.3737
Epoch 96, Training loss: 0.3863, Validation loss: 0.3781
Epoch 97, Training loss: 0.3868, Validation loss: 0.3666
Epoch 98, Training loss: 0.4119, Validation loss: 0.4372
Epoch 99, Training loss: 0.3931, Validation loss: 0.3822
Epoch 100, Training loss: 0.3900, Validation loss: 0.3762
Epoch 101, Training loss: 0.3923, Validation loss: 0.3654
Early stopping.
Epoch 0, Training loss: 1.0057, Validation loss: 0.7923
Epoch 1, Training loss: 0.6517, Validation loss: 0.5607
Epoch 2, Training loss: 0.6139, Validation loss: 0.5558
Epoch 3, Training loss: 0.5500, Validation loss: 0.4823
Epoch 4, Training loss: 0.5342, Validation loss: 0.4815
Epoch 5, Training loss: 0.5504, Validation loss: 0.4762
Epoch 6, Training loss: 0.5311, Validation loss: 0.4962
Epoch 7, Training loss: 0.5150, Validation loss: 0.4674
Epoch 8, Training loss: 0.5114, Validation loss: 0.4656
Epoch 9, Training loss: 0.5082, Validation loss: 0.4607
Epoch 10, Training loss: 0.5131, Validation loss: 0.4810
Epoch 11, Training loss: 0.5099, Validation loss: 0.4789
Epoch 12, Training loss: 0.5016, Validation loss: 0.4590
Epoch 13, Training loss: 0.5062, Validation loss: 0.4772
Epoch 14, Training loss: 0.5046, Validation loss: 0.4566
Epoch 15, Training loss: 0.4948, Validation loss: 0.4589
Epoch 16, Training loss: 0.5005, Validation loss: 0.4550
Epoch 17, Training loss: 0.5159, Validation loss: 0.4549
Epoch 18, Training loss: 0.4973, Validation loss: 0.4783
Epoch 19, Training loss: 0.5152, Validation loss: 0.5049
Epoch 20, Training loss: 0.4992, Validation loss: 0.4799
Epoch 21, Training loss: 0.4900, Validation loss: 0.4508
Epoch 22, Training loss: 0.4865, Validation loss: 0.4553
Epoch 23, Training loss: 0.4869, Validation loss: 0.4519
Epoch 24, Training loss: 0.4870, Validation loss: 0.4698
Epoch 25, Training loss: 0.4870, Validation loss: 0.4545
Epoch 26, Training loss: 0.4841, Validation loss: 0.4597
Epoch 27, Training loss: 0.4878, Validation loss: 0.4528
Epoch 28, Training loss: 0.4837, Validation loss: 0.4556
Epoch 29, Training loss: 0.4836, Validation loss: 0.4658
Epoch 30, Training loss: 0.4887, Validation loss: 0.4518
Epoch 31, Training loss: 0.4866, Validation loss: 0.4722
Early stopping.
Epoch 0, Training loss: 0.4208, Validation loss: 0.3685
Epoch 1, Training loss: 0.4162, Validation loss: 0.3473
Epoch 2, Training loss: 0.4142, Validation loss: 0.3354
Epoch 3, Training loss: 0.4148, Validation loss: 0.3501
Epoch 4, Training loss: 0.4157, Validation loss: 0.3538
Epoch 5, Training loss: 0.4094, Validation loss: 0.3340
Epoch 6, Training loss: 0.4257, Validation loss: 0.3426
Epoch 7, Training loss: 0.4206, Validation loss: 0.3465
Epoch 8, Training loss: 0.4163, Validation loss: 0.3541
Epoch 9, Training loss: 0.4208, Validation loss: 0.3549
Epoch 10, Training loss: 0.4226, Validation loss: 0.3609
Epoch 11, Training loss: 0.4267, Validation loss: 0.3600
Epoch 12, Training loss: 0.4251, Validation loss: 0.3565
Epoch 13, Training loss: 0.4285, Validation loss: 0.3562
Epoch 14, Training loss: 0.4258, Validation loss: 0.3591
Epoch 15, Training loss: 0.4218, Validation loss: 0.3566
Early stopping.
Epoch 0, Training loss: 0.4521, Validation loss: 0.4196
Epoch 1, Training loss: 0.4232, Validation loss: 0.3696
Epoch 2, Training loss: 0.4202, Validation loss: 0.3545
Epoch 3, Training loss: 0.4162, Validation loss: 0.3529
Epoch 4, Training loss: 0.4104, Validation loss: 0.3568
Epoch 5, Training loss: 0.4133, Validation loss: 0.3584
Epoch 6, Training loss: 0.4170, Validation loss: 0.3609
Epoch 7, Training loss: 0.4170, Validation loss: 0.3622
Epoch 8, Training loss: 0.4192, Validation loss: 0.3574
Epoch 9, Training loss: 0.4259, Validation loss: 0.3526
Epoch 10, Training loss: 0.4238, Validation loss: 0.3836
Epoch 11, Training loss: 0.4302, Validation loss: 0.3546
Epoch 12, Training loss: 0.4235, Validation loss: 0.3566
Epoch 13, Training loss: 0.4296, Validation loss: 0.3603
Epoch 14, Training loss: 0.4215, Validation loss: 0.3592
Epoch 15, Training loss: 0.4200, Validation loss: 0.3601
Epoch 16, Training loss: 0.4208, Validation loss: 0.3586
Epoch 17, Training loss: 0.4254, Validation loss: 0.3575
Epoch 18, Training loss: 0.4259, Validation loss: 0.3572
Epoch 19, Training loss: 0.4241, Validation loss: 0.3596
Early stopping.
Epoch 0, Training loss: 0.4642, Validation loss: 0.4178
Epoch 1, Training loss: 0.5092, Validation loss: 0.4997
Epoch 2, Training loss: 0.4241, Validation loss: 0.3444
Epoch 3, Training loss: 0.4142, Validation loss: 0.3547
Epoch 4, Training loss: 0.4527, Validation loss: 0.3508
Epoch 5, Training loss: 0.4164, Validation loss: 0.3479
Epoch 6, Training loss: 0.4378, Validation loss: 0.4111
Epoch 7, Training loss: 0.4178, Validation loss: 0.3751
Epoch 8, Training loss: 0.4441, Validation loss: 0.3556
Epoch 9, Training loss: 0.4128, Validation loss: 0.3485
Epoch 10, Training loss: 0.4161, Validation loss: 0.3458
Epoch 11, Training loss: 0.4132, Validation loss: 0.3471
Epoch 12, Training loss: 0.4192, Validation loss: 0.3472
Early stopping.
Epoch 0, Training loss: 0.5125, Validation loss: 0.4276
Epoch 1, Training loss: 0.4892, Validation loss: 0.4270
Epoch 2, Training loss: 0.4973, Validation loss: 0.4329
Epoch 3, Training loss: 0.4858, Validation loss: 0.4359
Epoch 4, Training loss: 0.4880, Validation loss: 0.4371
Epoch 5, Training loss: 0.4857, Validation loss: 0.4462
Epoch 6, Training loss: 0.5006, Validation loss: 0.4454
Epoch 7, Training loss: 0.4959, Validation loss: 0.4463
Epoch 8, Training loss: 0.4934, Validation loss: 0.4444
Epoch 9, Training loss: 0.4912, Validation loss: 0.4455
Epoch 10, Training loss: 0.5008, Validation loss: 0.4468
Epoch 11, Training loss: 0.4966, Validation loss: 0.4516
Early stopping.
Epoch 0, Training loss: 0.5597, Validation loss: 0.4867
Epoch 1, Training loss: 0.5218, Validation loss: 0.4664
Epoch 2, Training loss: 0.5072, Validation loss: 0.4568
Epoch 3, Training loss: 0.5064, Validation loss: 0.4673
Epoch 4, Training loss: 0.4936, Validation loss: 0.4493
Epoch 5, Training loss: 0.4925, Validation loss: 0.4486
Epoch 6, Training loss: 0.4964, Validation loss: 0.4677
Epoch 7, Training loss: 0.5138, Validation loss: 0.4469
Epoch 8, Training loss: 0.4935, Validation loss: 0.4345
Epoch 9, Training loss: 0.4920, Validation loss: 0.4414
Epoch 10, Training loss: 0.4906, Validation loss: 0.4506
Epoch 11, Training loss: 0.4934, Validation loss: 0.4425
Epoch 12, Training loss: 0.5006, Validation loss: 0.4746
Epoch 13, Training loss: 0.4924, Validation loss: 0.4480
Epoch 14, Training loss: 0.4957, Validation loss: 0.4492
Epoch 15, Training loss: 0.5054, Validation loss: 0.4471
Epoch 16, Training loss: 0.4942, Validation loss: 0.4496
Epoch 17, Training loss: 0.4978, Validation loss: 0.4492
Epoch 18, Training loss: 0.4974, Validation loss: 0.4499
Early stopping.
Epoch 0, Training loss: 0.8138, Validation loss: 0.6546
Epoch 1, Training loss: 0.6867, Validation loss: 0.5676
Epoch 2, Training loss: 0.6122, Validation loss: 0.5219
Epoch 3, Training loss: 0.5751, Validation loss: 0.4940
Epoch 4, Training loss: 0.5431, Validation loss: 0.4765
Epoch 5, Training loss: 0.5189, Validation loss: 0.4755
Epoch 6, Training loss: 0.5118, Validation loss: 0.4721
Epoch 7, Training loss: 0.5056, Validation loss: 0.4713
Epoch 8, Training loss: 0.5047, Validation loss: 0.4582
Epoch 9, Training loss: 0.5004, Validation loss: 0.4667
Epoch 10, Training loss: 0.5026, Validation loss: 0.4760
Epoch 11, Training loss: 0.5433, Validation loss: 0.4869
Epoch 12, Training loss: 0.5058, Validation loss: 0.4419
Epoch 13, Training loss: 0.4975, Validation loss: 0.4481
Epoch 14, Training loss: 0.4926, Validation loss: 0.4593
Epoch 15, Training loss: 0.4976, Validation loss: 0.4703
Epoch 16, Training loss: 0.5005, Validation loss: 0.4880
Epoch 17, Training loss: 0.4917, Validation loss: 0.4558
Epoch 18, Training loss: 0.4934, Validation loss: 0.4522
Epoch 19, Training loss: 0.4912, Validation loss: 0.4636
Epoch 20, Training loss: 0.4883, Validation loss: 0.4467
Epoch 21, Training loss: 0.4905, Validation loss: 0.4453
Epoch 22, Training loss: 0.4894, Validation loss: 0.4539
Early stopping.
Epoch 0, Training loss: 0.4661, Validation loss: 0.4511
Epoch 1, Training loss: 0.4074, Validation loss: 0.3413
Epoch 2, Training loss: 0.4126, Validation loss: 0.3558
Epoch 3, Training loss: 0.4064, Validation loss: 0.3464
Epoch 4, Training loss: 0.4139, Validation loss: 0.3508
Epoch 5, Training loss: 0.4098, Validation loss: 0.3533
Epoch 6, Training loss: 0.4372, Validation loss: 0.3500
Epoch 7, Training loss: 0.4194, Validation loss: 0.3451
Epoch 8, Training loss: 0.4180, Validation loss: 0.3807
Epoch 9, Training loss: 0.4260, Validation loss: 0.3543
Epoch 10, Training loss: 0.4173, Validation loss: 0.3560
Epoch 11, Training loss: 0.4134, Validation loss: 0.3518
Early stopping.
Epoch 0, Training loss: 0.4741, Validation loss: 0.4003
Epoch 1, Training loss: 0.4305, Validation loss: 0.3500
Epoch 2, Training loss: 0.4160, Validation loss: 0.3436
Epoch 3, Training loss: 0.4095, Validation loss: 0.3534
Epoch 4, Training loss: 0.4185, Validation loss: 0.3668
Epoch 5, Training loss: 0.4226, Validation loss: 0.3861
Epoch 6, Training loss: 0.4047, Validation loss: 0.3703
Epoch 7, Training loss: 0.4072, Validation loss: 0.3492
Epoch 8, Training loss: 0.4116, Validation loss: 0.3529
Epoch 9, Training loss: 0.4133, Validation loss: 0.3536
Epoch 10, Training loss: 0.4140, Validation loss: 0.3632
Epoch 11, Training loss: 0.4215, Validation loss: 0.3531
Epoch 12, Training loss: 0.4171, Validation loss: 0.3603
Early stopping.
Epoch 0, Training loss: 0.4508, Validation loss: 0.3565
Epoch 1, Training loss: 0.4876, Validation loss: 0.4925
Epoch 2, Training loss: 0.4378, Validation loss: 0.3539
Epoch 3, Training loss: 0.4176, Validation loss: 0.3704
Epoch 4, Training loss: 0.4224, Validation loss: 0.3378
Epoch 5, Training loss: 0.6133, Validation loss: 0.4460
Epoch 6, Training loss: 0.4400, Validation loss: 0.3197
Epoch 7, Training loss: 0.4262, Validation loss: 0.3715
Epoch 8, Training loss: 0.4315, Validation loss: 0.3984
Epoch 9, Training loss: 0.4118, Validation loss: 0.3567
Epoch 10, Training loss: 0.4119, Validation loss: 0.3386
Epoch 11, Training loss: 0.4112, Validation loss: 0.3516
Epoch 12, Training loss: 0.4124, Validation loss: 0.3547
Epoch 13, Training loss: 0.4145, Validation loss: 0.3423
Epoch 14, Training loss: 0.4158, Validation loss: 0.3475
Epoch 15, Training loss: 0.4186, Validation loss: 0.3419
Epoch 16, Training loss: 0.4126, Validation loss: 0.3465
Early stopping.
Best Model Parameters: {'hidden_layer_sizes': (100,), 'activation': 'tanh', 'learning_rate': 0.01995074189394607, 'max_iter': 500, 'early_stopping': True, 'validation_split': 0.2, 'patience': 10, 'alpha': 0.07554626972671763, 'batch_size': 64}
Best Model Test MSE: 0.3421485315714813
Best Model Test MAE: 0.369556239695163
